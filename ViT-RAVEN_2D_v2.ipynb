{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf791c6-8e50-4914-a1fc-ebfb60323129",
   "metadata": {},
   "source": [
    "# ViT Example on MNIST\n",
    "\n",
    "Adapted from: [https://keras.io/examples/vision/image_classification_with_vision_transformer/](https://keras.io/examples/vision/image_classification_with_vision_transformer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prime-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "## V2 Does not Augment Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incredible-wound",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'layersf' from 'tensorflow.keras' (/opt/conda/lib/python3.8/site-packages/tensorflow/keras/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-971fe13a6d2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayersf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'layersf' from 'tensorflow.keras' (/opt/conda/lib/python3.8/site-packages/tensorflow/keras/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_npz_img(img_path):\n",
    "    data = np.load(img_path)\n",
    "    img = data['image']\n",
    "    target = data['target']\n",
    "    x = img[:,:,:]\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    #x = x.reshape((x.shape[0],x.shape[1],x.shape[2],x.shape[3],1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_npz_target(target_path):\n",
    "    data = np.load(target_path)\n",
    "    target = data['target']\n",
    "    y = int(target)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(folder,num_imgs,config):\n",
    "    X = []\n",
    "    #X = np.array(X)\n",
    "    Y =[]\n",
    "    #for i in range(num_imgs):\n",
    "    name = ''\n",
    "    if config=='train':\n",
    "        name = 'train'\n",
    "    elif config=='validate':\n",
    "        name = 'val'\n",
    "    else:\n",
    "        name = 'test'\n",
    "        \n",
    "    count = 0\n",
    "    i = 0\n",
    "    while count < num_imgs:\n",
    "        try:\n",
    "            x = grab_npz_img('./RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            y = grab_npz_target('./RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            i += 1\n",
    "        except:\n",
    "            i += 1\n",
    "            continue\n",
    "        X.append(x)\n",
    "        #X = np.concatenate(x)\n",
    "        Y.append(y)\n",
    "        count += 1\n",
    "    X = np.array(X)\n",
    "    X = np.squeeze(X)\n",
    "    #X = np.expand_dims(X, axis=4)\n",
    "    #X = X.reshape((X.shape[0],X.shape[2],X.shape[3],X.shape[1]))\n",
    "    X = np.moveaxis(X, 1, -1)\n",
    "    return X,np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_3d(folder,num_imgs,config):\n",
    "    X = []\n",
    "    #X = np.array(X)\n",
    "    Y =[]\n",
    "    #for i in range(num_imgs):\n",
    "    \n",
    "    name = ''\n",
    "    if config=='train':\n",
    "        name = 'train'\n",
    "    elif config=='validate':\n",
    "        name = 'val'\n",
    "    else:\n",
    "        name = 'test'\n",
    "        \n",
    "    count = 0\n",
    "    i = 0\n",
    "    while count < num_imgs:\n",
    "        try:\n",
    "            x = grab_npz_img('./RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            y = grab_npz_target('./RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            i += 1\n",
    "        except:\n",
    "            i += 1\n",
    "            continue\n",
    "        X.append(x)\n",
    "        #X = np.concatenate(x)\n",
    "        Y.append(y)\n",
    "        count += 1\n",
    "    X = np.array(X)\n",
    "    X = np.squeeze(X)\n",
    "    X = np.expand_dims(X, axis=4)\n",
    "    return X,np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr = 0.01, embed_dim = 8192.0, warmup_steps = 100.0):\n",
    "    arg1 = tf.math.rsqrt(tf.cast(epoch,'float32'))\n",
    "    arg2 = epoch * (warmup_steps ** -1.5)\n",
    "    return tf.math.rsqrt(embed_dim) * tf.math.minimum(arg1,arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'center_single'\n",
    "#folder = 'in_center_single_out_center_single'\n",
    "num_imgs = 5000\n",
    "val_split = 0.1\n",
    "x_train,y_train = create_dataset(folder,num_imgs,'train')\n",
    "x_val,y_val = create_dataset(folder,num_imgs*val_split,'validate')\n",
    "x_test,y_test = create_dataset(folder,num_imgs*val_split,'test')\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_val /= 255\n",
    "#x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train ,num_classes=8)\n",
    "y_val = keras.utils.to_categorical(y_val,num_classes=8)\n",
    "y_test = keras.utils.to_categorical(y_test,num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "'''\n",
    "display(x_train.shape)\n",
    "display(y_train.shape)\n",
    "display(x_test.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardize the -input- data between 0.0-1.0 (real)\n",
    "## instead of the default 0-255 (integer)\n",
    "'''\n",
    "x_train = x_train.astype('float32').reshape(x_train.shape+(1,))\n",
    "x_test = x_test.astype('float32').reshape(x_test.shape+(1,))\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vector [0-9] to categorical assignments (one-hot)\n",
    "# y_train = keras.utils.to_categorical(y_train, len(np.unique(y_train)))\n",
    "# y_test = keras.utils.to_categorical(y_test, len(np.unique(y_test)))\n",
    "\n",
    "display(x_train.shape)\n",
    "display(y_train.shape)\n",
    "display(x_test.shape)\n",
    "display(y_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8\n",
    "input_shape = (160, 160, 16)\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 32\n",
    "num_epochs = 1000\n",
    "image_size = 160  # We'll resize input images to this size\n",
    "patch_size = 40 # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Normalization(),\n",
    "        layers.experimental.preprocessing.Resizing(image_size, image_size),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
    "        layers.experimental.preprocessing.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-2] # x already embedded\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    '''\n",
    "    inputs = layers.Input(shape=(x_train.shape[1],\n",
    "                                            x_train.shape[2],\n",
    "                                            x_train.shape[3],\n",
    "                                            x_train.shape[4]))\n",
    "    '''\n",
    "    # Augment data.\n",
    "    #augmented = data_augmentation(inputs)\n",
    "    augmented = inputs\n",
    "    # Create patches.\n",
    "    # patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    # encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "    \n",
    "    patches = keras.layers.Conv2D(projection_dim,\n",
    "                                  kernel_size=(patch_size,patch_size),\n",
    "                                  strides=(patch_size,patch_size))(augmented)\n",
    "    \n",
    "    #augmented = keras.layers.Reshape((160, 160, 16, 1))(augmented)\n",
    "    '''\n",
    "    patches = keras.layers.Conv3D(projection_dim,\n",
    "                                  kernel_size=(patch_size,patch_size,1),\n",
    "                                  strides=(patch_size,patch_size,1))(augmented)\n",
    "    '''\n",
    "    patches = keras.layers.Reshape((-1,projection_dim))(patches)\n",
    "    position_embedding = PositionEmbedding(patches.shape[-2],\n",
    "                                           projection_dim)\n",
    "    encoded_patches = position_embedding(patches)\n",
    "    \n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    #representation = layers.Flatten()(representation)\n",
    "    representation = layers.GlobalAveragePooling1D()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.TopKCategoricalAccuracy(4, name=\"top-4-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "    scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback,scheduler_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional n epochs? - will overwrite history...\n",
    "# num_epochs = 20\n",
    "# history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)  \n",
    "  \n",
    "# summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "   \n",
    "# summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = vit_classifier.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_classifier.summary()\n",
    "keras.utils.plot_model(vit_classifier,\n",
    "                       to_file=\"vit-cifar.png\",\n",
    "                       show_shapes=True,\n",
    "                       expand_nested=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
