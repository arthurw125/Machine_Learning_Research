{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07865754-05b1-4198-ae72-0139dc257fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from util import log\n",
    "from modules import *\n",
    "from dist3 import create_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a548cfc9-5c55-4130-99c5-946e4be00470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set,test_set = create_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae57d2c5-65be-457e-b50d-0fd3b445874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set['seq_ind'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b691aa-337d-4d57-8f63-ddafd99bf2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d442f1e-e39e-4894-bfe1-2929b893a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = training_set['seq_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a58126-f899-4505-a016-d5f74d8ed723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc03fbb9-b569-43be-803f-34d9ec6803dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916244aa-475e-426f-b0ce-abcc46e81591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "all_imgs = []\n",
    "n_shapes = 100\n",
    "for i in range(n_shapes):\n",
    "\timg_fname = '/home/asw3x/emergent_symbols/imgs/' + str(i) + '.png'\n",
    "\timg = torch.Tensor(np.array(Image.open(img_fname))) / 255.\n",
    "\tall_imgs.append(img)\n",
    "all_imgs = torch.stack(all_imgs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d87ce5-4d46-4361-88cc-8743100b04fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2aeff16-025d-4e7c-81ec-75837d0bff11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = all_imgs[0,:,:]\n",
    "#label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "#print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba38bac8-8879-4f5e-8d29-a6b581b69817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = all_imgs[train,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9f318c-7606-4054-984b-340854e7387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40dd45b9-bf4c-4de7-a184-d2a24a8ad6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist3_ESBN_task():\n",
    "    training_set,test_set = create_task()\n",
    "    # Load images\n",
    "    all_imgs = []\n",
    "    n_shapes = 100\n",
    "    for i in range(n_shapes):\n",
    "        img_fname = '/home/asw3x/emergent_symbols/imgs/' + str(i) + '.png'\n",
    "        img = torch.Tensor(np.array(Image.open(img_fname))) / 255.\n",
    "        all_imgs.append(img)\n",
    "    all_imgs = torch.stack(all_imgs, 0)\n",
    "    # Create training and test sets\n",
    "    train = training_set['seq_ind']\n",
    "    test = test_set['seq_ind']\n",
    "    X_train = all_imgs[train,:,:]\n",
    "    X_test = all_imgs[test,:,:]\n",
    "    Y_train = training_set['y']\n",
    "    Y_test = test_set['y']\n",
    "    \n",
    "    train_set = {'img_seq': X_train, 'y': Y_train}\n",
    "    test_set = {'img_seq': X_test, 'y': Y_test}\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa488ab-0a92-45a2-8a9a-b46df6e67769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,431] n_shapes = 100...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,432] m_holdout = 0...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,433] Total possible trials = 5821200...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,433] Training set size = 10000...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,433] Test set size = 10000...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_set,test_set = dist3_ESBN_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633b7c4f-b90b-4f5c-b72c-4672bc5b108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 9, 32, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['img_seq'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e67f724f-1d3c-4fc0-8e3a-bcfffd4a2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, target_transform=None):\n",
    "        '''\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        '''\n",
    "        self.img_seq = dataset['img_seq']\n",
    "        self.y = dataset['y']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "        '''\n",
    "        img_seq = self.img_seq[idx,:,:,:]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return img_seq, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "153311cb-07c7-48f6-abb9-f23db5e9f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_conv(nn.Module):\n",
    "\t#def __init__(self, args):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Encoder_conv, self).__init__()\n",
    "\t\tlog.info('Building convolutional encoder...')\n",
    "\t\t# Convolutional layers\n",
    "\t\tlog.info('Conv layers...')\n",
    "\t\t\n",
    "\t\tself.conv1 = nn.Conv2d(1, 32, 4, stride=2, padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(32, 32, 4, stride=2, padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(32, 32, 4, stride=2, padding=1)\n",
    "\t\t'''\n",
    "\t\tself.conv1 = nn.Conv2d(1, 160, 4, stride=2, padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(160, 160, 4, stride=2, padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(160, 160, 4, stride=2, padding=1)\n",
    "\t\t'''   \n",
    "\t\t# Fully-connected layers\n",
    "\t\tlog.info('FC layers...')\n",
    "\t\tself.fc1 = nn.Linear(4*4*32, 256)\n",
    "\t\tself.fc2 = nn.Linear(256, 128)\n",
    "\t\t#self.fc1 = nn.Linear(64000, 256)\n",
    "\t\t#self.fc2 = nn.Linear(256, 128)\n",
    "\t\t# Nonlinearities\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\t# Initialize parameters\n",
    "\t\tfor name, param in self.named_parameters():\n",
    "\t\t\t# Initialize all biases to 0\n",
    "\t\t\tif 'bias' in name:\n",
    "\t\t\t\tnn.init.constant_(param, 0.0)\n",
    "\t\t\t# Initialize all pre-ReLU weights using Kaiming normal distribution\n",
    "\t\t\telif 'weight' in name:\n",
    "\t\t\t\tnn.init.kaiming_normal_(param, nonlinearity='relu')\n",
    "\tdef forward(self, x):\n",
    "\t\t# Convolutional layers\n",
    "\t\tconv1_out = self.relu(self.conv1(x))\n",
    "\t\tconv2_out = self.relu(self.conv2(conv1_out))\n",
    "\t\tconv3_out = self.relu(self.conv3(conv2_out))\n",
    "\t\t# Flatten output of conv. net\n",
    "\t\tconv3_out_flat = torch.flatten(conv3_out, 1)\n",
    "\t\t# Fully-connected layers\n",
    "\t\t#print(\"conv3_out_flat.size() =\",conv3_out_flat.size())\n",
    "\t\t#time.sleep(120)\n",
    "\t\tfc1_out = self.relu(self.fc1(conv3_out_flat))\n",
    "\t\tfc2_out = self.relu(self.fc2(fc1_out))\n",
    "\t\t# Output\n",
    "\t\tz = fc2_out\n",
    "\t\treturn z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee457bd-d49a-47fa-ac0a-6ecf29be8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\t#def __init__(self, task_gen, args):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Model, self).__init__()\n",
    "\t\t# Encoder\n",
    "\t\tlog.info('Building encoder...')\n",
    "\t\t'''\n",
    "\t\tif args.encoder == 'conv':\n",
    "\t\t\tself.encoder = Encoder_conv(args)\n",
    "\t\telif args.encoder == 'mlp':\n",
    "\t\t\tself.encoder = Encoder_mlp(args)\n",
    "\t\telif args.encoder == 'rand':\n",
    "\t\t\tself.encoder = Encoder_rand(args)\n",
    "\t\t'''\n",
    "\t\tself.encoder = Encoder_conv()# removed \"args\" argument\n",
    "\t\t# LSTM and output layers\n",
    "\t\tlog.info('Building LSTM and output layers...')\n",
    "\t\tself.z_size = 128\n",
    "\t\tself.key_size = 256\n",
    "\t\tself.hidden_size = 512\n",
    "\t\tself.lstm = nn.LSTM(self.key_size + 1, self.hidden_size, batch_first=True)\n",
    "\t\tself.key_w_out = nn.Linear(self.hidden_size, self.key_size)\n",
    "\t\tself.g_out = nn.Linear(self.hidden_size, 1)\n",
    "\t\tself.confidence_gain = nn.Parameter(torch.ones(1))\n",
    "\t\tself.confidence_bias = nn.Parameter(torch.zeros(1))\n",
    "\t\t#self.y_out = nn.Linear(self.hidden_size, task_gen.y_dim)\n",
    "\t\ty_out = 4 # number of outputs/ ESBN = 4\n",
    "\t\tself.y_out = nn.Linear(self.hidden_size, y_out)\n",
    "\t\t# Context normalization\n",
    "\t\t#if args.norm_type == 'contextnorm' or args.norm_type == 'tasksegmented_contextnorm':\n",
    "\t\tif True: # assumes \"contextnorm or tasksegmented_contextnorm\"\n",
    "\t\t\tself.contextnorm = True\n",
    "\t\t\tself.gamma = nn.Parameter(torch.ones(self.z_size))\n",
    "\t\t\tself.beta = nn.Parameter(torch.zeros(self.z_size))\n",
    "\t\telse:\n",
    "\t\t\tself.contextnorm = False\n",
    "\t\t'''\n",
    "\t\tif args.norm_type == 'tasksegmented_contextnorm':\n",
    "\t\t\tself.task_seg = task_gen.task_seg\n",
    "\t\telse:\n",
    "\t\t\tself.task_seg = [np.arange(task_gen.seq_len)]\n",
    "\t\t'''\n",
    "\t\tseq_len = 9 # number of images per Raven problem / ESBN = 9        \n",
    "\t\tself.task_seg = [np.arange(seq_len)]\n",
    "\t\t# Nonlinearities\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\t\tself.softmax = nn.Softmax(dim=1)\n",
    "\t\t# Initialize parameters\n",
    "\t\tfor name, param in self.named_parameters():\n",
    "\t\t\t# Encoder parameters have already been initialized\n",
    "\t\t\tif not ('encoder' in name) and not ('confidence' in name):\n",
    "\t\t\t\t# Initialize all biases to 0\n",
    "\t\t\t\tif 'bias' in name:\n",
    "\t\t\t\t\tnn.init.constant_(param, 0.0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif 'lstm' in name:\n",
    "\t\t\t\t\t\t# Initialize gate weights (followed by sigmoid) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[:self.hidden_size*2,:])\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[self.hidden_size*3:,:])\n",
    "\t\t\t\t\t\t# Initialize input->hidden and hidden->hidden weights (followed by tanh) using Xavier normal distribution with gain = \n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[self.hidden_size*2:self.hidden_size*3,:], gain=5.0/3.0)\n",
    "\t\t\t\t\telif 'key_w' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for key output layer (followed by ReLU) using Kaiming normal distribution\n",
    "\t\t\t\t\t\tnn.init.kaiming_normal_(param, nonlinearity='relu')\n",
    "\t\t\t\t\telif 'g_out' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for gate output layer (followed by sigmoid) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param)\n",
    "\t\t\t\t\telif 'y_out' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for multiple-choice output layer (followed by softmax) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param)\n",
    "\tdef forward(self, x_seq, device):\n",
    "\t\t# Encode all images in sequence\n",
    "\t\tz_seq = []\n",
    "\t\tfor t in range(x_seq.shape[1]):\n",
    "\t\t\tx_t = x_seq[:,t,:,:].unsqueeze(1)\n",
    "\t\t\tz_t = self.encoder(x_t)\n",
    "\t\t\tz_seq.append(z_t)\n",
    "\t\tz_seq = torch.stack(z_seq, dim=1)\n",
    "\t\tif self.contextnorm:\n",
    "\t\t\tz_seq_all_seg = []\n",
    "\t\t\tfor seg in range(len(self.task_seg)):\n",
    "\t\t\t\tz_seq_all_seg.append(self.apply_context_norm(z_seq[:,self.task_seg[seg],:]))\n",
    "\t\t\tz_seq = torch.cat(z_seq_all_seg, dim=1)\n",
    "\t\t# Initialize hidden state\n",
    "\t\thidden = torch.zeros(1, x_seq.shape[0], self.hidden_size).to(device)\n",
    "\t\tcell_state = torch.zeros(1, x_seq.shape[0], self.hidden_size).to(device)\n",
    "\t\t# Initialize retrieved key vector\n",
    "\t\tkey_r = torch.zeros(x_seq.shape[0], 1, self.key_size + 1).to(device)\n",
    "\t\t# Memory model (extra time step to process key retrieved on final time step)\n",
    "\t\tfor t in range(x_seq.shape[1] + 1):\n",
    "\t\t\t# Image embedding\n",
    "\t\t\tif t == x_seq.shape[1]:\n",
    "\t\t\t\tz_t = torch.zeros(x_seq.shape[0], 1, self.z_size).to(device)\n",
    "\t\t\telse:\n",
    "\t\t\t\tz_t = z_seq[:,t,:].unsqueeze(1)\n",
    "\t\t\t# Controller\n",
    "\t\t\t# LSTM\n",
    "\t\t\tlstm_out, (hidden, cell_state) = self.lstm(key_r, (hidden, cell_state))\n",
    "\t\t\t# Key output layers\n",
    "\t\t\tkey_w = self.relu(self.key_w_out(lstm_out))\n",
    "\t\t\t# Gates\n",
    "\t\t\tg = self.sigmoid(self.g_out(lstm_out))\n",
    "\t\t\t# Task output layer\n",
    "\t\t\ty_pred_linear = self.y_out(lstm_out).squeeze()\n",
    "\t\t\ty_pred = y_pred_linear.argmax(1)\n",
    "\t\t\t# Read from memory\n",
    "\t\t\tif t == 0:\n",
    "\t\t\t\tkey_r = torch.zeros(x_seq.shape[0], 1, self.key_size + 1).to(device)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Read key\n",
    "\t\t\t\tw_k = self.softmax((z_t * M_v).sum(dim=2))\n",
    "\t\t\t\tc_k = self.sigmoid(((z_t * M_v).sum(dim=2) * self.confidence_gain) + self.confidence_bias)\n",
    "\t\t\t\tkey_r = g * (torch.cat([M_k, c_k.unsqueeze(2)], dim=2) * w_k.unsqueeze(2)).sum(1).unsqueeze(1)\n",
    "\t\t\t# Write to memory\n",
    "\t\t\tif t == 0:\n",
    "\t\t\t\tM_k = key_w\n",
    "\t\t\t\tM_v = z_t\n",
    "\t\t\telse:\n",
    "\t\t\t\tM_k = torch.cat([M_k, key_w], dim=1)\n",
    "\t\t\t\tM_v = torch.cat([M_v, z_t], dim=1)\n",
    "\t\treturn y_pred_linear, y_pred\n",
    "\tdef apply_context_norm(self, z_seq):\n",
    "\t\teps = 1e-8\n",
    "\t\tz_mu = z_seq.mean(1)\n",
    "\t\tz_sigma = (z_seq.var(1) + eps).sqrt()\n",
    "\t\tz_seq = (z_seq - z_mu.unsqueeze(1)) / z_sigma.unsqueeze(1)\n",
    "\t\tz_seq = (z_seq * self.gamma) + self.beta\n",
    "\t\treturn z_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80d2e2a7-51b2-4882-a2a9-39c7a9511b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CustomImageDataset(training_set)\n",
    "train_dataloader = DataLoader(training_set, batch_size=32, shuffle=True)\n",
    "test_set = CustomImageDataset(test_set)\n",
    "test_dataloader = DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9b41df4-aaa4-4e05-be80-c63a0e584bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 9, 32, 32])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAO/klEQVR4nO3df6xUdXrH8fejYFqXm3QpAxJF765CUkIUyECMmg2traAhUWPcrIQNGuPdxDUpZk0kNHYl8Q/rr5WYxgQrgW0suxg1wsa0q6SNWa3oiMKFIugS6iKEe60aMCTdIk//mEP2ws537tyZc84M9/m8kpuZ+T7nzPfJyf3cMzNn7jnm7ojI+HdetxsQkXIo7CJBKOwiQSjsIkEo7CJBKOwiQUzoZGUzWwKsBc4H/sndH222/JQpU7y/v7+TKUWkiYMHD/L5559bo1rbYTez84F/BP4GOAS8Z2Zb3P2/Uuv09/dTq9XanVJERlGtVpO1Tl7GLwQ+cfcD7v574BfAzR08n4gUqJOwXwz8bsTjQ9mYiPSgTsLe6H3BH3331swGzKxmZrXh4eEOphORTnQS9kPAjBGPLwEOn72Qu69z96q7VyuVSgfTiUgnOgn7e8BMM/uOmV0A/ADYkk9bIpK3tj+Nd/eTZnYf8G/UD72td/c9uXUmIrnq6Di7u78GvJZTLyJSIH2DTiQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSSIjq4IY2YHgePAN8BJd09fCV5EuqqjsGf+0t0/z+F5RKRAehkvEkSnYXfg12b2vpkN5NGQiBSj05fx17r7YTObCrxuZh+5+5sjF8j+CAwAXHrppR1OJyLt6mjP7u6Hs9sh4BVgYYNl1rl71d2rlUqlk+lEpANth93MvmVmfafvAzcAu/NqTETy1cnL+GnAK2Z2+nn+xd3/NZeuRCR3bYfd3Q8AV+XYi4gUSIfeRIJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCyOO0VBLUyZMnk7UJE/Sr1Wu0ZxcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCx0fGmY8++qjh+ObNm5PrbN26NVnbt29fsnb8+PFkra+vr+H48uXLk+vce++9ydqcOXOSNWmN9uwiQSjsIkEo7CJBKOwiQSjsIkEo7CJBmLs3X8BsPbAUGHL3OdnYZOCXQD9wEPi+u3852mTVatVrtVqHLcdw4sSJZG3VqlXJ2jPPPFNEO1337rvvJmsLFiwosZPeVq1WqdVq1qjWyp59A7DkrLFVwDZ3nwlsyx6LSA8bNezZ9da/OGv4ZmBjdn8jcEu+bYlI3tp9zz7N3Y8AZLdT82tJRIpQ+Ad0ZjZgZjUzqw0PDxc9nYgktBv2o2Y2HSC7HUot6O7r3L3q7tVKpdLmdCLSqXbDvgVYkd1fAbyaTzsiUpRR/+vNzDYBi4ApZnYI+CnwKLDZzO4GPgVuL7LJ8Wr79u3J2rJly5K1AwcOFNFOT1u6dGmy9tlnnyVrOvHlH4y6Jdz9jkTp+px7EZEC6Rt0IkEo7CJBKOwiQSjsIkEo7CJB6LhEwR555JFk7aGHHiqxk3Pb0FDye1sMDg4ma/PmzSuinXOS9uwiQSjsIkEo7CJBKOwiQSjsIkEo7CJB6NBbDjZs2JCsFXF47Z577knWZs+e3XD8/vvvz72PXpG6vh3o0NtI2rOLBKGwiwShsIsEobCLBKGwiwShT+PHYPfu3Q3H77rrrraeb9asWcnapk2bkrX58+ePea6vvvoqWVuzZs2Yn6+XTJs2rdstnBO0ZxcJQmEXCUJhFwlCYRcJQmEXCUJhFwmilcs/rQeWAkPuPicbexi4Bzh9WdbV7v5aUU2W6euvv07WbrvttjE/35VXXpmsvfXWW8napEmTxjxXMw888ECy9vzzzydrhw4dyrWPdvX19SVrCxYsKLGTc1cre/YNwJIG4z9z97nZz7gIush4NmrY3f1N4IsSehGRAnXynv0+M9tlZuvN7Nu5dSQihWg37M8ClwNzgSPAk6kFzWzAzGpmVhseHk4tJiIFayvs7n7U3b9x91PAc8DCJsuuc/equ1crlUq7fYpIh9oKu5lNH/HwVqDxf4iISM9o5dDbJmARMMXMDgE/BRaZ2VzAgYPAj4prsVwrV65M1vbv399wvNlhoS1btiRreR9ea6bZXM0OvS1evLiIdhpqth23bt3a1nryB6OG3d3vaDCc/u0QkZ6kb9CJBKGwiwShsIsEobCLBKGwiwShE06eZfny5cnanj17Go4/9thjyXUuu+yyjnsq2g033JCsbd++PVl74oknkrXDhw83HL/mmmuS69x5553JWuqyVtI67dlFglDYRYJQ2EWCUNhFglDYRYJQ2EWCMHcvbbJqteq1Wq20+USiqVar1Go1a1TTnl0kCIVdJAiFXSQIhV0kCIVdJAj9I8w56O23307W3njjjRI7OXetXr06WZswYXzGQnt2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIFq5/NMM4OfARcApYJ27rzWzycAvgX7ql4D6vrt/WVyrctqLL76YrD399NPlNXIOW7ZsWbJ2xRVXlNhJeVrZs58EfuLufwFcDfzYzGYDq4Bt7j4T2JY9FpEeNWrY3f2Iu+/I7h8H9gIXAzcDG7PFNgK3FNSjiORgTO/ZzawfmAdsB6a5+xGo/0EApubenYjkpuWwm9kk4CVgpbsfG8N6A2ZWM7Pa8PBwOz2KSA5aCruZTaQe9Bfc/eVs+KiZTc/q04GhRuu6+zp3r7p7tVKp5NGziLRh1LCbmVG/Hvted39qRGkLsCK7vwJ4Nf/2RCQvrfx7z7XAD4FBM/swG1sNPApsNrO7gU+B2wvpUP5I6jJUzaxZsyZZmzVrVlt9PP7448najh07Go4/+OCDyXXmzp3bVh9r165N1t55552G4x9//HFynfF66G3UsLv7b4CGJ7ADrs+3HREpir5BJxKEwi4ShMIuEoTCLhKEwi4SxPg8s944t3PnzjGvMzAwkKxddNFFbfWxefPmZC116G3JkiXJdRYtWtRWH/v370/WUofe9u3bl1znxhtvbKuPXqc9u0gQCrtIEAq7SBAKu0gQCrtIEAq7SBA69Najvvwyfe7OoaGGpw4AoK+vr+F4u4fXzgVz5swZ8zrNDr2NV9qziwShsIsEobCLBKGwiwShsIsEoU/je1Szc6Q1c9111+XcSe+bPXv2mNcZHBwsoJPepj27SBAKu0gQCrtIEAq7SBAKu0gQCrtIEKMeejOzGcDPgYuAU8A6d19rZg8D9wCnL8262t1fK6rRaJqdV62Zq666KudO0s47rzf2Fe1crmnXrl0FdNLbWjnOfhL4ibvvMLM+4H0zez2r/czdnyiuPRHJSyvXejsCHMnuHzezvcDFRTcmIvka0+swM+sH5gHbs6H7zGyXma03s2/n3ZyI5KflsJvZJOAlYKW7HwOeBS4H5lLf8z+ZWG/AzGpmVhseHm60iIiUoKWwm9lE6kF/wd1fBnD3o+7+jbufAp4DFjZa193XuXvV3auVSiWvvkVkjEYNu5kZ8Dyw192fGjE+fcRitwK7829PRPLSyqfx1wI/BAbN7MNsbDVwh5nNBRw4CPyogP7COnbsWLI2derUZK1arRbRTkOTJ09O1lI9Xnjhhbn3MWFC+td48eLFDcc/+OCD5DonTpxI1orovyytfBr/G8AalHRMXeQc0hvfihCRwinsIkEo7CJBKOwiQSjsIkGYu5c2WbVa9VqtVtp8ItFUq1VqtVqjo2fas4tEobCLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBKGwiwShsIsE0cq13v7EzN41s51mtsfM1mTjk83sdTP7OLvVJZtFelgre/b/Bf7K3a+ifnnmJWZ2NbAK2ObuM4Ft2WMR6VGjht3rvs4eTsx+HLgZ2JiNbwRuKaJBEclHq9dnPz+7gusQ8Lq7bwemufsRgOw2fWlREem6lsLu7t+4+1zgEmChmc1pdQIzGzCzmpnVhoeH22xTRDo1pk/j3f0r4D+AJcBRM5sOkN0OJdZZ5+5Vd69WKpXOuhWRtrXyaXzFzP4su/+nwF8DHwFbgBXZYiuAVwvqUURyMKGFZaYDG83sfOp/HDa7+6/M7D+BzWZ2N/ApcHuBfYpIh0YNu7vvAuY1GP8f4PoimhKR/OkbdCJBKOwiQSjsIkEo7CJBKOwiQZi7lzeZ2TDw39nDKcDnpU2epj7OpD7OdK71cZm7N/z2WqlhP2Nis5q7V7syufpQHwH70Mt4kSAUdpEguhn2dV2ceyT1cSb1caZx00fX3rOLSLn0Ml4kiK6E3cyWmNk+M/vEzLp27jozO2hmg2b2oZnVSpx3vZkNmdnuEWOln8Az0cfDZvZZtk0+NLObSuhjhpn9u5ntzU5q+rfZeKnbpEkfpW6Twk7y6u6l/gDnA78FvgtcAOwEZpfdR9bLQWBKF+b9HjAf2D1i7DFgVXZ/FfAPXerjYeCBkrfHdGB+dr8P2A/MLnubNOmj1G0CGDApuz8R2A5c3en26MaefSHwibsfcPffA7+gfvLKMNz9TeCLs4ZLP4Fnoo/SufsRd9+R3T8O7AUupuRt0qSPUnld7id57UbYLwZ+N+LxIbqwQTMO/NrM3jezgS71cFovncDzPjPblb3ML/V6AGbWT/38CV09qelZfUDJ26SIk7x2I+zWYKxbhwSudff5wI3Aj83se13qo5c8C1xO/RoBR4Any5rYzCYBLwEr3f1YWfO20Efp28Q7OMlrSjfCfgiYMeLxJcDhLvSBux/OboeAV6i/xeiWlk7gWTR3P5r9op0CnqOkbWJmE6kH7AV3fzkbLn2bNOqjW9skm/srxniS15RuhP09YKaZfcfMLgB+QP3klaUys2+ZWd/p+8ANwO7maxWqJ07gefqXKXMrJWwTMzPgeWCvuz81olTqNkn1UfY2Kewkr2V9wnjWp403Uf+k87fA33Wph+9SPxKwE9hTZh/AJuovB/+P+iudu4E/p34ZrY+z28ld6uOfgUFgV/bLNb2EPq6j/lZuF/Bh9nNT2dukSR+lbhPgSuCDbL7dwN9n4x1tD32DTiQIfYNOJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSSI/wfbwut+trkizQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,0,:,:].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b424614-729f-441d-87b1-56187400995b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 9, 32, 32])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,0,:,:].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65c2b27d-fb1c-4d69-bdd5-0fb51cf6a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(device, epoch, train_loader, model, optimizer):\n",
    "\tmodel.train()\n",
    "\t# Iterate over batches\n",
    "\tfor batch_idx, (X, y) in enumerate(train_loader):\n",
    "\t\t# Batch start time\n",
    "\t\tstart_time = time.time()\n",
    "\t\t# Use sequence indices to slice corresponding images\n",
    "\t\t#x_seq = all_imgs[seq_ind,:,:]\n",
    "\t\tx_seq = X.float()\n",
    "\t\t#print(\"x_seq.shape =\",x_seq.shape)\n",
    "\t\t# Load data to device\n",
    "\t\tx_seq = x_seq.to(device)\n",
    "\t\t#y = torch.nn.functional.one_hot(y,num_classes=4)\n",
    "\t\t#print(\"y =\",y)\n",
    "\t\ty = y.to(device)\n",
    "\t\t# Zero out gradients for optimizer \n",
    "\t\toptimizer.zero_grad()\n",
    "\t\t# Run model \n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\ty_pred_linear, y_pred, const_loss = model(x_seq, device)\n",
    "\t\telse:\n",
    "\t\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t'''\n",
    "\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t# Loss\n",
    "\t\tloss_fn = nn.CrossEntropyLoss()\n",
    "\t\tloss = loss_fn(y_pred_linear, y)\n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\tloss += const_loss\n",
    "\t\t'''\n",
    "\t\t# Update model\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t# Batch duration\n",
    "\t\tend_time = time.time()\n",
    "\t\tbatch_dur = end_time - start_time\n",
    "\t\t# Report prgoress\n",
    "\t\t#if batch_idx % args.log_interval == 0:\n",
    "\t\tif batch_idx % 10 == 0:\n",
    "\t\t\t# Accuracy\n",
    "\t\t\tacc = torch.eq(y_pred, y).float().mean().item() * 100.0\n",
    "\t\t\t# Report \t\n",
    "\t\t\tlog.info('[Epoch: ' + str(epoch) + '] ' + \\\n",
    "\t\t\t\t\t '[Batch: ' + str(batch_idx) + ' of ' + str(len(train_loader)) + '] ' + \\\n",
    "\t\t\t\t\t '[Loss = ' + '{:.4f}'.format(loss.item()) + '] ' + \\\n",
    "\t\t\t\t\t '[Accuracy = ' + '{:.2f}'.format(acc) + '] ' + \\\n",
    "\t\t\t\t\t '[' + '{:.3f}'.format(batch_dur) + ' sec/batch]')\n",
    "\t\t\t# Save progress to file\n",
    "\t\t\t'''\n",
    "\t\t\ttrain_prog_f.write(str(batch_idx) + ' ' +\\\n",
    "\t\t\t\t\t\t\t   '{:.4f}'.format(loss.item()) + ' ' + \\\n",
    "\t\t\t\t\t\t\t   '{:.2f}'.format(acc) + '\\n')\n",
    "\t\t\t'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6444ff38-679c-47c2-85ac-8ca5b1e108f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(device, epoch, test_loader, model):\n",
    "\tlog.info('Evaluating on test set...')\n",
    "\t# Set to eval mode\n",
    "\tmodel.eval()\n",
    "\t# Iterate over batches\n",
    "\tall_acc = []\n",
    "\tall_loss = []\n",
    "\tfor batch_idx, (X, y) in enumerate(test_loader):\n",
    "\t\t# Use sequence indices to slice corresponding images\n",
    "\t\tx_seq = X.float()\n",
    "\t\t# Load data to device\n",
    "\t\tx_seq = x_seq.to(device)\n",
    "\t\t#y = torch.nn.functional.one_hot(y,num_classes=4)\n",
    "\t\ty = y.to(device)\n",
    "\t\t# Run model \n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\ty_pred_linear, y_pred, const_loss = model(x_seq, device)\n",
    "\t\telse:\n",
    "\t\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t'''\n",
    "\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t# Loss\n",
    "\t\tloss_fn = nn.CrossEntropyLoss()\n",
    "\t\tloss = loss_fn(y_pred_linear, y)\n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\tloss += const_loss\n",
    "\t\t'''\n",
    "\t\tall_loss.append(loss.item())\n",
    "\t\t# Accuracy\n",
    "\t\tacc = torch.eq(y_pred, y).float().mean().item() * 100.0\n",
    "\t\tall_acc.append(acc)\n",
    "\t\t# Report progress\n",
    "\t\tlog.info('[Batch: ' + str(batch_idx) + ' of ' + str(len(test_loader)) + ']')\n",
    "\t# Report overall test performance\n",
    "\tavg_loss = np.mean(all_loss)\n",
    "\tavg_acc = np.mean(all_acc)\n",
    "\tlog.info('[Summary] ' + \\\n",
    "\t\t\t '[Loss = ' + '{:.4f}'.format(avg_loss) + '] ' + \\\n",
    "\t\t\t '[Accuracy = ' + '{:.2f}'.format(avg_acc) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27f64254-c0b3-4303-a9a7-953256157938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 01:59:20,373] Building encoder...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:20,374] Building convolutional encoder...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:20,374] Conv layers...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:20,376] FC layers...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:20,380] Building LSTM and output layers...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:20,458] [Epoch: 1] [Batch: 0 of 313] [Loss = 1.3840] [Accuracy = 25.00] [0.031 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 01:59:20,734] [Epoch: 1] [Batch: 10 of 313] [Loss = 1.3826] [Accuracy = 28.12] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:21,016] [Epoch: 1] [Batch: 20 of 313] [Loss = 1.3705] [Accuracy = 50.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:21,300] [Epoch: 1] [Batch: 30 of 313] [Loss = 1.3541] [Accuracy = 31.25] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:21,579] [Epoch: 1] [Batch: 40 of 313] [Loss = 1.2980] [Accuracy = 53.12] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:21,876] [Epoch: 1] [Batch: 50 of 313] [Loss = 0.6089] [Accuracy = 78.12] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:22,168] [Epoch: 1] [Batch: 60 of 313] [Loss = 0.1894] [Accuracy = 93.75] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:22,452] [Epoch: 1] [Batch: 70 of 313] [Loss = 0.1204] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:22,740] [Epoch: 1] [Batch: 80 of 313] [Loss = 0.0471] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:23,019] [Epoch: 1] [Batch: 90 of 313] [Loss = 0.0772] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:23,311] [Epoch: 1] [Batch: 100 of 313] [Loss = 0.0045] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:23,600] [Epoch: 1] [Batch: 110 of 313] [Loss = 0.0021] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:23,899] [Epoch: 1] [Batch: 120 of 313] [Loss = 0.0026] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:24,190] [Epoch: 1] [Batch: 130 of 313] [Loss = 0.0014] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:24,467] [Epoch: 1] [Batch: 140 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:24,740] [Epoch: 1] [Batch: 150 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:25,015] [Epoch: 1] [Batch: 160 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:25,308] [Epoch: 1] [Batch: 170 of 313] [Loss = 0.0013] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:25,600] [Epoch: 1] [Batch: 180 of 313] [Loss = 0.0007] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:25,883] [Epoch: 1] [Batch: 190 of 313] [Loss = 0.0004] [Accuracy = 100.00] [0.032 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:26,162] [Epoch: 1] [Batch: 200 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:26,451] [Epoch: 1] [Batch: 210 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:26,741] [Epoch: 1] [Batch: 220 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:27,023] [Epoch: 1] [Batch: 230 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:27,323] [Epoch: 1] [Batch: 240 of 313] [Loss = 0.0018] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:27,613] [Epoch: 1] [Batch: 250 of 313] [Loss = 0.2758] [Accuracy = 96.88] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:27,901] [Epoch: 1] [Batch: 260 of 313] [Loss = 0.0131] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:28,187] [Epoch: 1] [Batch: 270 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:28,459] [Epoch: 1] [Batch: 280 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:28,740] [Epoch: 1] [Batch: 290 of 313] [Loss = 0.0014] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:29,036] [Epoch: 1] [Batch: 300 of 313] [Loss = 0.0225] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:29,326] [Epoch: 1] [Batch: 310 of 313] [Loss = 0.0029] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:29,415] [Epoch: 2] [Batch: 0 of 313] [Loss = 0.0006] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 01:59:29,697] [Epoch: 2] [Batch: 10 of 313] [Loss = 0.0072] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:29,994] [Epoch: 2] [Batch: 20 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:30,276] [Epoch: 2] [Batch: 30 of 313] [Loss = 0.0006] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:30,563] [Epoch: 2] [Batch: 40 of 313] [Loss = 0.0004] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:30,866] [Epoch: 2] [Batch: 50 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.034 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:31,168] [Epoch: 2] [Batch: 60 of 313] [Loss = 0.0016] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:31,451] [Epoch: 2] [Batch: 70 of 313] [Loss = 0.1879] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:31,735] [Epoch: 2] [Batch: 80 of 313] [Loss = 0.0033] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:32,021] [Epoch: 2] [Batch: 90 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.032 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:32,307] [Epoch: 2] [Batch: 100 of 313] [Loss = 0.0027] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:32,597] [Epoch: 2] [Batch: 110 of 313] [Loss = 0.0029] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:32,896] [Epoch: 2] [Batch: 120 of 313] [Loss = 0.0014] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:33,159] [Epoch: 2] [Batch: 130 of 313] [Loss = 0.0026] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:33,443] [Epoch: 2] [Batch: 140 of 313] [Loss = 0.0022] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:33,740] [Epoch: 2] [Batch: 150 of 313] [Loss = 0.0027] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:34,032] [Epoch: 2] [Batch: 160 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:34,320] [Epoch: 2] [Batch: 170 of 313] [Loss = 0.0028] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:34,601] [Epoch: 2] [Batch: 180 of 313] [Loss = 0.0030] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:34,881] [Epoch: 2] [Batch: 190 of 313] [Loss = 0.0037] [Accuracy = 100.00] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:35,177] [Epoch: 2] [Batch: 200 of 313] [Loss = 0.0053] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:35,471] [Epoch: 2] [Batch: 210 of 313] [Loss = 0.2429] [Accuracy = 96.88] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:35,752] [Epoch: 2] [Batch: 220 of 313] [Loss = 0.0361] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:36,023] [Epoch: 2] [Batch: 230 of 313] [Loss = 0.0078] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:36,301] [Epoch: 2] [Batch: 240 of 313] [Loss = 0.0018] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:36,579] [Epoch: 2] [Batch: 250 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:36,863] [Epoch: 2] [Batch: 260 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:37,144] [Epoch: 2] [Batch: 270 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:37,421] [Epoch: 2] [Batch: 280 of 313] [Loss = 0.0014] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:37,693] [Epoch: 2] [Batch: 290 of 313] [Loss = 0.0004] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:37,967] [Epoch: 2] [Batch: 300 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:38,238] [Epoch: 2] [Batch: 310 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:38,324] [Epoch: 3] [Batch: 0 of 313] [Loss = 0.0007] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 01:59:38,598] [Epoch: 3] [Batch: 10 of 313] [Loss = 0.0004] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:38,854] [Epoch: 3] [Batch: 20 of 313] [Loss = 0.0049] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:39,130] [Epoch: 3] [Batch: 30 of 313] [Loss = 0.0183] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:39,395] [Epoch: 3] [Batch: 40 of 313] [Loss = 0.0714] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:39,652] [Epoch: 3] [Batch: 50 of 313] [Loss = 0.0602] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:39,921] [Epoch: 3] [Batch: 60 of 313] [Loss = 0.1323] [Accuracy = 96.88] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:40,164] [Epoch: 3] [Batch: 70 of 313] [Loss = 0.0076] [Accuracy = 100.00] [0.019 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:40,391] [Epoch: 3] [Batch: 80 of 313] [Loss = 0.0102] [Accuracy = 100.00] [0.019 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:40,635] [Epoch: 3] [Batch: 90 of 313] [Loss = 0.0037] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:40,873] [Epoch: 3] [Batch: 100 of 313] [Loss = 0.0077] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:41,105] [Epoch: 3] [Batch: 110 of 313] [Loss = 0.0290] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:41,337] [Epoch: 3] [Batch: 120 of 313] [Loss = 0.0399] [Accuracy = 96.88] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:41,566] [Epoch: 3] [Batch: 130 of 313] [Loss = 0.3585] [Accuracy = 84.38] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:41,803] [Epoch: 3] [Batch: 140 of 313] [Loss = 0.1632] [Accuracy = 93.75] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:42,035] [Epoch: 3] [Batch: 150 of 313] [Loss = 0.0112] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:42,264] [Epoch: 3] [Batch: 160 of 313] [Loss = 0.2541] [Accuracy = 96.88] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:42,495] [Epoch: 3] [Batch: 170 of 313] [Loss = 0.1540] [Accuracy = 93.75] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:42,736] [Epoch: 3] [Batch: 180 of 313] [Loss = 0.0399] [Accuracy = 100.00] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:42,976] [Epoch: 3] [Batch: 190 of 313] [Loss = 0.1221] [Accuracy = 93.75] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:43,252] [Epoch: 3] [Batch: 200 of 313] [Loss = 0.0433] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:43,521] [Epoch: 3] [Batch: 210 of 313] [Loss = 0.0182] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:43,771] [Epoch: 3] [Batch: 220 of 313] [Loss = 0.0058] [Accuracy = 100.00] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:44,052] [Epoch: 3] [Batch: 230 of 313] [Loss = 0.0427] [Accuracy = 100.00] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:44,324] [Epoch: 3] [Batch: 240 of 313] [Loss = 0.0073] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:44,584] [Epoch: 3] [Batch: 250 of 313] [Loss = 0.2416] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:44,850] [Epoch: 3] [Batch: 260 of 313] [Loss = 0.0047] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:45,122] [Epoch: 3] [Batch: 270 of 313] [Loss = 0.0251] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:45,394] [Epoch: 3] [Batch: 280 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:45,662] [Epoch: 3] [Batch: 290 of 313] [Loss = 0.0007] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:45,939] [Epoch: 3] [Batch: 300 of 313] [Loss = 0.0006] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:46,208] [Epoch: 3] [Batch: 310 of 313] [Loss = 0.0030] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:46,291] [Epoch: 4] [Batch: 0 of 313] [Loss = 0.0057] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 01:59:46,551] [Epoch: 4] [Batch: 10 of 313] [Loss = 0.1450] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:46,818] [Epoch: 4] [Batch: 20 of 313] [Loss = 0.0112] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:47,092] [Epoch: 4] [Batch: 30 of 313] [Loss = 0.1947] [Accuracy = 96.88] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:47,370] [Epoch: 4] [Batch: 40 of 313] [Loss = 0.0087] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:47,650] [Epoch: 4] [Batch: 50 of 313] [Loss = 0.0022] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:47,927] [Epoch: 4] [Batch: 60 of 313] [Loss = 0.1154] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:48,221] [Epoch: 4] [Batch: 70 of 313] [Loss = 0.0139] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:48,508] [Epoch: 4] [Batch: 80 of 313] [Loss = 0.0065] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:48,791] [Epoch: 4] [Batch: 90 of 313] [Loss = 0.0030] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:49,084] [Epoch: 4] [Batch: 100 of 313] [Loss = 0.0678] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:49,380] [Epoch: 4] [Batch: 110 of 313] [Loss = 0.0155] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:49,680] [Epoch: 4] [Batch: 120 of 313] [Loss = 0.0200] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:49,959] [Epoch: 4] [Batch: 130 of 313] [Loss = 0.1187] [Accuracy = 93.75] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:50,246] [Epoch: 4] [Batch: 140 of 313] [Loss = 0.2921] [Accuracy = 87.50] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:50,540] [Epoch: 4] [Batch: 150 of 313] [Loss = 0.1228] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:50,844] [Epoch: 4] [Batch: 160 of 313] [Loss = 0.0117] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:51,127] [Epoch: 4] [Batch: 170 of 313] [Loss = 0.0031] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:51,406] [Epoch: 4] [Batch: 180 of 313] [Loss = 0.0060] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:51,703] [Epoch: 4] [Batch: 190 of 313] [Loss = 0.0369] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:51,991] [Epoch: 4] [Batch: 200 of 313] [Loss = 0.0211] [Accuracy = 100.00] [0.032 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:52,272] [Epoch: 4] [Batch: 210 of 313] [Loss = 0.0828] [Accuracy = 96.88] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:52,557] [Epoch: 4] [Batch: 220 of 313] [Loss = 0.1798] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:52,843] [Epoch: 4] [Batch: 230 of 313] [Loss = 0.0047] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:53,144] [Epoch: 4] [Batch: 240 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:53,421] [Epoch: 4] [Batch: 250 of 313] [Loss = 0.0114] [Accuracy = 100.00] [0.020 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:53,712] [Epoch: 4] [Batch: 260 of 313] [Loss = 0.1263] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:54,001] [Epoch: 4] [Batch: 270 of 313] [Loss = 0.0109] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:54,284] [Epoch: 4] [Batch: 280 of 313] [Loss = 0.0076] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:54,552] [Epoch: 4] [Batch: 290 of 313] [Loss = 0.0003] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:54,840] [Epoch: 4] [Batch: 300 of 313] [Loss = 0.0003] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:55,128] [Epoch: 4] [Batch: 310 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:55,211] [Epoch: 5] [Batch: 0 of 313] [Loss = 0.2376] [Accuracy = 96.88] [0.030 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 01:59:55,490] [Epoch: 5] [Batch: 10 of 313] [Loss = 0.1524] [Accuracy = 96.88] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:55,776] [Epoch: 5] [Batch: 20 of 313] [Loss = 0.1582] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:56,054] [Epoch: 5] [Batch: 30 of 313] [Loss = 0.0089] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:56,335] [Epoch: 5] [Batch: 40 of 313] [Loss = 0.0041] [Accuracy = 100.00] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:56,565] [Epoch: 5] [Batch: 50 of 313] [Loss = 0.0092] [Accuracy = 100.00] [0.019 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:56,795] [Epoch: 5] [Batch: 60 of 313] [Loss = 0.0029] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:57,060] [Epoch: 5] [Batch: 70 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:57,351] [Epoch: 5] [Batch: 80 of 313] [Loss = 0.0006] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:57,648] [Epoch: 5] [Batch: 90 of 313] [Loss = 0.0019] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:57,929] [Epoch: 5] [Batch: 100 of 313] [Loss = 0.0459] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:58,216] [Epoch: 5] [Batch: 110 of 313] [Loss = 0.0016] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:58,497] [Epoch: 5] [Batch: 120 of 313] [Loss = 0.0004] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:58,796] [Epoch: 5] [Batch: 130 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:59,080] [Epoch: 5] [Batch: 140 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:59,357] [Epoch: 5] [Batch: 150 of 313] [Loss = 0.0030] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:59,631] [Epoch: 5] [Batch: 160 of 313] [Loss = 0.0013] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:59:59,914] [Epoch: 5] [Batch: 170 of 313] [Loss = 0.0594] [Accuracy = 96.88] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:00,212] [Epoch: 5] [Batch: 180 of 313] [Loss = 0.0031] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:00,498] [Epoch: 5] [Batch: 190 of 313] [Loss = 0.0027] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:00,795] [Epoch: 5] [Batch: 200 of 313] [Loss = 0.0074] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:01,087] [Epoch: 5] [Batch: 210 of 313] [Loss = 0.1086] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:01,382] [Epoch: 5] [Batch: 220 of 313] [Loss = 0.0038] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:01,671] [Epoch: 5] [Batch: 230 of 313] [Loss = 0.0029] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:01,973] [Epoch: 5] [Batch: 240 of 313] [Loss = 0.0782] [Accuracy = 96.88] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:02,274] [Epoch: 5] [Batch: 250 of 313] [Loss = 0.0244] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:02,568] [Epoch: 5] [Batch: 260 of 313] [Loss = 0.0007] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:02,847] [Epoch: 5] [Batch: 270 of 313] [Loss = 0.0021] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:03,122] [Epoch: 5] [Batch: 280 of 313] [Loss = 0.0108] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:03,415] [Epoch: 5] [Batch: 290 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:03,682] [Epoch: 5] [Batch: 300 of 313] [Loss = 0.0003] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:03,968] [Epoch: 5] [Batch: 310 of 313] [Loss = 0.0042] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:04,053] [Epoch: 6] [Batch: 0 of 313] [Loss = 0.0016] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 02:00:04,346] [Epoch: 6] [Batch: 10 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:04,626] [Epoch: 6] [Batch: 20 of 313] [Loss = 0.1169] [Accuracy = 93.75] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:04,919] [Epoch: 6] [Batch: 30 of 313] [Loss = 0.0074] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:05,200] [Epoch: 6] [Batch: 40 of 313] [Loss = 0.0942] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:05,482] [Epoch: 6] [Batch: 50 of 313] [Loss = 0.0038] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:05,761] [Epoch: 6] [Batch: 60 of 313] [Loss = 0.0038] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:06,048] [Epoch: 6] [Batch: 70 of 313] [Loss = 0.0018] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:06,347] [Epoch: 6] [Batch: 80 of 313] [Loss = 0.0532] [Accuracy = 96.88] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:06,640] [Epoch: 6] [Batch: 90 of 313] [Loss = 0.1447] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:06,941] [Epoch: 6] [Batch: 100 of 313] [Loss = 0.0107] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:07,241] [Epoch: 6] [Batch: 110 of 313] [Loss = 0.0219] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:07,528] [Epoch: 6] [Batch: 120 of 313] [Loss = 0.1216] [Accuracy = 96.88] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:07,816] [Epoch: 6] [Batch: 130 of 313] [Loss = 0.0294] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:08,108] [Epoch: 6] [Batch: 140 of 313] [Loss = 0.0265] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:08,387] [Epoch: 6] [Batch: 150 of 313] [Loss = 0.0067] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:08,684] [Epoch: 6] [Batch: 160 of 313] [Loss = 0.0073] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:08,967] [Epoch: 6] [Batch: 170 of 313] [Loss = 0.0949] [Accuracy = 96.88] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:09,260] [Epoch: 6] [Batch: 180 of 313] [Loss = 0.0086] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:09,537] [Epoch: 6] [Batch: 190 of 313] [Loss = 0.0212] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:09,828] [Epoch: 6] [Batch: 200 of 313] [Loss = 0.0021] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:10,127] [Epoch: 6] [Batch: 210 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:10,423] [Epoch: 6] [Batch: 220 of 313] [Loss = 0.0031] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:10,719] [Epoch: 6] [Batch: 230 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:11,004] [Epoch: 6] [Batch: 240 of 313] [Loss = 0.0035] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:11,300] [Epoch: 6] [Batch: 250 of 313] [Loss = 0.1665] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:11,582] [Epoch: 6] [Batch: 260 of 313] [Loss = 0.0085] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:11,871] [Epoch: 6] [Batch: 270 of 313] [Loss = 0.0016] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:12,161] [Epoch: 6] [Batch: 280 of 313] [Loss = 0.0107] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:12,450] [Epoch: 6] [Batch: 290 of 313] [Loss = 0.0060] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:12,735] [Epoch: 6] [Batch: 300 of 313] [Loss = 0.0289] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:13,030] [Epoch: 6] [Batch: 310 of 313] [Loss = 0.0497] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:13,120] [Epoch: 7] [Batch: 0 of 313] [Loss = 0.0077] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 02:00:13,424] [Epoch: 7] [Batch: 10 of 313] [Loss = 0.0046] [Accuracy = 100.00] [0.032 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:13,727] [Epoch: 7] [Batch: 20 of 313] [Loss = 0.0069] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:14,026] [Epoch: 7] [Batch: 30 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:14,317] [Epoch: 7] [Batch: 40 of 313] [Loss = 0.0072] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:14,600] [Epoch: 7] [Batch: 50 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:14,851] [Epoch: 7] [Batch: 60 of 313] [Loss = 0.1433] [Accuracy = 96.88] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:15,125] [Epoch: 7] [Batch: 70 of 313] [Loss = 0.0014] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:15,416] [Epoch: 7] [Batch: 80 of 313] [Loss = 0.0026] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:15,703] [Epoch: 7] [Batch: 90 of 313] [Loss = 0.0507] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:15,999] [Epoch: 7] [Batch: 100 of 313] [Loss = 0.0868] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:16,281] [Epoch: 7] [Batch: 110 of 313] [Loss = 0.0369] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:16,568] [Epoch: 7] [Batch: 120 of 313] [Loss = 0.0020] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:16,829] [Epoch: 7] [Batch: 130 of 313] [Loss = 0.0004] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:17,108] [Epoch: 7] [Batch: 140 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:17,388] [Epoch: 7] [Batch: 150 of 313] [Loss = 0.0004] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:17,656] [Epoch: 7] [Batch: 160 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:17,941] [Epoch: 7] [Batch: 170 of 313] [Loss = 0.0003] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:18,233] [Epoch: 7] [Batch: 180 of 313] [Loss = 0.0008] [Accuracy = 100.00] [0.033 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:18,534] [Epoch: 7] [Batch: 190 of 313] [Loss = 0.0003] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:18,845] [Epoch: 7] [Batch: 200 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:19,140] [Epoch: 7] [Batch: 210 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:19,439] [Epoch: 7] [Batch: 220 of 313] [Loss = 0.0006] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:19,727] [Epoch: 7] [Batch: 230 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:20,025] [Epoch: 7] [Batch: 240 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:20,321] [Epoch: 7] [Batch: 250 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:20,621] [Epoch: 7] [Batch: 260 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:20,912] [Epoch: 7] [Batch: 270 of 313] [Loss = 0.0008] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:21,200] [Epoch: 7] [Batch: 280 of 313] [Loss = 0.0178] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:21,488] [Epoch: 7] [Batch: 290 of 313] [Loss = 0.0050] [Accuracy = 100.00] [0.034 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:21,780] [Epoch: 7] [Batch: 300 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:22,087] [Epoch: 7] [Batch: 310 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:22,184] [Epoch: 8] [Batch: 0 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 02:00:22,476] [Epoch: 8] [Batch: 10 of 313] [Loss = 0.0003] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:22,766] [Epoch: 8] [Batch: 20 of 313] [Loss = 0.1831] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:23,064] [Epoch: 8] [Batch: 30 of 313] [Loss = 0.0026] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:23,362] [Epoch: 8] [Batch: 40 of 313] [Loss = 0.0158] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:23,669] [Epoch: 8] [Batch: 50 of 313] [Loss = 0.0496] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:23,964] [Epoch: 8] [Batch: 60 of 313] [Loss = 0.1329] [Accuracy = 96.88] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:24,263] [Epoch: 8] [Batch: 70 of 313] [Loss = 0.0030] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:24,578] [Epoch: 8] [Batch: 80 of 313] [Loss = 0.0556] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:24,869] [Epoch: 8] [Batch: 90 of 313] [Loss = 0.0033] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:25,171] [Epoch: 8] [Batch: 100 of 313] [Loss = 0.0189] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:25,467] [Epoch: 8] [Batch: 110 of 313] [Loss = 0.0008] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:25,766] [Epoch: 8] [Batch: 120 of 313] [Loss = 0.0162] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:26,070] [Epoch: 8] [Batch: 130 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.033 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:26,361] [Epoch: 8] [Batch: 140 of 313] [Loss = 0.0014] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:26,667] [Epoch: 8] [Batch: 150 of 313] [Loss = 0.0026] [Accuracy = 100.00] [0.032 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:26,958] [Epoch: 8] [Batch: 160 of 313] [Loss = 0.0037] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:27,251] [Epoch: 8] [Batch: 170 of 313] [Loss = 0.0117] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:27,547] [Epoch: 8] [Batch: 180 of 313] [Loss = 0.0040] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:27,849] [Epoch: 8] [Batch: 190 of 313] [Loss = 0.0170] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:28,140] [Epoch: 8] [Batch: 200 of 313] [Loss = 0.2491] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:28,444] [Epoch: 8] [Batch: 210 of 313] [Loss = 0.0047] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:28,749] [Epoch: 8] [Batch: 220 of 313] [Loss = 0.0067] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:29,053] [Epoch: 8] [Batch: 230 of 313] [Loss = 0.0735] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:29,348] [Epoch: 8] [Batch: 240 of 313] [Loss = 0.0106] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:29,642] [Epoch: 8] [Batch: 250 of 313] [Loss = 0.0036] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:29,943] [Epoch: 8] [Batch: 260 of 313] [Loss = 0.1018] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:30,240] [Epoch: 8] [Batch: 270 of 313] [Loss = 0.0054] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:30,523] [Epoch: 8] [Batch: 280 of 313] [Loss = 0.1716] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:30,812] [Epoch: 8] [Batch: 290 of 313] [Loss = 0.0050] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:31,072] [Epoch: 8] [Batch: 300 of 313] [Loss = 0.0043] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:31,336] [Epoch: 8] [Batch: 310 of 313] [Loss = 0.0060] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:31,421] [Epoch: 9] [Batch: 0 of 313] [Loss = 0.0922] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 02:00:31,691] [Epoch: 9] [Batch: 10 of 313] [Loss = 0.0878] [Accuracy = 96.88] [0.020 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:31,990] [Epoch: 9] [Batch: 20 of 313] [Loss = 0.0068] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:32,279] [Epoch: 9] [Batch: 30 of 313] [Loss = 0.0021] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:32,568] [Epoch: 9] [Batch: 40 of 313] [Loss = 0.1478] [Accuracy = 93.75] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:32,864] [Epoch: 9] [Batch: 50 of 313] [Loss = 0.0567] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:33,156] [Epoch: 9] [Batch: 60 of 313] [Loss = 0.0555] [Accuracy = 96.88] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:33,450] [Epoch: 9] [Batch: 70 of 313] [Loss = 0.0468] [Accuracy = 96.88] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:33,748] [Epoch: 9] [Batch: 80 of 313] [Loss = 0.1942] [Accuracy = 93.75] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:34,049] [Epoch: 9] [Batch: 90 of 313] [Loss = 0.0167] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:34,328] [Epoch: 9] [Batch: 100 of 313] [Loss = 0.0020] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:34,602] [Epoch: 9] [Batch: 110 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:34,892] [Epoch: 9] [Batch: 120 of 313] [Loss = 0.0006] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:35,180] [Epoch: 9] [Batch: 130 of 313] [Loss = 0.0996] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:35,460] [Epoch: 9] [Batch: 140 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:35,739] [Epoch: 9] [Batch: 150 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:36,028] [Epoch: 9] [Batch: 160 of 313] [Loss = 0.0032] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:36,311] [Epoch: 9] [Batch: 170 of 313] [Loss = 0.0052] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:36,576] [Epoch: 9] [Batch: 180 of 313] [Loss = 0.2028] [Accuracy = 96.88] [0.019 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:36,806] [Epoch: 9] [Batch: 190 of 313] [Loss = 0.0023] [Accuracy = 100.00] [0.021 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:37,082] [Epoch: 9] [Batch: 200 of 313] [Loss = 0.0030] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:37,360] [Epoch: 9] [Batch: 210 of 313] [Loss = 0.0019] [Accuracy = 100.00] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:37,579] [Epoch: 9] [Batch: 220 of 313] [Loss = 0.0023] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:37,796] [Epoch: 9] [Batch: 230 of 313] [Loss = 0.0006] [Accuracy = 100.00] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:38,023] [Epoch: 9] [Batch: 240 of 313] [Loss = 0.0006] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:38,247] [Epoch: 9] [Batch: 250 of 313] [Loss = 0.0008] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:38,471] [Epoch: 9] [Batch: 260 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:38,688] [Epoch: 9] [Batch: 270 of 313] [Loss = 0.0055] [Accuracy = 100.00] [0.020 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:38,957] [Epoch: 9] [Batch: 280 of 313] [Loss = 0.0025] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:39,251] [Epoch: 9] [Batch: 290 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:39,536] [Epoch: 9] [Batch: 300 of 313] [Loss = 0.0397] [Accuracy = 96.88] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:39,833] [Epoch: 9] [Batch: 310 of 313] [Loss = 0.0055] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:39,928] [Epoch: 10] [Batch: 0 of 313] [Loss = 0.0066] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 02:00:40,223] [Epoch: 10] [Batch: 10 of 313] [Loss = 0.1446] [Accuracy = 96.88] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:40,480] [Epoch: 10] [Batch: 20 of 313] [Loss = 0.0121] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:40,780] [Epoch: 10] [Batch: 30 of 313] [Loss = 0.0032] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:41,080] [Epoch: 10] [Batch: 40 of 313] [Loss = 0.0037] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:41,383] [Epoch: 10] [Batch: 50 of 313] [Loss = 0.0744] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:41,675] [Epoch: 10] [Batch: 60 of 313] [Loss = 0.0133] [Accuracy = 100.00] [0.032 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:41,973] [Epoch: 10] [Batch: 70 of 313] [Loss = 0.0064] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:42,274] [Epoch: 10] [Batch: 80 of 313] [Loss = 0.0320] [Accuracy = 96.88] [0.033 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:42,559] [Epoch: 10] [Batch: 90 of 313] [Loss = 0.1744] [Accuracy = 96.88] [0.025 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:42,859] [Epoch: 10] [Batch: 100 of 313] [Loss = 0.0153] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:43,148] [Epoch: 10] [Batch: 110 of 313] [Loss = 0.0091] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:43,435] [Epoch: 10] [Batch: 120 of 313] [Loss = 0.1034] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:43,735] [Epoch: 10] [Batch: 130 of 313] [Loss = 0.0589] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:44,027] [Epoch: 10] [Batch: 140 of 313] [Loss = 0.0005] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:44,312] [Epoch: 10] [Batch: 150 of 313] [Loss = 0.0069] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:44,600] [Epoch: 10] [Batch: 160 of 313] [Loss = 0.1513] [Accuracy = 96.88] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:44,884] [Epoch: 10] [Batch: 170 of 313] [Loss = 0.0045] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:45,161] [Epoch: 10] [Batch: 180 of 313] [Loss = 0.0933] [Accuracy = 96.88] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:45,468] [Epoch: 10] [Batch: 190 of 313] [Loss = 0.0130] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:45,768] [Epoch: 10] [Batch: 200 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:46,069] [Epoch: 10] [Batch: 210 of 313] [Loss = 0.1420] [Accuracy = 93.75] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:46,369] [Epoch: 10] [Batch: 220 of 313] [Loss = 0.1303] [Accuracy = 90.62] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:46,665] [Epoch: 10] [Batch: 230 of 313] [Loss = 0.1681] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:46,948] [Epoch: 10] [Batch: 240 of 313] [Loss = 0.0201] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:47,244] [Epoch: 10] [Batch: 250 of 313] [Loss = 0.1128] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:47,539] [Epoch: 10] [Batch: 260 of 313] [Loss = 0.0031] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:47,832] [Epoch: 10] [Batch: 270 of 313] [Loss = 0.0064] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:48,116] [Epoch: 10] [Batch: 280 of 313] [Loss = 0.0128] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:48,416] [Epoch: 10] [Batch: 290 of 313] [Loss = 0.1640] [Accuracy = 96.88] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:48,712] [Epoch: 10] [Batch: 300 of 313] [Loss = 0.0108] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,004] [Epoch: 10] [Batch: 310 of 313] [Loss = 0.0160] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,064] Evaluating on test set...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,077] [Batch: 0 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,090] [Batch: 1 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,099] [Batch: 2 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,109] [Batch: 3 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,118] [Batch: 4 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,128] [Batch: 5 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,138] [Batch: 6 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,148] [Batch: 7 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,157] [Batch: 8 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,167] [Batch: 9 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,177] [Batch: 10 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,186] [Batch: 11 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,196] [Batch: 12 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,205] [Batch: 13 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,215] [Batch: 14 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,224] [Batch: 15 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,234] [Batch: 16 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,244] [Batch: 17 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,253] [Batch: 18 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,263] [Batch: 19 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,272] [Batch: 20 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,282] [Batch: 21 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,291] [Batch: 22 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,301] [Batch: 23 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,311] [Batch: 24 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,320] [Batch: 25 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,330] [Batch: 26 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,339] [Batch: 27 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,349] [Batch: 28 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,358] [Batch: 29 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,368] [Batch: 30 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,377] [Batch: 31 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,387] [Batch: 32 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,396] [Batch: 33 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,406] [Batch: 34 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,415] [Batch: 35 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,425] [Batch: 36 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,434] [Batch: 37 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,444] [Batch: 38 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,453] [Batch: 39 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,462] [Batch: 40 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,472] [Batch: 41 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,482] [Batch: 42 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,491] [Batch: 43 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,501] [Batch: 44 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,510] [Batch: 45 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,520] [Batch: 46 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,529] [Batch: 47 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,539] [Batch: 48 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,548] [Batch: 49 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,558] [Batch: 50 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,567] [Batch: 51 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,577] [Batch: 52 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,586] [Batch: 53 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,596] [Batch: 54 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,605] [Batch: 55 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,614] [Batch: 56 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,624] [Batch: 57 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,633] [Batch: 58 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,643] [Batch: 59 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,652] [Batch: 60 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,662] [Batch: 61 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,672] [Batch: 62 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,682] [Batch: 63 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,692] [Batch: 64 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,701] [Batch: 65 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,710] [Batch: 66 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,720] [Batch: 67 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,729] [Batch: 68 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,739] [Batch: 69 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,748] [Batch: 70 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,758] [Batch: 71 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,768] [Batch: 72 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,777] [Batch: 73 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,787] [Batch: 74 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,796] [Batch: 75 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,806] [Batch: 76 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,815] [Batch: 77 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,825] [Batch: 78 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,834] [Batch: 79 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,844] [Batch: 80 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,853] [Batch: 81 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,862] [Batch: 82 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,872] [Batch: 83 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,881] [Batch: 84 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,891] [Batch: 85 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,900] [Batch: 86 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,910] [Batch: 87 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,919] [Batch: 88 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,928] [Batch: 89 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,938] [Batch: 90 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,947] [Batch: 91 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,957] [Batch: 92 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,966] [Batch: 93 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,976] [Batch: 94 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,985] [Batch: 95 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:49,994] [Batch: 96 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,004] [Batch: 97 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,013] [Batch: 98 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,023] [Batch: 99 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,032] [Batch: 100 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,041] [Batch: 101 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,051] [Batch: 102 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,060] [Batch: 103 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,070] [Batch: 104 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,079] [Batch: 105 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,089] [Batch: 106 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,098] [Batch: 107 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,107] [Batch: 108 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,117] [Batch: 109 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,126] [Batch: 110 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,135] [Batch: 111 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,145] [Batch: 112 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,154] [Batch: 113 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,164] [Batch: 114 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,173] [Batch: 115 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,183] [Batch: 116 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,192] [Batch: 117 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,202] [Batch: 118 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,211] [Batch: 119 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,220] [Batch: 120 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,230] [Batch: 121 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,239] [Batch: 122 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,249] [Batch: 123 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,258] [Batch: 124 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,267] [Batch: 125 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,277] [Batch: 126 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,286] [Batch: 127 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,296] [Batch: 128 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,305] [Batch: 129 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,314] [Batch: 130 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,324] [Batch: 131 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,333] [Batch: 132 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,342] [Batch: 133 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,352] [Batch: 134 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,361] [Batch: 135 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,371] [Batch: 136 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,380] [Batch: 137 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,389] [Batch: 138 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,399] [Batch: 139 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,408] [Batch: 140 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,418] [Batch: 141 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,427] [Batch: 142 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,437] [Batch: 143 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,446] [Batch: 144 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,455] [Batch: 145 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,465] [Batch: 146 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,474] [Batch: 147 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,483] [Batch: 148 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,493] [Batch: 149 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,502] [Batch: 150 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,511] [Batch: 151 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,521] [Batch: 152 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,530] [Batch: 153 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,540] [Batch: 154 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,549] [Batch: 155 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,558] [Batch: 156 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,568] [Batch: 157 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,577] [Batch: 158 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,587] [Batch: 159 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,597] [Batch: 160 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,607] [Batch: 161 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,616] [Batch: 162 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,626] [Batch: 163 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,636] [Batch: 164 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,646] [Batch: 165 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,655] [Batch: 166 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,665] [Batch: 167 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,675] [Batch: 168 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,685] [Batch: 169 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,695] [Batch: 170 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,704] [Batch: 171 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,714] [Batch: 172 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,724] [Batch: 173 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,734] [Batch: 174 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,743] [Batch: 175 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,753] [Batch: 176 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,762] [Batch: 177 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,771] [Batch: 178 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,781] [Batch: 179 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,790] [Batch: 180 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,800] [Batch: 181 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,809] [Batch: 182 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,819] [Batch: 183 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,828] [Batch: 184 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,837] [Batch: 185 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,847] [Batch: 186 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,856] [Batch: 187 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,865] [Batch: 188 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,875] [Batch: 189 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,884] [Batch: 190 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,893] [Batch: 191 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,903] [Batch: 192 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,912] [Batch: 193 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,921] [Batch: 194 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,931] [Batch: 195 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,940] [Batch: 196 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,950] [Batch: 197 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,959] [Batch: 198 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,968] [Batch: 199 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,978] [Batch: 200 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,987] [Batch: 201 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:50,996] [Batch: 202 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,006] [Batch: 203 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,021] [Batch: 204 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,031] [Batch: 205 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,040] [Batch: 206 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,049] [Batch: 207 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,059] [Batch: 208 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,068] [Batch: 209 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,077] [Batch: 210 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,087] [Batch: 211 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,096] [Batch: 212 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,105] [Batch: 213 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,115] [Batch: 214 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,124] [Batch: 215 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,134] [Batch: 216 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,143] [Batch: 217 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,153] [Batch: 218 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,162] [Batch: 219 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,171] [Batch: 220 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,181] [Batch: 221 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,190] [Batch: 222 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,199] [Batch: 223 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,209] [Batch: 224 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,218] [Batch: 225 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,228] [Batch: 226 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,237] [Batch: 227 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,246] [Batch: 228 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,256] [Batch: 229 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,265] [Batch: 230 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,275] [Batch: 231 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,284] [Batch: 232 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,293] [Batch: 233 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,303] [Batch: 234 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,312] [Batch: 235 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,322] [Batch: 236 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,331] [Batch: 237 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,341] [Batch: 238 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,350] [Batch: 239 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,359] [Batch: 240 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,369] [Batch: 241 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,378] [Batch: 242 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,388] [Batch: 243 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,397] [Batch: 244 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,407] [Batch: 245 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,416] [Batch: 246 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,425] [Batch: 247 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,435] [Batch: 248 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,444] [Batch: 249 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,453] [Batch: 250 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,463] [Batch: 251 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,472] [Batch: 252 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,482] [Batch: 253 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,491] [Batch: 254 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,501] [Batch: 255 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,510] [Batch: 256 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,519] [Batch: 257 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,529] [Batch: 258 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,538] [Batch: 259 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,547] [Batch: 260 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,557] [Batch: 261 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,566] [Batch: 262 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,576] [Batch: 263 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,585] [Batch: 264 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,594] [Batch: 265 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,604] [Batch: 266 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,613] [Batch: 267 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,623] [Batch: 268 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,632] [Batch: 269 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,641] [Batch: 270 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,651] [Batch: 271 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,660] [Batch: 272 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,670] [Batch: 273 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,679] [Batch: 274 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,689] [Batch: 275 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,698] [Batch: 276 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,707] [Batch: 277 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,717] [Batch: 278 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,726] [Batch: 279 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,735] [Batch: 280 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,745] [Batch: 281 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,754] [Batch: 282 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,764] [Batch: 283 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,773] [Batch: 284 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,783] [Batch: 285 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,792] [Batch: 286 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,801] [Batch: 287 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,811] [Batch: 288 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,820] [Batch: 289 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,830] [Batch: 290 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,839] [Batch: 291 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,849] [Batch: 292 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,858] [Batch: 293 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,867] [Batch: 294 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,877] [Batch: 295 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,886] [Batch: 296 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,896] [Batch: 297 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,905] [Batch: 298 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,914] [Batch: 299 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,924] [Batch: 300 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,933] [Batch: 301 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,943] [Batch: 302 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,952] [Batch: 303 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,962] [Batch: 304 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,971] [Batch: 305 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,980] [Batch: 306 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,990] [Batch: 307 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:51,999] [Batch: 308 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:52,009] [Batch: 309 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:52,018] [Batch: 310 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:52,028] [Batch: 311 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:52,037] [Batch: 312 of 313]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 02:00:52,037] [Summary] [Loss = 0.0432] [Accuracy = 98.85]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-4\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda:\" + str(0))\n",
    "model = Model().to(device)\n",
    "# Initialize the loss function\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(device, t+1, train_dataloader, model, optimizer)\n",
    "test_loop(device,t, test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb18591-ae59-4811-9cc5-c23bc0965e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
