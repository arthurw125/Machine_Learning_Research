{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07865754-05b1-4198-ae72-0139dc257fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from util import log\n",
    "from modules import *\n",
    "from dist3 import create_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a548cfc9-5c55-4130-99c5-946e4be00470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set,test_set = create_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae57d2c5-65be-457e-b50d-0fd3b445874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set['seq_ind'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b691aa-337d-4d57-8f63-ddafd99bf2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d442f1e-e39e-4894-bfe1-2929b893a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = training_set['seq_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a58126-f899-4505-a016-d5f74d8ed723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc03fbb9-b569-43be-803f-34d9ec6803dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916244aa-475e-426f-b0ce-abcc46e81591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "all_imgs = []\n",
    "n_shapes = 100\n",
    "for i in range(n_shapes):\n",
    "\timg_fname = '/home/asw3x/emergent_symbols/imgs/' + str(i) + '.png'\n",
    "\timg = torch.Tensor(np.array(Image.open(img_fname))) / 255.\n",
    "\tall_imgs.append(img)\n",
    "all_imgs = torch.stack(all_imgs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d87ce5-4d46-4361-88cc-8743100b04fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2aeff16-025d-4e7c-81ec-75837d0bff11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAUK0lEQVR4nO3de2xU5boG8OcVhS1SVCjFyq1bJfFQFCEjMYKCisD2EiRGkMhNjfUPIQoag5zkgCGSzYlA0G1IUBC2IIo3MCdy2Ip4LXAcKhQUlDsWCi2KygnhKPCeP2aRVFzv6syatWam/Z5fQjpdb7+uN4s+XdP5Zn1LVBVE1Pydl+8GiCg3GHYiRzDsRI5g2IkcwbATOYJhJ3LE+dkMFpGhAOYBaAHgFVX9e9DXFxcXa1lZWTa7pBgETb/u2LHDrJWUlJi19u3bZ9UThbNv3z4cPXpU/Gqhwy4iLQC8BOB2ADUAvhKR91X1W2tMWVkZkslk2F1STE6ePGnW+vXrZ9YmTpxo1saPH59NSxRSIpEwa9k8je8LYJeq7lHV3wC8AWBYFt+PiGKUTdg7Afihwec13jYiKkDZhN3v74I//fEnIhUikhSRZH19fRa7I6JsZBP2GgBdGnzeGcChc79IVReoakJVEx06dMhid0SUjWzC/hWA7iLyVxFpCeB+AO9H0xYRRS30q/GqekpEJgBYg9TU2yJV/Sayzhzw1FNPmbXu3bubtUcffTTSPiZPnmzWdu7cadZGjhwZaR9hvfLKK2btm2/8fyTnzp0bVzsFK6t5dlX9AMAHEfVCRDHiO+iIHMGwEzmCYSdyBMNO5AiGncgRWb0aT41bunSpWZs9e7ZZO3z4cKR9fP3112Zt/vz5Zm3GjBlm7cILL8yqp0xUVlaatUceecSsbdy4MY52miSe2YkcwbATOYJhJ3IEw07kCIadyBF8NT4Ce/fuNWtjxowxa5MmTTJrHTt2zKqnc4W98COXy0udOHHCrA0fPtysDRkyxKz17ds3q56aE57ZiRzBsBM5gmEncgTDTuQIhp3IEQw7kSM49RaBOXPmhBoXtPZbWNb01WuvvWaOKSoqMmudO3fOuqd0LVq0yKzV1dWZtaeffjqOdpodntmJHMGwEzmCYSdyBMNO5AiGncgRDDuRI7KaehORfQCOAzgN4JSq2neCbwZ++eUX3+3/+Mc/zDFBU1dxTGvt3r074zHl5eWR9xHGrFmzQo3jlW3piWKe/RZVPRrB9yGiGPFpPJEjsg27AviXiGwSkYooGiKieGT7NL6fqh4SkRIAH4rIDlX9rOEXeL8EKgCga9euWe6OiMLK6syuqoe8j3UA3gPwp1dKVHWBqiZUNdGhQ4dsdkdEWQgddhG5SESKzj4GMBjAtqgaI6JoZfM0viOA90Tk7Pd5XVX/O5KuCtSOHTsyHtOrV68YOrHt2rUr4zGdOnWKoRN/x44dM2s1NTVmLWiask2bNln15IrQYVfVPQBy+5NMRKFx6o3IEQw7kSMYdiJHMOxEjmDYiRzBBScz8N1332U8pkuXLjF0Ytu/f3/GYw4fPhxDJ/7CHEMA6NatW8SduIdndiJHMOxEjmDYiRzBsBM5gmEncgRfjc9AmFe6a2trY+jEdvHFF2c8prq62qydOnXKrJ1/fuY/Pj/88EPGY4DcH8fmiGd2Ikcw7ESOYNiJHMGwEzmCYSdyBMNO5AhOvWUgzOq469evN2tnzpwxa+edF+73cGlpacZjjh8/btY2bNhg1vr375/xvoqLizMeAwB79uwxaz/++KNZa9++faj9NUc8sxM5gmEncgTDTuQIhp3IEQw7kSMYdiJHNDr1JiKLANwFoE5Ve3rb2gF4E0AZgH0ARqiqfV+fZiLoFkSWuro6s1ZZWWnWwkxrAcDVV18dapxl2bJlZi1Mj5dffnk27fhatWqVWXvooYci319Tlc6ZfTGAoedsmwJgrap2B7DW+5yIClijYffut/7TOZuHAVjiPV4C4J6I+yKiiIX9m72jqtYCgPexJLqWiCgOsb9AJyIVIpIUkWR9fX3cuyMiQ9iwHxGRUgDwPpqvQqnqAlVNqGoizHvLiSgaYcP+PoBx3uNxAOyXQ4moIIiqBn+ByHIAAwEUAzgCYBqAlQBWAOgK4ACA+1T13Bfx/iSRSGgymcyy5fyxptE6duwY6vuNGzfOrC1evDjU97SUl5ebtW+//dasFRUVmbWgP8tatWrlu/306dPmmKBpuaApzD59+pi1TZs2mbXmKJFIIJlMil+t0Xl2VR1llG7Lqisiyim+g47IEQw7kSMYdiJHMOxEjmDYiRzBBSczUFLi/67gIUOGmGPWrFlj1pYsWWLWXnjhBbPWtm1bs2YZOXKkWZs2bZpZC1qMct26dWZt6NBzr51KadGihTnmgQceMGtz5841a1VVVWZt27Ztvtt79uxpjmmueGYncgTDTuQIhp3IEQw7kSMYdiJHMOxEjuDUWwRGjx5t1oKm3oKsXLnSrI0dOzbj7zdixAizFjT1FiRooUdr6i3IqFHWNVfBU29BXn/9dd/tM2fODPX9mjKe2YkcwbATOYJhJ3IEw07kCIadyBGNrkEXpaa+Bp3lxIkTZu2yyy4za0EXmdx///1mbfny5ek1lqbrr7/erAX9f/Xr18+sffHFF1n1dK5evXqZterqarN27bXX+m7fsmVL1j0VoqA16HhmJ3IEw07kCIadyBEMO5EjGHYiRzDsRI5o9EIYEVkE4C4Adara09s2HcAjAM7e/2eqqn4QV5OFrnXr1mYt6AKUhQsXmrVdu3Zl1VMmhg0bZtaCpt527twZRzu+gm6V9eSTT5q1oGk516RzZl8MwO8Sprmqep33z9mgEzUVjYZdVT8D0OhNG4mosGXzN/sEEakWkUUicmlkHRFRLMKGfT6AKwFcB6AWwGzrC0WkQkSSIpIMusUvEcUrVNhV9YiqnlbVMwBeBtA34GsXqGpCVRMdOnQI2ycRZSlU2EWktMGnwwH433aDiApGOlNvywEMBFAsIjUApgEYKCLXAVAA+wA8GmOPkdu9e7dZW7FihVlbunSp7/agtdiCrigLmno7fPiwWYvaVVddFWpcmzZtIu7E1rt370i/X9CVipWVlWatvLzcrJWWlpq1QtBo2FXVbxVA+6eUiAoS30FH5AiGncgRDDuRIxh2Ikcw7ESOaNK3f/r555/N2qRJk8za4sWLzZq1QCEAPP74477bgxaVLC4uNmtBOnfuHGpcGC1btgw17pprrom4E1vY42gJulJx2bJlZi3oZyfoCsfZs803mebs/5pndiJHMOxEjmDYiRzBsBM5gmEncgTDTuSIJjH19umnn/puHz16tDnmt99+M2tr1qwxa7fffrtZE/G9hVag2trajMcAwVdXRe3gwYOhxvXo0SPiTmxHjhwJNS6RSGQ85tVXXzVrY8eONWtBC3euXr3arK1cudJ3+6233mqOCYNndiJHMOxEjmDYiRzBsBM5gmEnckTBvBofdLujgQMH+m6/4oorzDFVVVVmLZer3O7ZsyfUuLvuuiviTmx79+4NNa5Pnz4Rd2IL2+O9994baR+33HKLWdu8ebNZGzBggFm75557fLdv3brVHNOtWzezZuGZncgRDDuRIxh2Ikcw7ESOYNiJHMGwEzkinds/dQHwTwCXATgDYIGqzhORdgDeBFCG1C2gRqjqsbCNPPfccxmPCVoPrFBuIvn555+btZKSErM2ePDgONrxtX79erMW1OPdd98dRzu+gnoMMmqU3w2N4hE0FfzMM8+Ytccee8x3+7x588wxc+bMSb8xTzpn9lMAnlTVfwNwA4DHRKQHgCkA1qpqdwBrvc+JqEA1GnZVrVXVKu/xcQDbAXQCMAzAEu/LlgDwf2cAERWEjP5mF5EyAL0BbATQUVVrgdQvBAD28z0iyru0wy4ibQC8A+AJVf01g3EVIpIUkWR9fX2YHokoAmmFXUQuQCroy1T1XW/zEREp9eqlAOr8xqrqAlVNqGqiUF40I3JRo2GX1FpMCwFsV9WGLwG+D2Cc93gcgFXRt0dEUUnnqrd+AMYA2CoiZy/rmQrg7wBWiMjDAA4AuC+bRiorKzMek8s10IJ88sknZi2ZTJq1l156yawF3Z4ojA0bNoSqzZw506y1atUqq57OtX//frMWtC7chAkTzFqYq8PicNNNN2U8xlp7MaxGw66qXwCwVlq8LdJuiCg2fAcdkSMYdiJHMOxEjmDYiRzBsBM5omAWnAx6w83333/vu3358uXmmKDpmKg9++yzZi1ogcKKioo42vEVdJVU0MKRkydPjqMdX88//7xZC7qibMaMGXG0E6m33nor4zFRT7/yzE7kCIadyBEMO5EjGHYiRzDsRI5g2IkcUTBTb4MGDTJrX375pe/2iRMnmmMuuugis/bggw+m31gDhw4d8t1+4MABc0zQFWXnnx/94a+pqfHdHjT1s2PHDrMW9ZVtZ86cMWsrV640a6tXrzZrl1xySVY9ZeLkyZNmbfr06WZt1qxZGe8raNo2DJ7ZiRzBsBM5gmEncgTDTuQIhp3IEaKqOdtZIpFQa022o0ePmuPKy8t9t9fV+S5o26igVzmnTp1q1m6++Wbf7S1btgzVRxys/8+9e/eaY4IuMmmufv/9d7P20UcfmbUpU+wbH1VXV4fqpaioyHd70Jp8l156qe/2RCKBZDLpu4wcz+xEjmDYiRzBsBM5gmEncgTDTuQIhp3IEY1eiSEiXQD8E8BlAM4AWKCq80RkOoBHAJy9NetUVf0gbCPFxcVmbdUq/9vIDR482Bxz/Phxs7Zu3bpQNcudd95p1m67zb5pTtAtgcrKysxa0IUf1sU1hTK9duLECbP2008/mbWgadaqqiqzZt1W7O233zbHBP3shGVNrwH2bZ6s6bWw0rns6hSAJ1W1SkSKAGwSkQ+92lxVtVcJJKKCkc693moB1HqPj4vIdgCd4m6MiKKV0d/sIlIGoDeAjd6mCSJSLSKLRCTa5xxEFKm0wy4ibQC8A+AJVf0VwHwAVwK4Dqkz/2xjXIWIJEUkWV9f7/clRJQDaYVdRC5AKujLVPVdAFDVI6p6WlXPAHgZQF+/saq6QFUTqpoIuhEEEcWr0bCLiABYCGC7qs5psL20wZcNB7At+vaIKCqNXvUmIv0BfA5gK1JTbwAwFcAopJ7CK4B9AB71XswzBV31FkbQ2m/jx483a2Gm15oKa4on6FlVSUmJWTt16pRZO3z4sFmz1sJrzoYNG2bW5s2bZ9a6desWWQ9BV72l82r8FwD8BoeeUyei3OM76IgcwbATOYJhJ3IEw07kCIadyBEFc/unMLp27WrWPv74Y7NmXQkFAC+++KJZe+ONN9JrLI+sK7aCruTas2dPXO00SWPGjDFrFRUVZq1///5xtBMZntmJHMGwEzmCYSdyBMNO5AiGncgRDDuRI5r01FtYN954Y6jawoULfbcHTeUFTQHu3r3brB08eNCsBd0DrNCvNgu6wi5oKrW0tNSsWfcCBIABAwb4bg/6f27btq1Za8p4ZidyBMNO5AiGncgRDDuRIxh2Ikcw7ESOcHLqLazWrVv7bh80aJA5JqgWB2sB0WPHjpljgu6jllpc2F/Q/fms+5Sddx7PL/nCI0/kCIadyBEMO5EjGHYiRzDsRI5o9NV4EfkLgM8AtPK+/m1VnSYi7QC8CaAMqds/jVBV+yVfygnr1fN27dqZY4Jq1Hykc2b/PwC3qmovpO7tNlREbgAwBcBaVe0OYK33OREVqEbDrin/6316gfdPAQwDsMTbvgTAPbF0SESRSPf+7C1EZDOAOgAfqupGAB3P3rXV+2hfqExEeZdW2FX1tKpeB6AzgL4i0jPdHYhIhYgkRSRZX18ftk8iylJGr8ar6s8APgEwFMARESkFAO+j73suVXWBqiZUNRF0j3AiilejYReRDiJyiff4QgCDAOwA8D6Acd6XjQOwKq4miSh76VwIUwpgiYi0QOqXwwpV/S8RWQ9ghYg8DOAAgPti7JOIstRo2FW1GkBvn+0/ArgtjqaIKHp8Bx2RIxh2Ikcw7ESOYNiJHMGwEzlCrDXLYtmZSD2As/cuKgZwNGc7t7GPP2Iff9TU+uimqr7vXstp2P+wY5GkqibysnP2wT4c7INP44kcwbATOSKfYV+Qx303xD7+iH38UbPpI29/sxNRbvFpPJEj8hJ2ERkqIt+JyC4RydvadSKyT0S2ishmEUnmcL+LRKRORLY12NZORD4UkZ3eR//7J8Xfx3QROegdk80ickcO+ugiIutEZLuIfCMij3vbc3pMAvrI6TERkb+IyP+IyBavj2e97dkdD1XN6T8ALQDsBnAFgJYAtgDokes+vF72ASjOw35vBtAHwLYG2/4TwBTv8RQAs/LUx3QAT+X4eJQC6OM9LgLwPYAeuT4mAX3k9JgAEABtvMcXANgI4IZsj0c+zux9AexS1T2q+huAN5BavNIZqvoZgJ/O2ZzzBTyNPnJOVWtVtcp7fBzAdgCdkONjEtBHTmlK5Iu85iPsnQD80ODzGuThgHoUwL9EZJOIVOSph7MKaQHPCSJS7T3Nj/3PiYZEpAyp9RPyuqjpOX0AOT4mcSzymo+w+93FIF9TAv1UtQ+AvwF4TERuzlMfhWQ+gCuRukdALYDZudqxiLQB8A6AJ1T111ztN40+cn5MNItFXi35CHsNgC4NPu8M4FAe+oCqHvI+1gF4D6k/MfIlrQU846aqR7wftDMAXkaOjomIXIBUwJap6rve5pwfE78+8nVMvH1nvMirJR9h/wpAdxH5q4i0BHA/UotX5pSIXCQiRWcfAxgMYFvwqFgVxAKeZ3+YPMORg2MiqXtWLQSwXVXnNCjl9JhYfeT6mMS2yGuuXmE859XGO5B6pXM3gH/PUw9XIDUTsAXAN7nsA8BypJ4O/o7UM52HAbRH6jZaO72P7fLUx2sAtgKo9n64SnPQR3+k/pSrBrDZ+3dHro9JQB85PSYArgXwtbe/bQD+w9ue1fHgO+iIHMF30BE5gmEncgTDTuQIhp3IEQw7kSMYdiJHMOxEjmDYiRzx/4euhjKtG/TLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = all_imgs[0,:,:]\n",
    "#label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "#print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba38bac8-8879-4f5e-8d29-a6b581b69817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = all_imgs[train,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9f318c-7606-4054-984b-340854e7387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40dd45b9-bf4c-4de7-a184-d2a24a8ad6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist3_ESBN_task():\n",
    "    training_set,test_set = create_task()\n",
    "    # Load images\n",
    "    all_imgs = []\n",
    "    n_shapes = 100\n",
    "    for i in range(n_shapes):\n",
    "        img_fname = '/home/asw3x/emergent_symbols/imgs/' + str(i) + '.png'\n",
    "        img = torch.Tensor(np.array(Image.open(img_fname))) / 255.\n",
    "        all_imgs.append(img)\n",
    "    all_imgs = torch.stack(all_imgs, 0)\n",
    "    # Create training and test sets\n",
    "    train = training_set['seq_ind']\n",
    "    test = test_set['seq_ind']\n",
    "    X_train = all_imgs[train,:,:]\n",
    "    X_test = all_imgs[test,:,:]\n",
    "    Y_train = training_set['y']\n",
    "    Y_test = test_set['y']\n",
    "    \n",
    "    train_set = {'img_seq': X_train, 'y': Y_train}\n",
    "    test_set = {'img_seq': X_test, 'y': Y_test}\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa488ab-0a92-45a2-8a9a-b46df6e67769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:08:54,771] n_shapes = 100...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:08:54,772] m_holdout = 0...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:08:54,772] Total possible trials = 5821200...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:08:54,773] Training set size = 10000...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:08:54,773] Test set size = 10000...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_set,test_set = dist3_ESBN_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633b7c4f-b90b-4f5c-b72c-4672bc5b108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 9, 32, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['img_seq'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "313f6274-18ca-4e65-a25a-b971f286a9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e67f724f-1d3c-4fc0-8e3a-bcfffd4a2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, target_transform=None):\n",
    "        '''\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        '''\n",
    "        self.img_seq = dataset['img_seq']\n",
    "        self.y = dataset['y']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "        '''\n",
    "        img_seq = self.img_seq[idx,:,:,:]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return img_seq, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "153311cb-07c7-48f6-abb9-f23db5e9f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_conv(nn.Module):\n",
    "\t#def __init__(self, args):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Encoder_conv, self).__init__()\n",
    "\t\tlog.info('Building convolutional encoder...')\n",
    "\t\t# Convolutional layers\n",
    "\t\tlog.info('Conv layers...')\n",
    "\t\t\n",
    "\t\tself.conv1 = nn.Conv2d(1, 32, 4, stride=2, padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(32, 32, 4, stride=2, padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(32, 32, 4, stride=2, padding=1)\n",
    "\t\t'''\n",
    "\t\tself.conv1 = nn.Conv2d(1, 160, 4, stride=2, padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(160, 160, 4, stride=2, padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(160, 160, 4, stride=2, padding=1)\n",
    "\t\t'''   \n",
    "\t\t# Fully-connected layers\n",
    "\t\tlog.info('FC layers...')\n",
    "\t\tself.fc1 = nn.Linear(4*4*32, 256)\n",
    "\t\tself.fc2 = nn.Linear(256, 128)\n",
    "\t\t#self.fc1 = nn.Linear(64000, 256)\n",
    "\t\t#self.fc2 = nn.Linear(256, 128)\n",
    "\t\t# Nonlinearities\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\t# Initialize parameters\n",
    "\t\tfor name, param in self.named_parameters():\n",
    "\t\t\t# Initialize all biases to 0\n",
    "\t\t\tif 'bias' in name:\n",
    "\t\t\t\tnn.init.constant_(param, 0.0)\n",
    "\t\t\t# Initialize all pre-ReLU weights using Kaiming normal distribution\n",
    "\t\t\telif 'weight' in name:\n",
    "\t\t\t\tnn.init.kaiming_normal_(param, nonlinearity='relu')\n",
    "\tdef forward(self, x):\n",
    "\t\t# Convolutional layers\n",
    "\t\tconv1_out = self.relu(self.conv1(x))\n",
    "\t\tconv2_out = self.relu(self.conv2(conv1_out))\n",
    "\t\tconv3_out = self.relu(self.conv3(conv2_out))\n",
    "\t\t# Flatten output of conv. net\n",
    "\t\tconv3_out_flat = torch.flatten(conv3_out, 1)\n",
    "\t\t# Fully-connected layers\n",
    "\t\t#print(\"conv3_out_flat.size() =\",conv3_out_flat.size())\n",
    "\t\t#time.sleep(120)\n",
    "\t\tfc1_out = self.relu(self.fc1(conv3_out_flat))\n",
    "\t\tfc2_out = self.relu(self.fc2(fc1_out))\n",
    "\t\t# Output\n",
    "\t\tz = fc2_out\n",
    "\t\treturn z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bee457bd-d49a-47fa-ac0a-6ecf29be8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\t#def __init__(self, task_gen, args):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Model, self).__init__()\n",
    "\t\t# Encoder\n",
    "\t\tlog.info('Building encoder...')\n",
    "\t\t'''\n",
    "\t\tif args.encoder == 'conv':\n",
    "\t\t\tself.encoder = Encoder_conv(args)\n",
    "\t\telif args.encoder == 'mlp':\n",
    "\t\t\tself.encoder = Encoder_mlp(args)\n",
    "\t\telif args.encoder == 'rand':\n",
    "\t\t\tself.encoder = Encoder_rand(args)\n",
    "\t\t'''\n",
    "\t\tself.encoder = Encoder_conv()# removed \"args\" argument\n",
    "\t\t# LSTM and output layers\n",
    "\t\tlog.info('Building LSTM and output layers...')\n",
    "\t\tself.z_size = 128\n",
    "\t\tself.key_size = 256\n",
    "\t\tself.hidden_size = 512\n",
    "\t\tself.lstm = nn.LSTM(self.key_size + 1, self.hidden_size, batch_first=True)\n",
    "\t\tself.key_w_out = nn.Linear(self.hidden_size, self.key_size)\n",
    "\t\tself.g_out = nn.Linear(self.hidden_size, 1)\n",
    "\t\tself.confidence_gain = nn.Parameter(torch.ones(1))\n",
    "\t\tself.confidence_bias = nn.Parameter(torch.zeros(1))\n",
    "\t\t#self.y_out = nn.Linear(self.hidden_size, task_gen.y_dim)\n",
    "\t\ty_out = 4 # number of outputs/ ESBN = 4\n",
    "\t\tself.y_out = nn.Linear(self.hidden_size, y_out)\n",
    "\t\t# Context normalization\n",
    "\t\t#if args.norm_type == 'contextnorm' or args.norm_type == 'tasksegmented_contextnorm':\n",
    "\t\tif True: # assumes \"contextnorm or tasksegmented_contextnorm\"\n",
    "\t\t\tself.contextnorm = True\n",
    "\t\t\tself.gamma = nn.Parameter(torch.ones(self.z_size))\n",
    "\t\t\tself.beta = nn.Parameter(torch.zeros(self.z_size))\n",
    "\t\telse:\n",
    "\t\t\tself.contextnorm = False\n",
    "\t\t'''\n",
    "\t\tif args.norm_type == 'tasksegmented_contextnorm':\n",
    "\t\t\tself.task_seg = task_gen.task_seg\n",
    "\t\telse:\n",
    "\t\t\tself.task_seg = [np.arange(task_gen.seq_len)]\n",
    "\t\t'''\n",
    "\t\tseq_len = 9 # number of images per Raven problem / ESBN = 9        \n",
    "\t\tself.task_seg = [np.arange(seq_len)]\n",
    "\t\t# Nonlinearities\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\t\tself.softmax = nn.Softmax(dim=1)\n",
    "\t\t# Initialize parameters\n",
    "\t\tfor name, param in self.named_parameters():\n",
    "\t\t\t# Encoder parameters have already been initialized\n",
    "\t\t\tif not ('encoder' in name) and not ('confidence' in name):\n",
    "\t\t\t\t# Initialize all biases to 0\n",
    "\t\t\t\tif 'bias' in name:\n",
    "\t\t\t\t\tnn.init.constant_(param, 0.0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif 'lstm' in name:\n",
    "\t\t\t\t\t\t# Initialize gate weights (followed by sigmoid) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[:self.hidden_size*2,:])\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[self.hidden_size*3:,:])\n",
    "\t\t\t\t\t\t# Initialize input->hidden and hidden->hidden weights (followed by tanh) using Xavier normal distribution with gain = \n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[self.hidden_size*2:self.hidden_size*3,:], gain=5.0/3.0)\n",
    "\t\t\t\t\telif 'key_w' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for key output layer (followed by ReLU) using Kaiming normal distribution\n",
    "\t\t\t\t\t\tnn.init.kaiming_normal_(param, nonlinearity='relu')\n",
    "\t\t\t\t\telif 'g_out' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for gate output layer (followed by sigmoid) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param)\n",
    "\t\t\t\t\telif 'y_out' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for multiple-choice output layer (followed by softmax) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param)\n",
    "\tdef forward(self, x_seq, device):\n",
    "\t\t# Encode all images in sequence\n",
    "\t\tz_seq = []\n",
    "\t\tfor t in range(x_seq.shape[1]):\n",
    "\t\t\tx_t = x_seq[:,t,:,:].unsqueeze(1)\n",
    "\t\t\tz_t = self.encoder(x_t)\n",
    "\t\t\tz_seq.append(z_t)\n",
    "\t\tz_seq = torch.stack(z_seq, dim=1)\n",
    "\t\tif self.contextnorm:\n",
    "\t\t\tz_seq_all_seg = []\n",
    "\t\t\tfor seg in range(len(self.task_seg)):\n",
    "\t\t\t\tz_seq_all_seg.append(self.apply_context_norm(z_seq[:,self.task_seg[seg],:]))\n",
    "\t\t\tz_seq = torch.cat(z_seq_all_seg, dim=1)\n",
    "\t\t# Initialize hidden state\n",
    "\t\thidden = torch.zeros(1, x_seq.shape[0], self.hidden_size).to(device)\n",
    "\t\tcell_state = torch.zeros(1, x_seq.shape[0], self.hidden_size).to(device)\n",
    "\t\t# Initialize retrieved key vector\n",
    "\t\tkey_r = torch.zeros(x_seq.shape[0], 1, self.key_size + 1).to(device)\n",
    "\t\t# Memory model (extra time step to process key retrieved on final time step)\n",
    "\t\tfor t in range(x_seq.shape[1] + 1):\n",
    "\t\t\t# Image embedding\n",
    "\t\t\tif t == x_seq.shape[1]:\n",
    "\t\t\t\tz_t = torch.zeros(x_seq.shape[0], 1, self.z_size).to(device)\n",
    "\t\t\telse:\n",
    "\t\t\t\tz_t = z_seq[:,t,:].unsqueeze(1)\n",
    "\t\t\t# Controller\n",
    "\t\t\t# LSTM\n",
    "\t\t\tlstm_out, (hidden, cell_state) = self.lstm(key_r, (hidden, cell_state))\n",
    "\t\t\t# Key output layers\n",
    "\t\t\tkey_w = self.relu(self.key_w_out(lstm_out))\n",
    "\t\t\t# Gates\n",
    "\t\t\tg = self.sigmoid(self.g_out(lstm_out))\n",
    "\t\t\t# Task output layer\n",
    "\t\t\ty_pred_linear = self.y_out(lstm_out).squeeze()\n",
    "\t\t\ty_pred = y_pred_linear.argmax(1)\n",
    "\t\t\t# Read from memory\n",
    "\t\t\tif t == 0:\n",
    "\t\t\t\tkey_r = torch.zeros(x_seq.shape[0], 1, self.key_size + 1).to(device)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Read key\n",
    "\t\t\t\tw_k = self.softmax((z_t * M_v).sum(dim=2))\n",
    "\t\t\t\tc_k = self.sigmoid(((z_t * M_v).sum(dim=2) * self.confidence_gain) + self.confidence_bias)\n",
    "\t\t\t\tkey_r = g * (torch.cat([M_k, c_k.unsqueeze(2)], dim=2) * w_k.unsqueeze(2)).sum(1).unsqueeze(1)\n",
    "\t\t\t# Write to memory\n",
    "\t\t\tif t == 0:\n",
    "\t\t\t\tM_k = key_w\n",
    "\t\t\t\tM_v = z_t\n",
    "\t\t\telse:\n",
    "\t\t\t\tM_k = torch.cat([M_k, key_w], dim=1)\n",
    "\t\t\t\tM_v = torch.cat([M_v, z_t], dim=1)\n",
    "\t\t\t#print('M_k =',M_k.size())\n",
    "\t\t\t#print('M_v =',M_v.size())\n",
    "\t\tprint('y_pred_linear.size()',y_pred_linear.size())\n",
    "\t\tprint('y_pred.size()',y_pred.size())  \n",
    "\t\treturn y_pred_linear, y_pred\n",
    "\tdef apply_context_norm(self, z_seq):\n",
    "\t\teps = 1e-8\n",
    "\t\tz_mu = z_seq.mean(1)\n",
    "\t\tz_sigma = (z_seq.var(1) + eps).sqrt()\n",
    "\t\tz_seq = (z_seq - z_mu.unsqueeze(1)) / z_sigma.unsqueeze(1)\n",
    "\t\tz_seq = (z_seq * self.gamma) + self.beta\n",
    "\t\treturn z_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80d2e2a7-51b2-4882-a2a9-39c7a9511b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CustomImageDataset(training_set)\n",
    "train_dataloader = DataLoader(training_set, batch_size=32, shuffle=True)\n",
    "test_set = CustomImageDataset(test_set)\n",
    "test_dataloader = DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9b41df4-aaa4-4e05-be80-c63a0e584bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 9, 32, 32])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,0,:,:].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b424614-729f-441d-87b1-56187400995b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 9, 32, 32])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,0,:,:].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65c2b27d-fb1c-4d69-bdd5-0fb51cf6a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(device, epoch, train_loader, model, optimizer):\n",
    "\tmodel.train()\n",
    "\t# Iterate over batches\n",
    "\tfor batch_idx, (X, y) in enumerate(train_loader):\n",
    "\t\t# Batch start time\n",
    "\t\tstart_time = time.time()\n",
    "\t\t# Use sequence indices to slice corresponding images\n",
    "\t\t#x_seq = all_imgs[seq_ind,:,:]\n",
    "\t\tx_seq = X.float()\n",
    "\t\t#print(\"x_seq.shape =\",x_seq.shape)\n",
    "\t\t# Load data to device\n",
    "\t\tx_seq = x_seq.to(device)\n",
    "\t\t#y = torch.nn.functional.one_hot(y,num_classes=4)\n",
    "\t\t#print(\"y =\",y)\n",
    "\t\ty = y.to(device)\n",
    "\t\t# Zero out gradients for optimizer \n",
    "\t\toptimizer.zero_grad()\n",
    "\t\t# Run model \n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\ty_pred_linear, y_pred, const_loss = model(x_seq, device)\n",
    "\t\telse:\n",
    "\t\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t'''\n",
    "\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t# Loss\n",
    "\t\tloss_fn = nn.CrossEntropyLoss()\n",
    "\t\tloss = loss_fn(y_pred_linear, y)\n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\tloss += const_loss\n",
    "\t\t'''\n",
    "\t\t# Update model\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t# Batch duration\n",
    "\t\tend_time = time.time()\n",
    "\t\tbatch_dur = end_time - start_time\n",
    "\t\t# Report prgoress\n",
    "\t\t#if batch_idx % args.log_interval == 0:\n",
    "\t\tif batch_idx % 10 == 0:\n",
    "\t\t\t# Accuracy\n",
    "\t\t\tacc = torch.eq(y_pred, y).float().mean().item() * 100.0\n",
    "\t\t\t# Report \t\n",
    "\t\t\tlog.info('[Epoch: ' + str(epoch) + '] ' + \\\n",
    "\t\t\t\t\t '[Batch: ' + str(batch_idx) + ' of ' + str(len(train_loader)) + '] ' + \\\n",
    "\t\t\t\t\t '[Loss = ' + '{:.4f}'.format(loss.item()) + '] ' + \\\n",
    "\t\t\t\t\t '[Accuracy = ' + '{:.2f}'.format(acc) + '] ' + \\\n",
    "\t\t\t\t\t '[' + '{:.3f}'.format(batch_dur) + ' sec/batch]')\n",
    "\t\t\t# Save progress to file\n",
    "\t\t\t'''\n",
    "\t\t\ttrain_prog_f.write(str(batch_idx) + ' ' +\\\n",
    "\t\t\t\t\t\t\t   '{:.4f}'.format(loss.item()) + ' ' + \\\n",
    "\t\t\t\t\t\t\t   '{:.2f}'.format(acc) + '\\n')\n",
    "\t\t\t'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6444ff38-679c-47c2-85ac-8ca5b1e108f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(device, epoch, test_loader, model):\n",
    "\tlog.info('Evaluating on test set...')\n",
    "\t# Set to eval mode\n",
    "\tmodel.eval()\n",
    "\t# Iterate over batches\n",
    "\tall_acc = []\n",
    "\tall_loss = []\n",
    "\tfor batch_idx, (X, y) in enumerate(test_loader):\n",
    "\t\t# Use sequence indices to slice corresponding images\n",
    "\t\tx_seq = X.float()\n",
    "\t\t# Load data to device\n",
    "\t\tx_seq = x_seq.to(device)\n",
    "\t\t#y = torch.nn.functional.one_hot(y,num_classes=4)\n",
    "\t\ty = y.to(device)\n",
    "\t\t# Run model \n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\ty_pred_linear, y_pred, const_loss = model(x_seq, device)\n",
    "\t\telse:\n",
    "\t\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t'''\n",
    "\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t# Loss\n",
    "\t\tloss_fn = nn.CrossEntropyLoss()\n",
    "\t\tloss = loss_fn(y_pred_linear, y)\n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\tloss += const_loss\n",
    "\t\t'''\n",
    "\t\tall_loss.append(loss.item())\n",
    "\t\t# Accuracy\n",
    "\t\tacc = torch.eq(y_pred, y).float().mean().item() * 100.0\n",
    "\t\tall_acc.append(acc)\n",
    "\t\t# Report progress\n",
    "\t\tlog.info('[Batch: ' + str(batch_idx) + ' of ' + str(len(test_loader)) + ']')\n",
    "\t# Report overall test performance\n",
    "\tavg_loss = np.mean(all_loss)\n",
    "\tavg_acc = np.mean(all_acc)\n",
    "\tlog.info('[Summary] ' + \\\n",
    "\t\t\t '[Loss = ' + '{:.4f}'.format(avg_loss) + '] ' + \\\n",
    "\t\t\t '[Accuracy = ' + '{:.2f}'.format(avg_acc) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27f64254-c0b3-4303-a9a7-953256157938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:18,420] Building encoder...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:11:18,421] Building convolutional encoder...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:11:18,421] Conv layers...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:11:18,423] FC layers...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:11:18,426] Building LSTM and output layers...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:23,317] [Epoch: 1] [Batch: 0 of 313] [Loss = 1.3875] [Accuracy = 25.00] [2.544 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:23,585] [Epoch: 1] [Batch: 10 of 313] [Loss = 1.3811] [Accuracy = 25.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:23,864] [Epoch: 1] [Batch: 20 of 313] [Loss = 1.3930] [Accuracy = 6.25] [0.031 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:24,146] [Epoch: 1] [Batch: 30 of 313] [Loss = 1.3344] [Accuracy = 56.25] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:24,424] [Epoch: 1] [Batch: 40 of 313] [Loss = 1.2017] [Accuracy = 43.75] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:24,701] [Epoch: 1] [Batch: 50 of 313] [Loss = 0.8960] [Accuracy = 87.50] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:24,981] [Epoch: 1] [Batch: 60 of 313] [Loss = 0.2435] [Accuracy = 87.50] [0.023 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:25,269] [Epoch: 1] [Batch: 70 of 313] [Loss = 0.1609] [Accuracy = 96.88] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:25,545] [Epoch: 1] [Batch: 80 of 313] [Loss = 0.0749] [Accuracy = 96.88] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:25,824] [Epoch: 1] [Batch: 90 of 313] [Loss = 0.0287] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:26,108] [Epoch: 1] [Batch: 100 of 313] [Loss = 0.0145] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:26,384] [Epoch: 1] [Batch: 110 of 313] [Loss = 0.0041] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:26,664] [Epoch: 1] [Batch: 120 of 313] [Loss = 0.0014] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:26,948] [Epoch: 1] [Batch: 130 of 313] [Loss = 0.0136] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:27,213] [Epoch: 1] [Batch: 140 of 313] [Loss = 0.0294] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:27,500] [Epoch: 1] [Batch: 150 of 313] [Loss = 0.2982] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:27,775] [Epoch: 1] [Batch: 160 of 313] [Loss = 0.0047] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:28,054] [Epoch: 1] [Batch: 170 of 313] [Loss = 0.2769] [Accuracy = 96.88] [0.024 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:28,333] [Epoch: 1] [Batch: 180 of 313] [Loss = 0.1891] [Accuracy = 96.88] [0.023 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:28,612] [Epoch: 1] [Batch: 190 of 313] [Loss = 0.0072] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:28,901] [Epoch: 1] [Batch: 200 of 313] [Loss = 0.0037] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:29,168] [Epoch: 1] [Batch: 210 of 313] [Loss = 0.0039] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:29,449] [Epoch: 1] [Batch: 220 of 313] [Loss = 0.0007] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:29,732] [Epoch: 1] [Batch: 230 of 313] [Loss = 0.0018] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:30,021] [Epoch: 1] [Batch: 240 of 313] [Loss = 0.0017] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:30,308] [Epoch: 1] [Batch: 250 of 313] [Loss = 0.0021] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:30,601] [Epoch: 1] [Batch: 260 of 313] [Loss = 0.0059] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:30,886] [Epoch: 1] [Batch: 270 of 313] [Loss = 0.0058] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:31,166] [Epoch: 1] [Batch: 280 of 313] [Loss = 0.0019] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:31,456] [Epoch: 1] [Batch: 290 of 313] [Loss = 0.1347] [Accuracy = 96.88] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:31,741] [Epoch: 1] [Batch: 300 of 313] [Loss = 0.0882] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:32,016] [Epoch: 1] [Batch: 310 of 313] [Loss = 0.0533] [Accuracy = 96.88] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:11:32,109] [Epoch: 2] [Batch: 0 of 313] [Loss = 0.0044] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([16, 4])\n",
      "y_pred.size() torch.Size([16])\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:32,393] [Epoch: 2] [Batch: 10 of 313] [Loss = 0.0426] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:32,672] [Epoch: 2] [Batch: 20 of 313] [Loss = 0.0812] [Accuracy = 96.88] [0.030 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:32,955] [Epoch: 2] [Batch: 30 of 313] [Loss = 0.0249] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:33,211] [Epoch: 2] [Batch: 40 of 313] [Loss = 0.0063] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:33,481] [Epoch: 2] [Batch: 50 of 313] [Loss = 0.1855] [Accuracy = 96.88] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:33,757] [Epoch: 2] [Batch: 60 of 313] [Loss = 0.0372] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:34,016] [Epoch: 2] [Batch: 70 of 313] [Loss = 0.0387] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:34,286] [Epoch: 2] [Batch: 80 of 313] [Loss = 0.0100] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:34,560] [Epoch: 2] [Batch: 90 of 313] [Loss = 0.0127] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:34,830] [Epoch: 2] [Batch: 100 of 313] [Loss = 0.0066] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:35,104] [Epoch: 2] [Batch: 110 of 313] [Loss = 0.0051] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:35,373] [Epoch: 2] [Batch: 120 of 313] [Loss = 0.0271] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:35,647] [Epoch: 2] [Batch: 130 of 313] [Loss = 0.0013] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:35,921] [Epoch: 2] [Batch: 140 of 313] [Loss = 0.0071] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:36,200] [Epoch: 2] [Batch: 150 of 313] [Loss = 0.0077] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:36,470] [Epoch: 2] [Batch: 160 of 313] [Loss = 0.0026] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:36,758] [Epoch: 2] [Batch: 170 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:37,033] [Epoch: 2] [Batch: 180 of 313] [Loss = 0.0036] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:37,308] [Epoch: 2] [Batch: 190 of 313] [Loss = 0.0028] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:37,582] [Epoch: 2] [Batch: 200 of 313] [Loss = 0.0026] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:37,862] [Epoch: 2] [Batch: 210 of 313] [Loss = 0.0008] [Accuracy = 100.00] [0.025 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:38,139] [Epoch: 2] [Batch: 220 of 313] [Loss = 0.0008] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:38,417] [Epoch: 2] [Batch: 230 of 313] [Loss = 0.0015] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:38,682] [Epoch: 2] [Batch: 240 of 313] [Loss = 0.0024] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:38,956] [Epoch: 2] [Batch: 250 of 313] [Loss = 0.0031] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:39,236] [Epoch: 2] [Batch: 260 of 313] [Loss = 0.0028] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:39,513] [Epoch: 2] [Batch: 270 of 313] [Loss = 0.0024] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:39,784] [Epoch: 2] [Batch: 280 of 313] [Loss = 0.0020] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:40,064] [Epoch: 2] [Batch: 290 of 313] [Loss = 0.0043] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:40,344] [Epoch: 2] [Batch: 300 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:40,625] [Epoch: 2] [Batch: 310 of 313] [Loss = 0.0127] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-08-30 16:11:40,705] [Epoch: 3] [Batch: 0 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([16, 4])\n",
      "y_pred.size() torch.Size([16])\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:40,977] [Epoch: 3] [Batch: 10 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:41,247] [Epoch: 3] [Batch: 20 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.032 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:41,535] [Epoch: 3] [Batch: 30 of 313] [Loss = 0.0013] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:41,809] [Epoch: 3] [Batch: 40 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.024 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:42,095] [Epoch: 3] [Batch: 50 of 313] [Loss = 0.0040] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:42,365] [Epoch: 3] [Batch: 60 of 313] [Loss = 0.0028] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:42,648] [Epoch: 3] [Batch: 70 of 313] [Loss = 0.2093] [Accuracy = 93.75] [0.026 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-08-30 16:11:42,929] [Epoch: 3] [Batch: 80 of 313] [Loss = 0.0097] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n",
      "y_pred_linear.size() torch.Size([32, 4])\n",
      "y_pred.size() torch.Size([32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c6bb3a660697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-dbeb63982852>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(device, epoch, train_loader, model, optimizer)\u001b[0m\n\u001b[1;32m     32\u001b[0m \t\t'''\n\u001b[1;32m     33\u001b[0m                 \u001b[0;31m# Update model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m# Batch duration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-4\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda:\" + str(1))\n",
    "model = Model().to(device)\n",
    "# Initialize the loss function\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(device, t+1, train_dataloader, model, optimizer)\n",
    "test_loop(device,t, test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb18591-ae59-4811-9cc5-c23bc0965e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ()",
   "language": "python",
   "name": "lambda-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
