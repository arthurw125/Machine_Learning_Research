{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from esbn_pytorch import ESBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\tdef __init__(self, task_gen, args):\n",
    "\t\tsuper(Model, self).__init__()\n",
    "\t\t# Encoder\n",
    "\t\tlog.info('Building encoder...')\n",
    "\t\tif args.encoder == 'conv':\n",
    "\t\t\tself.encoder = Encoder_conv(args)\n",
    "\t\telif args.encoder == 'mlp':\n",
    "\t\t\tself.encoder = Encoder_mlp(args)\n",
    "\t\telif args.encoder == 'rand':\n",
    "\t\t\tself.encoder = Encoder_rand(args)\n",
    "\t\t# LSTM and output layers\n",
    "\t\tlog.info('Building LSTM and output layers...')\n",
    "\t\tself.z_size = 128\n",
    "\t\tself.key_size = 256\n",
    "\t\tself.hidden_size = 512\n",
    "\t\tself.lstm = nn.LSTM(self.key_size + 1, self.hidden_size, batch_first=True)\n",
    "\t\tself.key_w_out = nn.Linear(self.hidden_size, self.key_size)\n",
    "\t\tself.g_out = nn.Linear(self.hidden_size, 1)\n",
    "\t\tself.confidence_gain = nn.Parameter(torch.ones(1))\n",
    "\t\tself.confidence_bias = nn.Parameter(torch.zeros(1))\n",
    "\t\tself.y_out = nn.Linear(self.hidden_size, task_gen.y_dim)\n",
    "\t\t# Context normalization\n",
    "\t\tif args.norm_type == 'contextnorm' or args.norm_type == 'tasksegmented_contextnorm':\n",
    "\t\t\tself.contextnorm = True\n",
    "\t\t\tself.gamma = nn.Parameter(torch.ones(self.z_size))\n",
    "\t\t\tself.beta = nn.Parameter(torch.zeros(self.z_size))\n",
    "\t\telse:\n",
    "\t\t\tself.contextnorm = False\n",
    "\t\tif args.norm_type == 'tasksegmented_contextnorm':\n",
    "\t\t\tself.task_seg = task_gen.task_seg\n",
    "\t\telse:\n",
    "\t\t\tself.task_seg = [np.arange(task_gen.seq_len)]\n",
    "\t\t# Nonlinearities\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\t\tself.softmax = nn.Softmax(dim=1)\n",
    "\t\t# Initialize parameters\n",
    "\t\tfor name, param in self.named_parameters():\n",
    "\t\t\t# Encoder parameters have already been initialized\n",
    "\t\t\tif not ('encoder' in name) and not ('confidence' in name):\n",
    "\t\t\t\t# Initialize all biases to 0\n",
    "\t\t\t\tif 'bias' in name:\n",
    "\t\t\t\t\tnn.init.constant_(param, 0.0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif 'lstm' in name:\n",
    "\t\t\t\t\t\t# Initialize gate weights (followed by sigmoid) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[:self.hidden_size*2,:])\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[self.hidden_size*3:,:])\n",
    "\t\t\t\t\t\t# Initialize input->hidden and hidden->hidden weights (followed by tanh) using Xavier normal distribution with gain = \n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[self.hidden_size*2:self.hidden_size*3,:], gain=5.0/3.0)\n",
    "\t\t\t\t\telif 'key_w' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for key output layer (followed by ReLU) using Kaiming normal distribution\n",
    "\t\t\t\t\t\tnn.init.kaiming_normal_(param, nonlinearity='relu')\n",
    "\t\t\t\t\telif 'g_out' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for gate output layer (followed by sigmoid) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param)\n",
    "\t\t\t\t\telif 'y_out' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for multiple-choice output layer (followed by softmax) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param)\n",
    "\tdef forward(self, x_seq, device):\n",
    "\t\t# Encode all images in sequence\n",
    "\t\tz_seq = []\n",
    "\t\tfor t in range(x_seq.shape[1]):\n",
    "\t\t\tx_t = x_seq[:,t,:,:].unsqueeze(1)\n",
    "\t\t\tz_t = self.encoder(x_t)\n",
    "\t\t\tz_seq.append(z_t)\n",
    "\t\tz_seq = torch.stack(z_seq, dim=1)\n",
    "\t\tif self.contextnorm:\n",
    "\t\t\tz_seq_all_seg = []\n",
    "\t\t\tfor seg in range(len(self.task_seg)):\n",
    "\t\t\t\tz_seq_all_seg.append(self.apply_context_norm(z_seq[:,self.task_seg[seg],:]))\n",
    "\t\t\tz_seq = torch.cat(z_seq_all_seg, dim=1)\n",
    "\t\t# Initialize hidden state\n",
    "\t\thidden = torch.zeros(1, x_seq.shape[0], self.hidden_size).to(device)\n",
    "\t\tcell_state = torch.zeros(1, x_seq.shape[0], self.hidden_size).to(device)\n",
    "\t\t# Initialize retrieved key vector\n",
    "\t\tkey_r = torch.zeros(x_seq.shape[0], 1, self.key_size + 1).to(device)\n",
    "\t\t# Memory model (extra time step to process key retrieved on final time step)\n",
    "\t\tfor t in range(x_seq.shape[1] + 1):\n",
    "\t\t\t# Image embedding\n",
    "\t\t\tif t == x_seq.shape[1]:\n",
    "\t\t\t\tz_t = torch.zeros(x_seq.shape[0], 1, self.z_size).to(device)\n",
    "\t\t\telse:\n",
    "\t\t\t\tz_t = z_seq[:,t,:].unsqueeze(1)\n",
    "\t\t\t# Controller\n",
    "\t\t\t# LSTM\n",
    "\t\t\tlstm_out, (hidden, cell_state) = self.lstm(key_r, (hidden, cell_state))\n",
    "\t\t\t# Key output layers\n",
    "\t\t\tkey_w = self.relu(self.key_w_out(lstm_out))\n",
    "\t\t\t# Gates\n",
    "\t\t\tg = self.sigmoid(self.g_out(lstm_out))\n",
    "\t\t\t# Task output layer\n",
    "\t\t\ty_pred_linear = self.y_out(lstm_out).squeeze()\n",
    "\t\t\ty_pred = y_pred_linear.argmax(1)\n",
    "\t\t\t# Read from memory\n",
    "\t\t\tif t == 0:\n",
    "\t\t\t\tkey_r = torch.zeros(x_seq.shape[0], 1, self.key_size + 1).to(device)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Read key\n",
    "\t\t\t\tw_k = self.softmax((z_t * M_v).sum(dim=2))\n",
    "\t\t\t\tc_k = self.sigmoid(((z_t * M_v).sum(dim=2) * self.confidence_gain) + self.confidence_bias)\n",
    "\t\t\t\tkey_r = g * (torch.cat([M_k, c_k.unsqueeze(2)], dim=2) * w_k.unsqueeze(2)).sum(1).unsqueeze(1)\n",
    "\t\t\t# Write to memory\n",
    "\t\t\tif t == 0:\n",
    "\t\t\t\tM_k = key_w\n",
    "\t\t\t\tM_v = z_t\n",
    "\t\t\telse:\n",
    "\t\t\t\tM_k = torch.cat([M_k, key_w], dim=1)\n",
    "\t\t\t\tM_v = torch.cat([M_v, z_t], dim=1)\n",
    "\t\treturn y_pred_linear, y_pred\n",
    "\tdef apply_context_norm(self, z_seq):\n",
    "\t\teps = 1e-8\n",
    "\t\tz_mu = z_seq.mean(1)\n",
    "\t\tz_sigma = (z_seq.var(1) + eps).sqrt()\n",
    "\t\tz_seq = (z_seq - z_mu.unsqueeze(1)) / z_sigma.unsqueeze(1)\n",
    "\t\tz_seq = (z_seq * self.gamma) + self.beta\n",
    "\t\treturn z_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_npz_img(img_path):\n",
    "    data = np.load(img_path)\n",
    "    img = data['image']\n",
    "    target = data['target']\n",
    "    x = img[:,:,:]\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    #x = x.reshape((x.shape[0],x.shape[1],x.shape[2],x.shape[3],1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_npz_target(target_path):\n",
    "    data = np.load(target_path)\n",
    "    target = data['target']\n",
    "    y = int(target)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(folder,num_imgs,config):\n",
    "    X = []\n",
    "    #X = np.array(X)\n",
    "    Y =[]\n",
    "    #for i in range(num_imgs):\n",
    "    name = ''\n",
    "    if config=='train':\n",
    "        name = 'train'\n",
    "    elif config=='validate':\n",
    "        name = 'val'\n",
    "    else:\n",
    "        name = 'test'\n",
    "        \n",
    "    count = 0\n",
    "    i = 0\n",
    "    while count < num_imgs:\n",
    "        try:\n",
    "            x = grab_npz_img('/home/asw3x/RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            y = grab_npz_target('/home/asw3x/RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            i += 1\n",
    "        except:\n",
    "            i += 1\n",
    "            continue\n",
    "        X.append(x)\n",
    "        #X = np.concatenate(x)\n",
    "        Y.append(y)\n",
    "        count += 1\n",
    "    X = np.array(X)\n",
    "    X = np.squeeze(X)\n",
    "    #X = np.expand_dims(X, axis=4)\n",
    "    #X = X.reshape((X.shape[0],X.shape[2],X.shape[3],X.shape[1]))\n",
    "    X = np.moveaxis(X, 1, -1)\n",
    "    return X,np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task(args, train_shapes, test_shapes):\n",
    "    folder = \"center_single\"\n",
    "    train_size = 1000\n",
    "    test_size = train_size*0.4\n",
    "    \n",
    "    X_train, Y_train = create_dataset(folder,train_size,\"train\")\n",
    "    X_test, Y_test = create_dataset(folder,test_size,\"test\")\n",
    "    \n",
    "    # Create training and test sets\n",
    "    train_set = {'img_seq': X_train, 'y': Y_train}\n",
    "    test_set = {'img_seq': X_test, 'y': Y_test}\n",
    "    return args, train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "args,training_set,test_set = create_task(None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['img_seq'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, target_transform=None):\n",
    "        '''\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        '''\n",
    "        self.img_seq = dataset['img_seq']\n",
    "        self.y = dataset['y']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "        '''\n",
    "        img_seq = self.img_seq[idx,:,:,:]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return img_seq, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CustomImageDataset(training_set)\n",
    "train_dataloader = DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "test_set = CustomImageDataset(test_set)\n",
    "test_dataloader = DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,:,:,0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,:,:,0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ESBN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 128 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
