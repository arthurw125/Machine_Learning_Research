{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07865754-05b1-4198-ae72-0139dc257fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from util import log\n",
    "from modules import *\n",
    "from dist3 import create_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a548cfc9-5c55-4130-99c5-946e4be00470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set,test_set = create_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae57d2c5-65be-457e-b50d-0fd3b445874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set['seq_ind'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b691aa-337d-4d57-8f63-ddafd99bf2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d442f1e-e39e-4894-bfe1-2929b893a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = training_set['seq_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a58126-f899-4505-a016-d5f74d8ed723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc03fbb9-b569-43be-803f-34d9ec6803dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916244aa-475e-426f-b0ce-abcc46e81591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "all_imgs = []\n",
    "n_shapes = 100\n",
    "for i in range(n_shapes):\n",
    "\timg_fname = '/home/asw3x/emergent_symbols/imgs/' + str(i) + '.png'\n",
    "\timg = torch.Tensor(np.array(Image.open(img_fname))) / 255.\n",
    "\tall_imgs.append(img)\n",
    "all_imgs = torch.stack(all_imgs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d87ce5-4d46-4361-88cc-8743100b04fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2aeff16-025d-4e7c-81ec-75837d0bff11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAULUlEQVR4nO3de2xU5boG8OcVhS1SL1CKlVu3SuKhKEJGYgQFFYHtJUCMIJGbGusfQhQ0BjnJAUMkmxOBoNuQoCBsQRRvYE7ksBXxWuA4VCgoKHcstLQoKieEo8B7/phFUnG9qzNr1poZ+j2/hHS63n5dbxZ9uqbzzfqWqCqIqPk7L98NEFFuMOxEjmDYiRzBsBM5gmEncgTDTuSI87MZLCJDAMwD0ALAK6r696CvLy4u1rKysmx2STEImn7dsWOHWSspKTFr7dq1y6onCmffvn04cuSI+NVCh11EWgB4CcAdAGoAfCUi76vqt9aYsrIyJJPJsLukmJw4ccKs9e3b16xNnDjRrI0fPz6bliikRCJh1rJ5Gt8HwC5V3aOqvwF4A8DQLL4fEcUom7B3BPBDo89rvG1EVICyCbvf3wV/+uNPRCpEJCkiyYaGhix2R0TZyCbsNQA6N/q8E4BDZ3+Rqi5Q1YSqJtq3b5/F7ogoG9mE/SsA3UTkryLSEsD9AN6Ppi0iilroV+NV9aSITACwBqmpt0Wq+k1knTngqaeeMmvdunUza48++mikfUyePNms7dy506yNHDky0j7CeuWVV8zaN9/4/0jOnTs3rnYKVlbz7Kr6AYAPIuqFiGLEd9AROYJhJ3IEw07kCIadyBEMO5Ejsno1npq2dOlSszZ79myzVldXF2kfX3/9tVmbP3++WZsxY4ZZu/DCC7PqKROVlZVm7ZFHHjFrGzdujKOdcxLP7ESOYNiJHMGwEzmCYSdyBMNO5Ai+Gh+BvXv3mrUxY8aYtUmTJpm1Dh06ZNXT2cJe+JHL5aWOHz9u1oYPH27WBg8ebNb69OmTVU/NCc/sRI5g2IkcwbATOYJhJ3IEw07kCIadyBGceovAnDlzQo0LWvstLGv66rXXXjPHFBUVmbVOnTpl3VO6Fi1aZNbq6+vN2tNPPx1HO80Oz+xEjmDYiRzBsBM5gmEncgTDTuQIhp3IEVlNvYnIPgDHAJwCcFJV7TvBNwO//PKL7/Z//OMf5pigqas4prV2796d8Zjy8vLI+whj1qxZocbxyrb0RDHPfquqHong+xBRjPg0nsgR2YZdAfxLRDaJSEUUDRFRPLJ9Gt9XVQ+JSAmAD0Vkh6p+1vgLvF8CFQDQpUuXLHdHRGFldWZX1UPex3oA7wH40yslqrpAVROqmmjfvn02uyOiLIQOu4hcJCJFZx4DGARgW1SNEVG0snka3wHAeyJy5vu8rqr/HUlXBWrHjh0Zj+nZs2cMndh27dqV8ZiOHTvG0Im/o0ePmrWamhqzFjRN2aZNm6x6ckXosKvqHgC5/UkmotA49UbkCIadyBEMO5EjGHYiRzDsRI7ggpMZ+O677zIe07lz5xg6se3fvz/jMXV1dTF04i/MMQSArl27RtyJe3hmJ3IEw07kCIadyBEMO5EjGHYiR/DV+AyEeaW7trY2hk5sl1xyScZjqqurzdrJkyfN2vnnZ/7j88MPP2Q8Bsj9cWyOeGYncgTDTuQIhp3IEQw7kSMYdiJHMOxEjuDUWwbCrI67fv16s3b69Gmzdt554X4Pl5aWZjzm2LFjZm3Dhg1mrV+/fhnvq7i4OOMxALBnzx6z9uOPP5q1du3ahdpfc8QzO5EjGHYiRzDsRI5g2IkcwbATOYJhJ3JEk1NvIrIIwN0A6lW1h7etLYA3AZQB2AdghKra9/VpJoJuQWSpr683a5WVlWYtzLQWAFxzzTWhxlmWLVtm1sL0eMUVV2TTjq9Vq1aZtYceeijy/Z2r0jmzLwYw5KxtUwCsVdVuANZ6nxNRAWsy7N791n86a/NQAEu8x0sADIu2LSKKWti/2Tuoai0AeB9LomuJiOIQ+wt0IlIhIkkRSTY0NMS9OyIyhA37YREpBQDvo/kqlKouUNWEqibCvLeciKIRNuzvAxjnPR4HwH45lIgKgqhq8BeILAcwAEAxgMMApgFYCWAFgC4ADgC4T1XPfhHvTxKJhCaTyew6ziNrGq1Dhw6hvt+4cePM2uLFi0N9T0t5eblZ+/bbb81aUVGRWQv6s6xVq1a+20+dOmWOCZqWC5rC7N27t1nbtGmTWWuOEokEksmk+NWanGdX1VFG6fasuiKinOI76IgcwbATOYJhJ3IEw07kCIadyBFccDIDJSX+7woePHiwOWbNmjVmbcmSJWbthRdeMGsXX3yxWbOMHDnSrE2bNs2sBS1GuW7dOrM2ZMjZ106ltGjRwhzzwAMPmLW5c+eataqqKrO2bds23+09evQwxzRXPLMTOYJhJ3IEw07kCIadyBEMO5EjGHYiR3DqLQKjR482a0FTb0FWrlxp1saOHZvx9xsxYoRZC5p6CxK00KM19RZk1Cjrmqvgqbcgr7/+uu/2mTNnhvp+5zKe2YkcwbATOYJhJ3IEw07kCIadyBFNrkEXpXN9DTrL8ePHzdrll19u1oIuMrn//vvN2vLly9NrLE033HCDWQv6/+rbt69Z++KLL7Lq6Ww9e/Y0a9XV1Wbtuuuu892+ZcuWrHsqREFr0PHMTuQIhp3IEQw7kSMYdiJHMOxEjmDYiRzR5IUwIrIIwN0A6lW1h7dtOoBHAJy5/89UVf0griYLXevWrc1a0AUoCxcuNGu7du3KqqdMDB061KwFTb3t3LkzjnZ8Bd0q68knnzRrQdNyrknnzL4YgN8lTHNV9Xrvn7NBJzpXNBl2Vf0MQJM3bSSiwpbN3+wTRKRaRBaJyGWRdUREsQgb9vkArgJwPYBaALOtLxSRChFJikgy6Ba/RBSvUGFX1cOqekpVTwN4GUCfgK9doKoJVU20b98+bJ9ElKVQYReR0kafDgfgf9sNIioY6Uy9LQcwAECxiNQAmAZggIhcD0AB7APwaHwtRm/37t1mbcWKFWZt6dKlvtuD1mILuqIsaOqtrq7OrEXt6quvDjWuTZs2EXdi69WrV6TfL+hKxcrKSrNWXl5u1kpLS81aIWgy7Krqtwqg/VNKRAWJ76AjcgTDTuQIhp3IEQw7kSMYdiJHnNO3f/r555/N2qRJk8za4sWLzZq1QCEAPP74477bgxaVLC4uNmtBOnXqFGpcGC1btgw17tprr424E1vY42gJulJx2bJlZi3oZyfoCsfZs803mebs/5pndiJHMOxEjmDYiRzBsBM5gmEncgTDTuSIc2Lq7dNPP/XdPnr0aHPMb7/9ZtbWrFlj1u644w6zJuJ7C61AtbW1GY8Bgq+uitrBgwdDjevevXvEndgOHz4calwikch4zKuvvmrWxo4da9aCFu5cvXq1WVu5cqXv9ttuu80cEwbP7ESOYNiJHMGwEzmCYSdyBMNO5IiCeTU+6HZHAwYM8N1+5ZVXmmOqqqrMWi5Xud2zZ0+ocXfffXfEndj27t0balzv3r0j7sQWtsd777030j5uvfVWs7Z582az1r9/f7M2bNgw3+1bt241x3Tt2tWsWXhmJ3IEw07kCIadyBEMO5EjGHYiRzDsRI5I5/ZPnQH8E8DlAE4DWKCq80SkLYA3AZQhdQuoEap6NGwjzz33XMZjgtYDK5SbSH7++edmraSkxKwNGjQojnZ8rV+/3qwF9XjPPffE0Y6voB6DjBrld0OjeARNBT/zzDNm7bHHHvPdPm/ePHPMnDlz0m/Mk86Z/SSAJ1X13wDcCOAxEekOYAqAtaraDcBa73MiKlBNhl1Va1W1ynt8DMB2AB0BDAWwxPuyJQCGxdQjEUUgo7/ZRaQMQC8AGwF0UNVaIPULAYD9fI+I8i7tsItIGwDvAHhCVX/NYFyFiCRFJNnQ0BCmRyKKQFphF5ELkAr6MlV919t8WERKvXopgHq/saq6QFUTqpoolBfNiFzUZNgltRbTQgDbVbXxS4DvAxjnPR4HYFX07RFRVNK56q0vgDEAtorIZm/bVAB/B7BCRB4GcADAfdk0UllZmfGYXK6BFuSTTz4xa8lk0qy99NJLZi3o9kRhbNiwIVRt5syZZq1Vq1ZZ9XS2/fv3m7WgdeEmTJhg1sJcHRaHm2++OeMx1tqLYTUZdlX9AoC10uLtkXZDRLHhO+iIHMGwEzmCYSdyBMNO5AiGncgRBbPgZNAbbr7//nvf7cuXLzfHBE3HRO3ZZ581a0ELFFZUVMTRjq+gq6SCFo6cPHlyHO34ev75581a0BVlM2bMiKOdSL311lsZj4l6+pVndiJHMOxEjmDYiRzBsBM5gmEncgTDTuSIgpl6GzhwoFn78ssvfbdPnDjRHHPRRReZtQcffDD9xho5dOiQ7/YDBw6YY4KuKDv//OgPf01Nje/2oKmfHTt2mLWor2w7ffq0WVu5cqVZW716tVm79NJLs+goMydOnDBr06dPN2uzZs3KeF9B07Zh8MxO5AiGncgRDDuRIxh2Ikcw7ESOEFXN2c4SiYRaa7IdOXLEHFdeXu67vb7ed0HbJgW9yjl16lSzdsstt/hub9myZag+4mD9f+7du9ccE3SRSXP1+++/m7WPPvrIrE2ZYt/4qLq6OlQvRUVFvtuD1uS77LLLfLcnEgkkk0nfZeR4ZidyBMNO5AiGncgRDDuRIxh2Ikcw7ESOaPJKDBHpDOCfAC4HcBrAAlWdJyLTATwC4MytWaeq6gdhGykuLjZrq1b530Zu0KBB5phjx46ZtXXr1oWqWe666y6zdvvt9k1zgm4JVFZWZtaCLvywLq4plOm148ePm7WffvrJrAVNs1ZVVZk167Zib7/9tjkm6GcnLGt6DbBv82RNr4WVzmVXJwE8qapVIlIEYJOIfOjV5qqqvUogERWMdO71Vgug1nt8TES2A+gYd2NEFK2M/mYXkTIAvQBs9DZNEJFqEVkkItE+5yCiSKUddhFpA+AdAE+o6q8A5gO4CsD1SJ35ZxvjKkQkKSLJhoYGvy8hohxIK+wicgFSQV+mqu8CgKoeVtVTqnoawMsA+viNVdUFqppQ1UTQjSCIKF5Nhl1EBMBCANtVdU6j7aWNvmw4gG3Rt0dEUWnyqjcR6QfgcwBbkZp6A4CpAEYh9RReAewD8Kj3Yp4p6Kq3MILWfhs/frxZCzO9dq6wpniCnlWVlJSYtZMnT5q1uro6s2athdecDR061KzNmzfPrHXt2jWyHoKuekvn1fgvAPgNDj2nTkS5x3fQETmCYSdyBMNO5AiGncgRDDuRIwrm9k9hdOnSxax9/PHHZs26EgoAXnzxRbP2xhtvpNdYHllXbAVdybVnz5642jknjRkzxqxVVFSYtX79+sXRTmR4ZidyBMNO5AiGncgRDDuRIxh2Ikcw7ESOOKen3sK66aabQtUWLlzouz1oKi9oCnD37t1m7eDBg2Yt6B5ghX61WdAVdkFTqaWlpWbNuhcgAPTv3993e9D/88UXX2zWzmU8sxM5gmEncgTDTuQIhp3IEQw7kSMYdiJHODn1Flbr1q19tw8cONAcE1SLg7WA6NGjR80xQfdRSy0u7C/o/nzWfcrOO4/nl3zhkSdyBMNO5AiGncgRDDuRIxh2Ikc0+Wq8iPwFwGcAWnlf/7aqThORtgDeBFCG1O2fRqiq/ZIv5YT16nnbtm3NMUE1aj7SObP/H4DbVLUnUvd2GyIiNwKYAmCtqnYDsNb7nIgKVJNh15T/9T69wPunAIYCWOJtXwJgWBwNElE00r0/ewsR2QygHsCHqroRQIczd231PtoXKhNR3qUVdlU9parXA+gEoI+I9Eh3ByJSISJJEUk2NDSEbJOIspXRq/Gq+jOATwAMAXBYREoBwPvo+55LVV2gqglVTQTdI5yI4tVk2EWkvYhc6j2+EMBAADsAvA9gnPdl4wCsiqlHIopAOhfClAJYIiItkPrlsEJV/0tE1gNYISIPAzgA4L4Y+ySiLDUZdlWtBtDLZ/uPAG6Poykiih7fQUfkCIadyBEMO5EjGHYiRzDsRI4Qa82yWHYm0gDgzL2LigEcydnObezjj9jHH51rfXRVVd93r+U07H/YsUhSVRN52Tn7YB8O9sGn8USOYNiJHJHPsC/I474bYx9/xD7+qNn0kbe/2Ykot/g0nsgReQm7iAwRke9EZJeI5G3tOhHZJyJbRWSziCRzuN9FIlIvItsabWsrIh+KyE7vo//9k+LvY7qIHPSOyWYRuTMHfXQWkXUisl1EvhGRx73tOT0mAX3k9JiIyF9E5H9EZIvXx7Pe9uyOh6rm9B+AFgB2A7gSQEsAWwB0z3UfXi/7ABTnYb+3AOgNYFujbf8JYIr3eAqAWXnqYzqAp3J8PEoB9PYeFwH4HkD3XB+TgD5yekwACIA23uMLAGwEcGO2xyMfZ/Y+AHap6h5V/Q3AG0gtXukMVf0MwE9nbc75Ap5GHzmnqrWqWuU9PgZgO4COyPExCegjpzQl8kVe8xH2jgB+aPR5DfJwQD0K4F8isklEKvLUwxmFtIDnBBGp9p7mx/7nRGMiUobU+gl5XdT0rD6AHB+TOBZ5zUfY/e5ikK8pgb6q2hvA3wA8JiK35KmPQjIfwFVI3SOgFsDsXO1YRNoAeAfAE6r6a672m0YfOT8mmsUir5Z8hL0GQOdGn3cCcCgPfUBVD3kf6wG8h9SfGPmS1gKecVPVw94P2mkALyNHx0RELkAqYMtU9V1vc86PiV8f+Tom3r5/RoaLvFryEfavAHQTkb+KSEsA9yO1eGVOichFIlJ05jGAQQC2BY+KVUEs4Hnmh8kzHDk4JpK6Z9VCANtVdU6jUk6PidVHro9JbIu85uoVxrNebbwTqVc6dwP49zz1cCVSMwFbAHyTyz4ALEfq6eDvSD3TeRhAO6Ruo7XT+9g2T328BmArgGrvh6s0B330Q+pPuWoAm71/d+b6mAT0kdNjAuA6AF97+9sG4D+87VkdD76DjsgRfAcdkSMYdiJHMOxEjmDYiRzBsBM5gmEncgTDTuQIhp3IEf8Ph66GMsFvVL4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = all_imgs[0,:,:]\n",
    "#label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "#print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba38bac8-8879-4f5e-8d29-a6b581b69817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = all_imgs[train,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9f318c-7606-4054-984b-340854e7387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40dd45b9-bf4c-4de7-a184-d2a24a8ad6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist3_ESBN_task():\n",
    "    training_set,test_set = create_task()\n",
    "    # Load images\n",
    "    all_imgs = []\n",
    "    n_shapes = 100\n",
    "    for i in range(n_shapes):\n",
    "        img_fname = '/home/asw3x/emergent_symbols/imgs/' + str(i) + '.png'\n",
    "        img = torch.Tensor(np.array(Image.open(img_fname))) / 255.\n",
    "        all_imgs.append(img)\n",
    "    all_imgs = torch.stack(all_imgs, 0)\n",
    "    # Create training and test sets\n",
    "    train = training_set['seq_ind']\n",
    "    test = test_set['seq_ind']\n",
    "    X_train = all_imgs[train,:,:]\n",
    "    X_test = all_imgs[test,:,:]\n",
    "    Y_train = training_set['y']\n",
    "    Y_test = test_set['y']\n",
    "    \n",
    "    train_set = {'img_seq': X_train, 'y': Y_train}\n",
    "    test_set = {'img_seq': X_test, 'y': Y_test}\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa488ab-0a92-45a2-8a9a-b46df6e67769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,431] n_shapes = 100...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,432] m_holdout = 0...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,433] Total possible trials = 5821200...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,433] Training set size = 10000...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 00:40:29,433] Test set size = 10000...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_set,test_set = dist3_ESBN_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633b7c4f-b90b-4f5c-b72c-4672bc5b108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 9, 32, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['img_seq'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e67f724f-1d3c-4fc0-8e3a-bcfffd4a2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, target_transform=None):\n",
    "        '''\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        '''\n",
    "        self.img_seq = dataset['img_seq']\n",
    "        self.y = dataset['y']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "        '''\n",
    "        img_seq = self.img_seq[idx,:,:,:]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return img_seq, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "153311cb-07c7-48f6-abb9-f23db5e9f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_conv(nn.Module):\n",
    "\t#def __init__(self, args):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Encoder_conv, self).__init__()\n",
    "\t\tlog.info('Building convolutional encoder...')\n",
    "\t\t# Convolutional layers\n",
    "\t\tlog.info('Conv layers...')\n",
    "\t\t\n",
    "\t\tself.conv1 = nn.Conv2d(1, 32, 4, stride=2, padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(32, 32, 4, stride=2, padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(32, 32, 4, stride=2, padding=1)\n",
    "\t\t'''\n",
    "\t\tself.conv1 = nn.Conv2d(1, 160, 4, stride=2, padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(160, 160, 4, stride=2, padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(160, 160, 4, stride=2, padding=1)\n",
    "\t\t'''   \n",
    "\t\t# Fully-connected layers\n",
    "\t\tlog.info('FC layers...')\n",
    "\t\tself.fc1 = nn.Linear(4*4*32, 256)\n",
    "\t\tself.fc2 = nn.Linear(256, 128)\n",
    "\t\t#self.fc1 = nn.Linear(64000, 256)\n",
    "\t\t#self.fc2 = nn.Linear(256, 128)\n",
    "\t\t# Nonlinearities\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\t# Initialize parameters\n",
    "\t\tfor name, param in self.named_parameters():\n",
    "\t\t\t# Initialize all biases to 0\n",
    "\t\t\tif 'bias' in name:\n",
    "\t\t\t\tnn.init.constant_(param, 0.0)\n",
    "\t\t\t# Initialize all pre-ReLU weights using Kaiming normal distribution\n",
    "\t\t\telif 'weight' in name:\n",
    "\t\t\t\tnn.init.kaiming_normal_(param, nonlinearity='relu')\n",
    "\tdef forward(self, x):\n",
    "\t\t# Convolutional layers\n",
    "\t\tconv1_out = self.relu(self.conv1(x))\n",
    "\t\tconv2_out = self.relu(self.conv2(conv1_out))\n",
    "\t\tconv3_out = self.relu(self.conv3(conv2_out))\n",
    "\t\t# Flatten output of conv. net\n",
    "\t\tconv3_out_flat = torch.flatten(conv3_out, 1)\n",
    "\t\t# Fully-connected layers\n",
    "\t\t#print(\"conv3_out_flat.size() =\",conv3_out_flat.size())\n",
    "\t\t#time.sleep(120)\n",
    "\t\tfc1_out = self.relu(self.fc1(conv3_out_flat))\n",
    "\t\tfc2_out = self.relu(self.fc2(fc1_out))\n",
    "\t\t# Output\n",
    "\t\tz = fc2_out\n",
    "\t\treturn z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee457bd-d49a-47fa-ac0a-6ecf29be8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\t#def __init__(self, task_gen, args):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Model, self).__init__()\n",
    "\t\t# Encoder\n",
    "\t\tlog.info('Building encoder...')\n",
    "\t\t'''\n",
    "\t\tif args.encoder == 'conv':\n",
    "\t\t\tself.encoder = Encoder_conv(args)\n",
    "\t\telif args.encoder == 'mlp':\n",
    "\t\t\tself.encoder = Encoder_mlp(args)\n",
    "\t\telif args.encoder == 'rand':\n",
    "\t\t\tself.encoder = Encoder_rand(args)\n",
    "\t\t'''\n",
    "\t\tself.encoder = Encoder_conv()# removed \"args\" argument\n",
    "\t\t# LSTM and output layers\n",
    "\t\tlog.info('Building LSTM and output layers...')\n",
    "\t\tself.z_size = 128\n",
    "\t\tself.key_size = 256\n",
    "\t\tself.hidden_size = 512\n",
    "\t\tself.lstm = nn.LSTM(self.key_size + 1, self.hidden_size, batch_first=True)\n",
    "\t\tself.key_w_out = nn.Linear(self.hidden_size, self.key_size)\n",
    "\t\tself.g_out = nn.Linear(self.hidden_size, 1)\n",
    "\t\tself.confidence_gain = nn.Parameter(torch.ones(1))\n",
    "\t\tself.confidence_bias = nn.Parameter(torch.zeros(1))\n",
    "\t\t#self.y_out = nn.Linear(self.hidden_size, task_gen.y_dim)\n",
    "\t\ty_out = 4 # number of outputs/ ESBN = 4\n",
    "\t\tself.y_out = nn.Linear(self.hidden_size, y_out)\n",
    "\t\t# Context normalization\n",
    "\t\t#if args.norm_type == 'contextnorm' or args.norm_type == 'tasksegmented_contextnorm':\n",
    "\t\tif True: # assumes \"contextnorm or tasksegmented_contextnorm\"\n",
    "\t\t\tself.contextnorm = True\n",
    "\t\t\tself.gamma = nn.Parameter(torch.ones(self.z_size))\n",
    "\t\t\tself.beta = nn.Parameter(torch.zeros(self.z_size))\n",
    "\t\telse:\n",
    "\t\t\tself.contextnorm = False\n",
    "\t\t'''\n",
    "\t\tif args.norm_type == 'tasksegmented_contextnorm':\n",
    "\t\t\tself.task_seg = task_gen.task_seg\n",
    "\t\telse:\n",
    "\t\t\tself.task_seg = [np.arange(task_gen.seq_len)]\n",
    "\t\t'''\n",
    "\t\tseq_len = 9 # number of images per Raven problem / ESBN = 9        \n",
    "\t\tself.task_seg = [np.arange(seq_len)]\n",
    "\t\t# Nonlinearities\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\t\tself.softmax = nn.Softmax(dim=1)\n",
    "\t\t# Initialize parameters\n",
    "\t\tfor name, param in self.named_parameters():\n",
    "\t\t\t# Encoder parameters have already been initialized\n",
    "\t\t\tif not ('encoder' in name) and not ('confidence' in name):\n",
    "\t\t\t\t# Initialize all biases to 0\n",
    "\t\t\t\tif 'bias' in name:\n",
    "\t\t\t\t\tnn.init.constant_(param, 0.0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif 'lstm' in name:\n",
    "\t\t\t\t\t\t# Initialize gate weights (followed by sigmoid) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[:self.hidden_size*2,:])\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[self.hidden_size*3:,:])\n",
    "\t\t\t\t\t\t# Initialize input->hidden and hidden->hidden weights (followed by tanh) using Xavier normal distribution with gain = \n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param[self.hidden_size*2:self.hidden_size*3,:], gain=5.0/3.0)\n",
    "\t\t\t\t\telif 'key_w' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for key output layer (followed by ReLU) using Kaiming normal distribution\n",
    "\t\t\t\t\t\tnn.init.kaiming_normal_(param, nonlinearity='relu')\n",
    "\t\t\t\t\telif 'g_out' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for gate output layer (followed by sigmoid) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param)\n",
    "\t\t\t\t\telif 'y_out' in name:\n",
    "\t\t\t\t\t\t# Initialize weights for multiple-choice output layer (followed by softmax) using Xavier normal distribution\n",
    "\t\t\t\t\t\tnn.init.xavier_normal_(param)\n",
    "\tdef forward(self, x_seq, device):\n",
    "\t\t# Encode all images in sequence\n",
    "\t\tz_seq = []\n",
    "\t\tfor t in range(x_seq.shape[1]):\n",
    "\t\t\tx_t = x_seq[:,t,:,:].unsqueeze(1)\n",
    "\t\t\tz_t = self.encoder(x_t)\n",
    "\t\t\tz_seq.append(z_t)\n",
    "\t\tz_seq = torch.stack(z_seq, dim=1)\n",
    "\t\tif self.contextnorm:\n",
    "\t\t\tz_seq_all_seg = []\n",
    "\t\t\tfor seg in range(len(self.task_seg)):\n",
    "\t\t\t\tz_seq_all_seg.append(self.apply_context_norm(z_seq[:,self.task_seg[seg],:]))\n",
    "\t\t\tz_seq = torch.cat(z_seq_all_seg, dim=1)\n",
    "\t\t# Initialize hidden state\n",
    "\t\thidden = torch.zeros(1, x_seq.shape[0], self.hidden_size).to(device)\n",
    "\t\tcell_state = torch.zeros(1, x_seq.shape[0], self.hidden_size).to(device)\n",
    "\t\t# Initialize retrieved key vector\n",
    "\t\tkey_r = torch.zeros(x_seq.shape[0], 1, self.key_size + 1).to(device)\n",
    "\t\t# Memory model (extra time step to process key retrieved on final time step)\n",
    "\t\tfor t in range(x_seq.shape[1] + 1):\n",
    "\t\t\t# Image embedding\n",
    "\t\t\tif t == x_seq.shape[1]:\n",
    "\t\t\t\tz_t = torch.zeros(x_seq.shape[0], 1, self.z_size).to(device)\n",
    "\t\t\telse:\n",
    "\t\t\t\tz_t = z_seq[:,t,:].unsqueeze(1)\n",
    "\t\t\t# Controller\n",
    "\t\t\t# LSTM\n",
    "\t\t\tlstm_out, (hidden, cell_state) = self.lstm(key_r, (hidden, cell_state))\n",
    "\t\t\t# Key output layers\n",
    "\t\t\tkey_w = self.relu(self.key_w_out(lstm_out))\n",
    "\t\t\t# Gates\n",
    "\t\t\tg = self.sigmoid(self.g_out(lstm_out))\n",
    "\t\t\t# Task output layer\n",
    "\t\t\ty_pred_linear = self.y_out(lstm_out).squeeze()\n",
    "\t\t\ty_pred = y_pred_linear.argmax(1)\n",
    "\t\t\t# Read from memory\n",
    "\t\t\tif t == 0:\n",
    "\t\t\t\tkey_r = torch.zeros(x_seq.shape[0], 1, self.key_size + 1).to(device)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Read key\n",
    "\t\t\t\tw_k = self.softmax((z_t * M_v).sum(dim=2))\n",
    "\t\t\t\tc_k = self.sigmoid(((z_t * M_v).sum(dim=2) * self.confidence_gain) + self.confidence_bias)\n",
    "\t\t\t\tkey_r = g * (torch.cat([M_k, c_k.unsqueeze(2)], dim=2) * w_k.unsqueeze(2)).sum(1).unsqueeze(1)\n",
    "\t\t\t# Write to memory\n",
    "\t\t\tif t == 0:\n",
    "\t\t\t\tM_k = key_w\n",
    "\t\t\t\tM_v = z_t\n",
    "\t\t\telse:\n",
    "\t\t\t\tM_k = torch.cat([M_k, key_w], dim=1)\n",
    "\t\t\t\tM_v = torch.cat([M_v, z_t], dim=1)\n",
    "\t\treturn y_pred_linear, y_pred\n",
    "\tdef apply_context_norm(self, z_seq):\n",
    "\t\teps = 1e-8\n",
    "\t\tz_mu = z_seq.mean(1)\n",
    "\t\tz_sigma = (z_seq.var(1) + eps).sqrt()\n",
    "\t\tz_seq = (z_seq - z_mu.unsqueeze(1)) / z_sigma.unsqueeze(1)\n",
    "\t\tz_seq = (z_seq * self.gamma) + self.beta\n",
    "\t\treturn z_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80d2e2a7-51b2-4882-a2a9-39c7a9511b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CustomImageDataset(training_set)\n",
    "train_dataloader = DataLoader(training_set, batch_size=32, shuffle=True)\n",
    "test_set = CustomImageDataset(test_set)\n",
    "test_dataloader = DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9b41df4-aaa4-4e05-be80-c63a0e584bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 9, 32, 32])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,0,:,:].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b424614-729f-441d-87b1-56187400995b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 9, 32, 32])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,0,:,:].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65c2b27d-fb1c-4d69-bdd5-0fb51cf6a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(device, epoch, train_loader, model, optimizer):\n",
    "\tmodel.train()\n",
    "\t# Iterate over batches\n",
    "\tfor batch_idx, (X, y) in enumerate(train_loader):\n",
    "\t\t# Batch start time\n",
    "\t\tstart_time = time.time()\n",
    "\t\t# Use sequence indices to slice corresponding images\n",
    "\t\t#x_seq = all_imgs[seq_ind,:,:]\n",
    "\t\tx_seq = X.float()\n",
    "\t\t#print(\"x_seq.shape =\",x_seq.shape)\n",
    "\t\t# Load data to device\n",
    "\t\tx_seq = x_seq.to(device)\n",
    "\t\t#y = torch.nn.functional.one_hot(y,num_classes=4)\n",
    "\t\t#print(\"y =\",y)\n",
    "\t\ty = y.to(device)\n",
    "\t\t# Zero out gradients for optimizer \n",
    "\t\toptimizer.zero_grad()\n",
    "\t\t# Run model \n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\ty_pred_linear, y_pred, const_loss = model(x_seq, device)\n",
    "\t\telse:\n",
    "\t\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t'''\n",
    "\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t# Loss\n",
    "\t\tloss_fn = nn.CrossEntropyLoss()\n",
    "\t\tloss = loss_fn(y_pred_linear, y)\n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\tloss += const_loss\n",
    "\t\t'''\n",
    "\t\t# Update model\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t# Batch duration\n",
    "\t\tend_time = time.time()\n",
    "\t\tbatch_dur = end_time - start_time\n",
    "\t\t# Report prgoress\n",
    "\t\t#if batch_idx % args.log_interval == 0:\n",
    "\t\tif batch_idx % 10 == 0:\n",
    "\t\t\t# Accuracy\n",
    "\t\t\tacc = torch.eq(y_pred, y).float().mean().item() * 100.0\n",
    "\t\t\t# Report \t\n",
    "\t\t\tlog.info('[Epoch: ' + str(epoch) + '] ' + \\\n",
    "\t\t\t\t\t '[Batch: ' + str(batch_idx) + ' of ' + str(len(train_loader)) + '] ' + \\\n",
    "\t\t\t\t\t '[Loss = ' + '{:.4f}'.format(loss.item()) + '] ' + \\\n",
    "\t\t\t\t\t '[Accuracy = ' + '{:.2f}'.format(acc) + '] ' + \\\n",
    "\t\t\t\t\t '[' + '{:.3f}'.format(batch_dur) + ' sec/batch]')\n",
    "\t\t\t# Save progress to file\n",
    "\t\t\t'''\n",
    "\t\t\ttrain_prog_f.write(str(batch_idx) + ' ' +\\\n",
    "\t\t\t\t\t\t\t   '{:.4f}'.format(loss.item()) + ' ' + \\\n",
    "\t\t\t\t\t\t\t   '{:.2f}'.format(acc) + '\\n')\n",
    "\t\t\t'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6444ff38-679c-47c2-85ac-8ca5b1e108f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(device, epoch, test_loader, model):\n",
    "\tlog.info('Evaluating on test set...')\n",
    "\t# Set to eval mode\n",
    "\tmodel.eval()\n",
    "\t# Iterate over batches\n",
    "\tall_acc = []\n",
    "\tall_loss = []\n",
    "\tfor batch_idx, (X, y) in enumerate(test_loader):\n",
    "\t\t# Use sequence indices to slice corresponding images\n",
    "\t\tx_seq = X.float()\n",
    "\t\t# Load data to device\n",
    "\t\tx_seq = x_seq.to(device)\n",
    "\t\t#y = torch.nn.functional.one_hot(y,num_classes=4)\n",
    "\t\ty = y.to(device)\n",
    "\t\t# Run model \n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\ty_pred_linear, y_pred, const_loss = model(x_seq, device)\n",
    "\t\telse:\n",
    "\t\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t'''\n",
    "\t\ty_pred_linear, y_pred = model(x_seq, device)\n",
    "\t\t# Loss\n",
    "\t\tloss_fn = nn.CrossEntropyLoss()\n",
    "\t\tloss = loss_fn(y_pred_linear, y)\n",
    "\t\t'''\n",
    "\t\tif 'MNM' in args.model_name:\n",
    "\t\t\tloss += const_loss\n",
    "\t\t'''\n",
    "\t\tall_loss.append(loss.item())\n",
    "\t\t# Accuracy\n",
    "\t\tacc = torch.eq(y_pred, y).float().mean().item() * 100.0\n",
    "\t\tall_acc.append(acc)\n",
    "\t\t# Report progress\n",
    "\t\tlog.info('[Batch: ' + str(batch_idx) + ' of ' + str(len(test_loader)) + ']')\n",
    "\t# Report overall test performance\n",
    "\tavg_loss = np.mean(all_loss)\n",
    "\tavg_acc = np.mean(all_acc)\n",
    "\tlog.info('[Summary] ' + \\\n",
    "\t\t\t '[Loss = ' + '{:.4f}'.format(avg_loss) + '] ' + \\\n",
    "\t\t\t '[Accuracy = ' + '{:.2f}'.format(avg_acc) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27f64254-c0b3-4303-a9a7-953256157938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 01:19:31,763] Building encoder...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:31,764] Building convolutional encoder...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:31,764] Conv layers...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:31,766] FC layers...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:31,770] Building LSTM and output layers...\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:31,847] [Epoch: 1] [Batch: 0 of 313] [Loss = 1.3889] [Accuracy = 25.00] [0.029 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 01:19:32,142] [Epoch: 1] [Batch: 10 of 313] [Loss = 1.3803] [Accuracy = 28.12] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:32,436] [Epoch: 1] [Batch: 20 of 313] [Loss = 1.3728] [Accuracy = 25.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:32,713] [Epoch: 1] [Batch: 30 of 313] [Loss = 1.3370] [Accuracy = 31.25] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:33,010] [Epoch: 1] [Batch: 40 of 313] [Loss = 1.1886] [Accuracy = 53.12] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:33,318] [Epoch: 1] [Batch: 50 of 313] [Loss = 0.4288] [Accuracy = 84.38] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:33,612] [Epoch: 1] [Batch: 60 of 313] [Loss = 0.1013] [Accuracy = 96.88] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:33,911] [Epoch: 1] [Batch: 70 of 313] [Loss = 0.0865] [Accuracy = 96.88] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:34,195] [Epoch: 1] [Batch: 80 of 313] [Loss = 0.0496] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:34,507] [Epoch: 1] [Batch: 90 of 313] [Loss = 0.0062] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:34,800] [Epoch: 1] [Batch: 100 of 313] [Loss = 0.0090] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:35,092] [Epoch: 1] [Batch: 110 of 313] [Loss = 0.0054] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:35,379] [Epoch: 1] [Batch: 120 of 313] [Loss = 0.0046] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:35,679] [Epoch: 1] [Batch: 130 of 313] [Loss = 0.0019] [Accuracy = 100.00] [0.032 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:35,976] [Epoch: 1] [Batch: 140 of 313] [Loss = 0.0026] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:36,278] [Epoch: 1] [Batch: 150 of 313] [Loss = 0.0035] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:36,568] [Epoch: 1] [Batch: 160 of 313] [Loss = 0.0031] [Accuracy = 100.00] [0.026 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:36,861] [Epoch: 1] [Batch: 170 of 313] [Loss = 0.0024] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:37,155] [Epoch: 1] [Batch: 180 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:37,439] [Epoch: 1] [Batch: 190 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:37,728] [Epoch: 1] [Batch: 200 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:38,024] [Epoch: 1] [Batch: 210 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:38,323] [Epoch: 1] [Batch: 220 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:38,600] [Epoch: 1] [Batch: 230 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.029 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:38,894] [Epoch: 1] [Batch: 240 of 313] [Loss = 0.0010] [Accuracy = 100.00] [0.024 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:39,184] [Epoch: 1] [Batch: 250 of 313] [Loss = 0.0007] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:39,484] [Epoch: 1] [Batch: 260 of 313] [Loss = 0.0015] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:39,783] [Epoch: 1] [Batch: 270 of 313] [Loss = 0.0008] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:40,075] [Epoch: 1] [Batch: 280 of 313] [Loss = 0.0008] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:40,351] [Epoch: 1] [Batch: 290 of 313] [Loss = 0.0013] [Accuracy = 100.00] [0.022 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:40,648] [Epoch: 1] [Batch: 300 of 313] [Loss = 0.0070] [Accuracy = 100.00] [0.030 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:40,933] [Epoch: 1] [Batch: 310 of 313] [Loss = 0.0049] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:41,016] [Epoch: 2] [Batch: 0 of 313] [Loss = 0.0020] [Accuracy = 100.00] [0.027 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2021-05-20 01:19:41,307] [Epoch: 2] [Batch: 10 of 313] [Loss = 0.0012] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:41,600] [Epoch: 2] [Batch: 20 of 313] [Loss = 0.0008] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:41,896] [Epoch: 2] [Batch: 30 of 313] [Loss = 0.0009] [Accuracy = 100.00] [0.032 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:42,182] [Epoch: 2] [Batch: 40 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:42,471] [Epoch: 2] [Batch: 50 of 313] [Loss = 0.0029] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:42,767] [Epoch: 2] [Batch: 60 of 313] [Loss = 0.0015] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:43,060] [Epoch: 2] [Batch: 70 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.023 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:43,340] [Epoch: 2] [Batch: 80 of 313] [Loss = 0.0037] [Accuracy = 100.00] [0.028 sec/batch]\u001b[0m\n",
      "\u001b[37m\u001b[01m[2021-05-20 01:19:43,619] [Epoch: 2] [Batch: 90 of 313] [Loss = 0.0011] [Accuracy = 100.00] [0.031 sec/batch]\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-aa2ca3680a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-dbeb63982852>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(device, epoch, train_loader, model, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0my_pred_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \t\t'''\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0my_pred_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;31m# Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-c45574a215a8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_seq, device)\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                         \u001b[0;31m# Key output layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                         \u001b[0mkey_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_w_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                         \u001b[0;31m# Gates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \"\"\"\n\u001b[0;32m-> 1201\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-4\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "device = torch.device(\"cuda:\" + str(0))\n",
    "model = Model().to(device)\n",
    "# Initialize the loss function\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(device, t+1, train_dataloader, model, optimizer)\n",
    "test_loop(device,t, test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb18591-ae59-4811-9cc5-c23bc0965e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
