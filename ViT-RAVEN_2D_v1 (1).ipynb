{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mineral-corps",
   "metadata": {},
   "source": [
    "# ViT Example on MNIST\n",
    "\n",
    "Adapted from: [https://keras.io/examples/vision/image_classification_with_vision_transformer/](https://keras.io/examples/vision/image_classification_with_vision_transformer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "narrow-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "olympic-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_npz_img(img_path):\n",
    "    data = np.load(img_path)\n",
    "    img = data['image']\n",
    "    target = data['target']\n",
    "    x = img[:,:,:]\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    #x = x.reshape((x.shape[0],x.shape[1],x.shape[2],x.shape[3],1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unavailable-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_npz_target(target_path):\n",
    "    data = np.load(target_path)\n",
    "    target = data['target']\n",
    "    y = int(target)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "third-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(folder,num_imgs,config):\n",
    "    X = []\n",
    "    #X = np.array(X)\n",
    "    Y =[]\n",
    "    #for i in range(num_imgs):\n",
    "    name = ''\n",
    "    if config=='train':\n",
    "        name = 'train'\n",
    "    elif config=='validate':\n",
    "        name = 'val'\n",
    "    else:\n",
    "        name = 'test'\n",
    "        \n",
    "    count = 0\n",
    "    i = 0\n",
    "    while count < num_imgs:\n",
    "        try:\n",
    "            x = grab_npz_img('./RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            y = grab_npz_target('./RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            i += 1\n",
    "        except:\n",
    "            i += 1\n",
    "            continue\n",
    "        X.append(x)\n",
    "        #X = np.concatenate(x)\n",
    "        Y.append(y)\n",
    "        count += 1\n",
    "    X = np.array(X)\n",
    "    X = np.squeeze(X)\n",
    "    #X = np.expand_dims(X, axis=4)\n",
    "    #X = X.reshape((X.shape[0],X.shape[2],X.shape[3],X.shape[1]))\n",
    "    X = np.moveaxis(X, 1, -1)\n",
    "    return X,np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worthy-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_3d(folder,num_imgs,config):\n",
    "    X = []\n",
    "    #X = np.array(X)\n",
    "    Y =[]\n",
    "    #for i in range(num_imgs):\n",
    "    \n",
    "    name = ''\n",
    "    if config=='train':\n",
    "        name = 'train'\n",
    "    elif config=='validate':\n",
    "        name = 'val'\n",
    "    else:\n",
    "        name = 'test'\n",
    "        \n",
    "    count = 0\n",
    "    i = 0\n",
    "    while count < num_imgs:\n",
    "        try:\n",
    "            x = grab_npz_img('./RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            y = grab_npz_target('./RAVEN-10000/'+folder+'/RAVEN_%d_%s.npz'%(i,name))\n",
    "            i += 1\n",
    "        except:\n",
    "            i += 1\n",
    "            continue\n",
    "        X.append(x)\n",
    "        #X = np.concatenate(x)\n",
    "        Y.append(y)\n",
    "        count += 1\n",
    "    X = np.array(X)\n",
    "    X = np.squeeze(X)\n",
    "    X = np.expand_dims(X, axis=4)\n",
    "    return X,np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "closing-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr = 0.01, embed_dim = 8192.0, warmup_steps = 100.0):\n",
    "    arg1 = tf.math.rsqrt(tf.cast(epoch,'float32'))\n",
    "    arg2 = epoch * (warmup_steps ** -1.5)\n",
    "    return tf.math.rsqrt(embed_dim) * tf.math.minimum(arg1,arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adjacent-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'center_single'\n",
    "#folder = 'in_center_single_out_center_single'\n",
    "num_imgs = 5000\n",
    "val_split = 0.1\n",
    "x_train,y_train = create_dataset(folder,num_imgs,'train')\n",
    "x_val,y_val = create_dataset(folder,num_imgs*val_split,'validate')\n",
    "x_test,y_test = create_dataset(folder,num_imgs*val_split,'test')\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_val /= 255\n",
    "#x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "surface-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train ,num_classes=8)\n",
    "y_val = keras.utils.to_categorical(y_val,num_classes=8)\n",
    "y_test = keras.utils.to_categorical(y_test,num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eligible-battery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 160, 160, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(500, 160, 160, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(500, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "'''\n",
    "display(x_train.shape)\n",
    "display(y_train.shape)\n",
    "display(x_test.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defined-speaker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx_train = x_train.astype('float32').reshape(x_train.shape+(1,))\\nx_test = x_test.astype('float32').reshape(x_test.shape+(1,))\\nx_train /= 255\\nx_test /= 255\\n\\n# Convert class vector [0-9] to categorical assignments (one-hot)\\n# y_train = keras.utils.to_categorical(y_train, len(np.unique(y_train)))\\n# y_test = keras.utils.to_categorical(y_test, len(np.unique(y_test)))\\n\\ndisplay(x_train.shape)\\ndisplay(y_train.shape)\\ndisplay(x_test.shape)\\ndisplay(y_test.shape)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Standardize the -input- data between 0.0-1.0 (real)\n",
    "## instead of the default 0-255 (integer)\n",
    "'''\n",
    "x_train = x_train.astype('float32').reshape(x_train.shape+(1,))\n",
    "x_test = x_test.astype('float32').reshape(x_test.shape+(1,))\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vector [0-9] to categorical assignments (one-hot)\n",
    "# y_train = keras.utils.to_categorical(y_train, len(np.unique(y_train)))\n",
    "# y_test = keras.utils.to_categorical(y_test, len(np.unique(y_test)))\n",
    "\n",
    "display(x_train.shape)\n",
    "display(y_train.shape)\n",
    "display(x_test.shape)\n",
    "display(y_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "trying-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8\n",
    "input_shape = (160, 160, 16)\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 1000\n",
    "image_size = 160  # We'll resize input images to this size\n",
    "patch_size = 40 # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "minute-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Normalization(),\n",
    "        layers.experimental.preprocessing.Resizing(image_size, image_size),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
    "        layers.experimental.preprocessing.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interstate-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suitable-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-2] # x already embedded\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "physical-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    '''\n",
    "    inputs = layers.Input(shape=(x_train.shape[1],\n",
    "                                            x_train.shape[2],\n",
    "                                            x_train.shape[3],\n",
    "                                            x_train.shape[4]))\n",
    "    '''\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    #augmented = inputs\n",
    "    # Create patches.\n",
    "    # patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    # encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "    \n",
    "    patches = keras.layers.Conv2D(projection_dim,\n",
    "                                  kernel_size=(patch_size,patch_size),\n",
    "                                  strides=(patch_size,patch_size))(augmented)\n",
    "    \n",
    "    #augmented = keras.layers.Reshape((160, 160, 16, 1))(augmented)\n",
    "    '''\n",
    "    patches = keras.layers.Conv3D(projection_dim,\n",
    "                                  kernel_size=(patch_size,patch_size,1),\n",
    "                                  strides=(patch_size,patch_size,1))(augmented)\n",
    "    '''\n",
    "    patches = keras.layers.Reshape((-1,projection_dim))(patches)\n",
    "    position_embedding = PositionEmbedding(patches.shape[-2],\n",
    "                                           projection_dim)\n",
    "    encoded_patches = position_embedding(patches)\n",
    "    \n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    #representation = layers.Flatten()(representation)\n",
    "    representation = layers.GlobalAveragePooling1D()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alternate-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.TopKCategoricalAccuracy(4, name=\"top-4-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "    scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback,scheduler_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "046ef86b-9f61-4aa8-b870-f0b55ac5cab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 160, 16 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "data_augmentation (Sequential)  (None, 160, 160, 16) 33          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 4, 4, 64)     1638464     data_augmentation[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 16, 64)       0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding (PositionEmb (None, 16, 64)       1024        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 16, 64)       128         position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 16, 64)       66368       layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 64)       0           multi_head_attention[0][0]       \n",
      "                                                                 position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 16, 64)       128         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16, 128)      8320        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16, 128)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16, 64)       8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 64)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 64)       0           dropout_1[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 16, 64)       128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 16, 64)       66368       layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 64)       0           multi_head_attention_1[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 16, 64)       128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16, 128)      8320        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 128)      0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16, 64)       8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 64)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 64)       0           dropout_3[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 16, 64)       128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 16, 64)       66368       layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 64)       0           multi_head_attention_2[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 16, 64)       128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16, 128)      8320        layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 128)      0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16, 64)       8256        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 64)       0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 64)       0           dropout_5[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 16, 64)       128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 16, 64)       66368       layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 64)       0           multi_head_attention_3[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 16, 64)       128         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16, 128)      8320        layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 128)      0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16, 64)       8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16, 64)       0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 64)       0           dropout_7[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 16, 64)       128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 16, 64)       66368       layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 64)       0           multi_head_attention_4[0][0]     \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 16, 64)       128         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16, 128)      8320        layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 128)      0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16, 64)       8256        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 64)       0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 64)       0           dropout_9[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, 16, 64)       128         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 16, 64)       66368       layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 64)       0           multi_head_attention_5[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, 16, 64)       128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16, 128)      8320        layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 128)      0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16, 64)       8256        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 64)       0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 64)       0           dropout_11[0][0]                 \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 16, 64)       128         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, 16, 64)       66368       layer_normalization_12[0][0]     \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 64)       0           multi_head_attention_6[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 16, 64)       128         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 16, 128)      8320        layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 128)      0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16, 64)       8256        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 64)       0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 64)       0           dropout_13[0][0]                 \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 16, 64)       128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, 16, 64)       66368       layer_normalization_14[0][0]     \n",
      "                                                                 layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 64)       0           multi_head_attention_7[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, 16, 64)       128         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16, 128)      8320        layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 128)      0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 16, 64)       8256        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 64)       0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 64)       0           dropout_15[0][0]                 \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 16, 64)       128         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64)           0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2048)         133120      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 2048)         0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1024)         2098176     dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1024)         0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 8)            8200        dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,544,745\n",
      "Trainable params: 4,544,712\n",
      "Non-trainable params: 33\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "71/71 [==============================] - 11s 61ms/step - loss: 2.0935 - accuracy: 0.1157 - top-4-accuracy: 0.4988 - val_loss: 2.0793 - val_accuracy: 0.1280 - val_top-4-accuracy: 0.5060\n",
      "Epoch 2/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0906 - accuracy: 0.1233 - top-4-accuracy: 0.5012 - val_loss: 2.0768 - val_accuracy: 0.1380 - val_top-4-accuracy: 0.5360\n",
      "Epoch 3/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 2.0837 - accuracy: 0.1379 - top-4-accuracy: 0.5135 - val_loss: 2.0775 - val_accuracy: 0.1280 - val_top-4-accuracy: 0.5280\n",
      "Epoch 4/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 2.0819 - accuracy: 0.1397 - top-4-accuracy: 0.5227 - val_loss: 2.0797 - val_accuracy: 0.1080 - val_top-4-accuracy: 0.5080\n",
      "Epoch 5/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0826 - accuracy: 0.1322 - top-4-accuracy: 0.5128 - val_loss: 2.0769 - val_accuracy: 0.1320 - val_top-4-accuracy: 0.5360\n",
      "Epoch 6/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0865 - accuracy: 0.1208 - top-4-accuracy: 0.5108 - val_loss: 2.0767 - val_accuracy: 0.1280 - val_top-4-accuracy: 0.5320\n",
      "Epoch 7/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0819 - accuracy: 0.1332 - top-4-accuracy: 0.5221 - val_loss: 2.0831 - val_accuracy: 0.1240 - val_top-4-accuracy: 0.4980\n",
      "Epoch 8/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0798 - accuracy: 0.1353 - top-4-accuracy: 0.5304 - val_loss: 2.0805 - val_accuracy: 0.1080 - val_top-4-accuracy: 0.5220\n",
      "Epoch 9/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0749 - accuracy: 0.1540 - top-4-accuracy: 0.5385 - val_loss: 2.0788 - val_accuracy: 0.1180 - val_top-4-accuracy: 0.5460\n",
      "Epoch 10/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0784 - accuracy: 0.1340 - top-4-accuracy: 0.5280 - val_loss: 2.0774 - val_accuracy: 0.1460 - val_top-4-accuracy: 0.5620\n",
      "Epoch 11/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0744 - accuracy: 0.1433 - top-4-accuracy: 0.5475 - val_loss: 2.0802 - val_accuracy: 0.1120 - val_top-4-accuracy: 0.5140\n",
      "Epoch 12/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0777 - accuracy: 0.1327 - top-4-accuracy: 0.5354 - val_loss: 2.0827 - val_accuracy: 0.1100 - val_top-4-accuracy: 0.5200\n",
      "Epoch 13/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 2.0741 - accuracy: 0.1409 - top-4-accuracy: 0.5463 - val_loss: 2.0799 - val_accuracy: 0.1280 - val_top-4-accuracy: 0.5360\n",
      "Epoch 14/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0791 - accuracy: 0.1457 - top-4-accuracy: 0.5256 - val_loss: 2.0834 - val_accuracy: 0.1260 - val_top-4-accuracy: 0.5280\n",
      "Epoch 15/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0751 - accuracy: 0.1348 - top-4-accuracy: 0.5317 - val_loss: 2.0804 - val_accuracy: 0.1300 - val_top-4-accuracy: 0.5120\n",
      "Epoch 16/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0699 - accuracy: 0.1420 - top-4-accuracy: 0.5538 - val_loss: 2.0860 - val_accuracy: 0.1420 - val_top-4-accuracy: 0.5140\n",
      "Epoch 17/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 2.0700 - accuracy: 0.1505 - top-4-accuracy: 0.5556 - val_loss: 2.0781 - val_accuracy: 0.1400 - val_top-4-accuracy: 0.5060\n",
      "Epoch 18/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0737 - accuracy: 0.1376 - top-4-accuracy: 0.5474 - val_loss: 2.0797 - val_accuracy: 0.1140 - val_top-4-accuracy: 0.5260\n",
      "Epoch 19/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0699 - accuracy: 0.1606 - top-4-accuracy: 0.5442 - val_loss: 2.0759 - val_accuracy: 0.1380 - val_top-4-accuracy: 0.5260\n",
      "Epoch 20/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0708 - accuracy: 0.1453 - top-4-accuracy: 0.5533 - val_loss: 2.0763 - val_accuracy: 0.1400 - val_top-4-accuracy: 0.5300\n",
      "Epoch 21/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0758 - accuracy: 0.1384 - top-4-accuracy: 0.5389 - val_loss: 2.0753 - val_accuracy: 0.1540 - val_top-4-accuracy: 0.5400\n",
      "Epoch 22/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0709 - accuracy: 0.1546 - top-4-accuracy: 0.5617 - val_loss: 2.0724 - val_accuracy: 0.1560 - val_top-4-accuracy: 0.5240\n",
      "Epoch 23/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0676 - accuracy: 0.1503 - top-4-accuracy: 0.5635 - val_loss: 2.0701 - val_accuracy: 0.1460 - val_top-4-accuracy: 0.5700\n",
      "Epoch 24/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0652 - accuracy: 0.1463 - top-4-accuracy: 0.5634 - val_loss: 2.0690 - val_accuracy: 0.1620 - val_top-4-accuracy: 0.5280\n",
      "Epoch 25/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0717 - accuracy: 0.1461 - top-4-accuracy: 0.5470 - val_loss: 2.0621 - val_accuracy: 0.1640 - val_top-4-accuracy: 0.5480\n",
      "Epoch 26/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 2.0683 - accuracy: 0.1490 - top-4-accuracy: 0.5534 - val_loss: 2.0699 - val_accuracy: 0.1320 - val_top-4-accuracy: 0.5740\n",
      "Epoch 27/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 2.0680 - accuracy: 0.1592 - top-4-accuracy: 0.5521 - val_loss: 2.0623 - val_accuracy: 0.1420 - val_top-4-accuracy: 0.5720\n",
      "Epoch 28/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0618 - accuracy: 0.1457 - top-4-accuracy: 0.5690 - val_loss: 2.0565 - val_accuracy: 0.1420 - val_top-4-accuracy: 0.5780\n",
      "Epoch 29/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0570 - accuracy: 0.1590 - top-4-accuracy: 0.5750 - val_loss: 2.0626 - val_accuracy: 0.1440 - val_top-4-accuracy: 0.5740\n",
      "Epoch 30/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0518 - accuracy: 0.1737 - top-4-accuracy: 0.5782 - val_loss: 2.0563 - val_accuracy: 0.1260 - val_top-4-accuracy: 0.5760\n",
      "Epoch 31/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0494 - accuracy: 0.1636 - top-4-accuracy: 0.5692 - val_loss: 2.0562 - val_accuracy: 0.1440 - val_top-4-accuracy: 0.5560\n",
      "Epoch 32/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0466 - accuracy: 0.1714 - top-4-accuracy: 0.5927 - val_loss: 2.0481 - val_accuracy: 0.1360 - val_top-4-accuracy: 0.5780\n",
      "Epoch 33/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 2.0438 - accuracy: 0.1639 - top-4-accuracy: 0.5928 - val_loss: 2.0429 - val_accuracy: 0.1680 - val_top-4-accuracy: 0.5880\n",
      "Epoch 34/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0359 - accuracy: 0.1682 - top-4-accuracy: 0.6013 - val_loss: 2.0543 - val_accuracy: 0.1580 - val_top-4-accuracy: 0.5580\n",
      "Epoch 35/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0312 - accuracy: 0.1735 - top-4-accuracy: 0.6025 - val_loss: 2.0187 - val_accuracy: 0.1820 - val_top-4-accuracy: 0.6060\n",
      "Epoch 36/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0218 - accuracy: 0.1965 - top-4-accuracy: 0.6077 - val_loss: 2.0168 - val_accuracy: 0.1980 - val_top-4-accuracy: 0.6140\n",
      "Epoch 37/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 2.0260 - accuracy: 0.1739 - top-4-accuracy: 0.6158 - val_loss: 2.0071 - val_accuracy: 0.1780 - val_top-4-accuracy: 0.6300\n",
      "Epoch 38/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 2.0148 - accuracy: 0.1968 - top-4-accuracy: 0.6268 - val_loss: 1.9957 - val_accuracy: 0.2060 - val_top-4-accuracy: 0.6240\n",
      "Epoch 39/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 2.0115 - accuracy: 0.1818 - top-4-accuracy: 0.6267 - val_loss: 1.9932 - val_accuracy: 0.1880 - val_top-4-accuracy: 0.6340\n",
      "Epoch 40/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9985 - accuracy: 0.1743 - top-4-accuracy: 0.6383 - val_loss: 1.9758 - val_accuracy: 0.2100 - val_top-4-accuracy: 0.6560\n",
      "Epoch 41/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9845 - accuracy: 0.2007 - top-4-accuracy: 0.6587 - val_loss: 1.9954 - val_accuracy: 0.2000 - val_top-4-accuracy: 0.6420\n",
      "Epoch 42/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 2.0048 - accuracy: 0.1711 - top-4-accuracy: 0.6460 - val_loss: 1.9884 - val_accuracy: 0.1960 - val_top-4-accuracy: 0.6520\n",
      "Epoch 43/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9896 - accuracy: 0.2010 - top-4-accuracy: 0.6501 - val_loss: 1.9841 - val_accuracy: 0.1640 - val_top-4-accuracy: 0.6680\n",
      "Epoch 44/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9728 - accuracy: 0.1948 - top-4-accuracy: 0.6726 - val_loss: 1.9588 - val_accuracy: 0.2080 - val_top-4-accuracy: 0.6680\n",
      "Epoch 45/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9779 - accuracy: 0.2010 - top-4-accuracy: 0.6590 - val_loss: 1.9605 - val_accuracy: 0.1900 - val_top-4-accuracy: 0.6920\n",
      "Epoch 46/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9664 - accuracy: 0.2091 - top-4-accuracy: 0.6687 - val_loss: 1.9512 - val_accuracy: 0.2480 - val_top-4-accuracy: 0.6660\n",
      "Epoch 47/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9513 - accuracy: 0.2094 - top-4-accuracy: 0.6810 - val_loss: 1.9561 - val_accuracy: 0.2140 - val_top-4-accuracy: 0.6940\n",
      "Epoch 48/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9584 - accuracy: 0.2146 - top-4-accuracy: 0.6741 - val_loss: 1.9519 - val_accuracy: 0.2240 - val_top-4-accuracy: 0.6760\n",
      "Epoch 49/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9689 - accuracy: 0.2107 - top-4-accuracy: 0.6615 - val_loss: 1.9417 - val_accuracy: 0.2120 - val_top-4-accuracy: 0.6980\n",
      "Epoch 50/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9364 - accuracy: 0.2341 - top-4-accuracy: 0.6977 - val_loss: 1.9453 - val_accuracy: 0.2360 - val_top-4-accuracy: 0.6820\n",
      "Epoch 51/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9310 - accuracy: 0.2139 - top-4-accuracy: 0.6932 - val_loss: 1.9094 - val_accuracy: 0.2400 - val_top-4-accuracy: 0.7080\n",
      "Epoch 52/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9353 - accuracy: 0.2337 - top-4-accuracy: 0.6812 - val_loss: 1.9411 - val_accuracy: 0.2180 - val_top-4-accuracy: 0.7020\n",
      "Epoch 53/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9549 - accuracy: 0.2144 - top-4-accuracy: 0.6729 - val_loss: 1.9608 - val_accuracy: 0.2340 - val_top-4-accuracy: 0.6840\n",
      "Epoch 54/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9395 - accuracy: 0.2114 - top-4-accuracy: 0.7074 - val_loss: 1.9420 - val_accuracy: 0.2300 - val_top-4-accuracy: 0.6980\n",
      "Epoch 55/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9252 - accuracy: 0.2188 - top-4-accuracy: 0.6951 - val_loss: 1.9350 - val_accuracy: 0.2320 - val_top-4-accuracy: 0.6820\n",
      "Epoch 56/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9058 - accuracy: 0.2329 - top-4-accuracy: 0.7248 - val_loss: 1.9236 - val_accuracy: 0.2280 - val_top-4-accuracy: 0.7160\n",
      "Epoch 57/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9253 - accuracy: 0.2227 - top-4-accuracy: 0.7032 - val_loss: 1.9200 - val_accuracy: 0.2320 - val_top-4-accuracy: 0.7020\n",
      "Epoch 58/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9117 - accuracy: 0.2335 - top-4-accuracy: 0.7110 - val_loss: 1.9347 - val_accuracy: 0.2240 - val_top-4-accuracy: 0.6920\n",
      "Epoch 59/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.9095 - accuracy: 0.2315 - top-4-accuracy: 0.6948 - val_loss: 1.9122 - val_accuracy: 0.2120 - val_top-4-accuracy: 0.7180\n",
      "Epoch 60/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8975 - accuracy: 0.2416 - top-4-accuracy: 0.7217 - val_loss: 1.9119 - val_accuracy: 0.2080 - val_top-4-accuracy: 0.7060\n",
      "Epoch 61/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.9151 - accuracy: 0.2291 - top-4-accuracy: 0.7173 - val_loss: 1.9065 - val_accuracy: 0.2440 - val_top-4-accuracy: 0.7140\n",
      "Epoch 62/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8920 - accuracy: 0.2400 - top-4-accuracy: 0.7339 - val_loss: 1.9080 - val_accuracy: 0.2540 - val_top-4-accuracy: 0.6980\n",
      "Epoch 63/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8810 - accuracy: 0.2681 - top-4-accuracy: 0.7300 - val_loss: 1.9139 - val_accuracy: 0.2360 - val_top-4-accuracy: 0.7180\n",
      "Epoch 64/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8831 - accuracy: 0.2501 - top-4-accuracy: 0.7236 - val_loss: 1.9014 - val_accuracy: 0.2240 - val_top-4-accuracy: 0.7440\n",
      "Epoch 65/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8934 - accuracy: 0.2372 - top-4-accuracy: 0.7174 - val_loss: 1.8960 - val_accuracy: 0.2100 - val_top-4-accuracy: 0.7260\n",
      "Epoch 66/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8857 - accuracy: 0.2333 - top-4-accuracy: 0.7254 - val_loss: 1.9262 - val_accuracy: 0.2200 - val_top-4-accuracy: 0.7100\n",
      "Epoch 67/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8955 - accuracy: 0.2456 - top-4-accuracy: 0.7299 - val_loss: 1.9020 - val_accuracy: 0.2420 - val_top-4-accuracy: 0.7200\n",
      "Epoch 68/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8892 - accuracy: 0.2366 - top-4-accuracy: 0.7297 - val_loss: 1.8761 - val_accuracy: 0.2620 - val_top-4-accuracy: 0.7540\n",
      "Epoch 69/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8485 - accuracy: 0.2542 - top-4-accuracy: 0.7678 - val_loss: 1.8774 - val_accuracy: 0.2360 - val_top-4-accuracy: 0.7440\n",
      "Epoch 70/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8507 - accuracy: 0.2823 - top-4-accuracy: 0.7468 - val_loss: 1.8897 - val_accuracy: 0.2460 - val_top-4-accuracy: 0.7320\n",
      "Epoch 71/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8628 - accuracy: 0.2666 - top-4-accuracy: 0.7522 - val_loss: 1.8892 - val_accuracy: 0.2420 - val_top-4-accuracy: 0.7360\n",
      "Epoch 72/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8615 - accuracy: 0.2504 - top-4-accuracy: 0.7396 - val_loss: 1.8864 - val_accuracy: 0.2380 - val_top-4-accuracy: 0.7320\n",
      "Epoch 73/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8573 - accuracy: 0.2686 - top-4-accuracy: 0.7495 - val_loss: 1.8620 - val_accuracy: 0.2340 - val_top-4-accuracy: 0.7500\n",
      "Epoch 74/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8389 - accuracy: 0.2621 - top-4-accuracy: 0.7581 - val_loss: 1.8780 - val_accuracy: 0.2200 - val_top-4-accuracy: 0.7440\n",
      "Epoch 75/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8522 - accuracy: 0.2508 - top-4-accuracy: 0.7539 - val_loss: 1.8648 - val_accuracy: 0.2460 - val_top-4-accuracy: 0.7780\n",
      "Epoch 76/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8409 - accuracy: 0.2562 - top-4-accuracy: 0.7636 - val_loss: 1.8793 - val_accuracy: 0.2580 - val_top-4-accuracy: 0.7400\n",
      "Epoch 77/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.8564 - accuracy: 0.2470 - top-4-accuracy: 0.7496 - val_loss: 1.8693 - val_accuracy: 0.2260 - val_top-4-accuracy: 0.7360\n",
      "Epoch 78/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8447 - accuracy: 0.2572 - top-4-accuracy: 0.7717 - val_loss: 1.8595 - val_accuracy: 0.2540 - val_top-4-accuracy: 0.7460\n",
      "Epoch 79/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8473 - accuracy: 0.2627 - top-4-accuracy: 0.7582 - val_loss: 1.8439 - val_accuracy: 0.2460 - val_top-4-accuracy: 0.7400\n",
      "Epoch 80/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8375 - accuracy: 0.2648 - top-4-accuracy: 0.7504 - val_loss: 1.8667 - val_accuracy: 0.2200 - val_top-4-accuracy: 0.7640\n",
      "Epoch 81/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8385 - accuracy: 0.2562 - top-4-accuracy: 0.7570 - val_loss: 1.8476 - val_accuracy: 0.2380 - val_top-4-accuracy: 0.7760\n",
      "Epoch 82/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8349 - accuracy: 0.2697 - top-4-accuracy: 0.7551 - val_loss: 1.8557 - val_accuracy: 0.2540 - val_top-4-accuracy: 0.7600\n",
      "Epoch 83/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8208 - accuracy: 0.2696 - top-4-accuracy: 0.7687 - val_loss: 1.8451 - val_accuracy: 0.2540 - val_top-4-accuracy: 0.7720\n",
      "Epoch 84/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7958 - accuracy: 0.2691 - top-4-accuracy: 0.7969 - val_loss: 1.8114 - val_accuracy: 0.2800 - val_top-4-accuracy: 0.7960\n",
      "Epoch 85/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8088 - accuracy: 0.2688 - top-4-accuracy: 0.7793 - val_loss: 1.8527 - val_accuracy: 0.2760 - val_top-4-accuracy: 0.7580\n",
      "Epoch 86/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8218 - accuracy: 0.2686 - top-4-accuracy: 0.7734 - val_loss: 1.8426 - val_accuracy: 0.2560 - val_top-4-accuracy: 0.7740\n",
      "Epoch 87/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7860 - accuracy: 0.2914 - top-4-accuracy: 0.7860 - val_loss: 1.8510 - val_accuracy: 0.2420 - val_top-4-accuracy: 0.7480\n",
      "Epoch 88/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8052 - accuracy: 0.2601 - top-4-accuracy: 0.7768 - val_loss: 1.7994 - val_accuracy: 0.2540 - val_top-4-accuracy: 0.7800\n",
      "Epoch 89/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.8007 - accuracy: 0.2825 - top-4-accuracy: 0.7987 - val_loss: 1.8010 - val_accuracy: 0.2540 - val_top-4-accuracy: 0.7920\n",
      "Epoch 90/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8100 - accuracy: 0.2609 - top-4-accuracy: 0.7877 - val_loss: 1.8007 - val_accuracy: 0.2580 - val_top-4-accuracy: 0.7900\n",
      "Epoch 91/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8144 - accuracy: 0.2792 - top-4-accuracy: 0.7711 - val_loss: 1.8037 - val_accuracy: 0.2300 - val_top-4-accuracy: 0.7940\n",
      "Epoch 92/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7897 - accuracy: 0.2815 - top-4-accuracy: 0.7909 - val_loss: 1.8372 - val_accuracy: 0.2480 - val_top-4-accuracy: 0.7660\n",
      "Epoch 93/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7963 - accuracy: 0.2606 - top-4-accuracy: 0.7911 - val_loss: 1.8303 - val_accuracy: 0.2800 - val_top-4-accuracy: 0.7800\n",
      "Epoch 94/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.8053 - accuracy: 0.2730 - top-4-accuracy: 0.7904 - val_loss: 1.7917 - val_accuracy: 0.2720 - val_top-4-accuracy: 0.7940\n",
      "Epoch 95/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7795 - accuracy: 0.2777 - top-4-accuracy: 0.8040 - val_loss: 1.8394 - val_accuracy: 0.2440 - val_top-4-accuracy: 0.7760\n",
      "Epoch 96/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7805 - accuracy: 0.2808 - top-4-accuracy: 0.7950 - val_loss: 1.8292 - val_accuracy: 0.2740 - val_top-4-accuracy: 0.7840\n",
      "Epoch 97/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7854 - accuracy: 0.2902 - top-4-accuracy: 0.8002 - val_loss: 1.8269 - val_accuracy: 0.2520 - val_top-4-accuracy: 0.7740\n",
      "Epoch 98/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.7810 - accuracy: 0.2779 - top-4-accuracy: 0.7846 - val_loss: 1.7734 - val_accuracy: 0.2520 - val_top-4-accuracy: 0.8220\n",
      "Epoch 99/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.7869 - accuracy: 0.2692 - top-4-accuracy: 0.7969 - val_loss: 1.7872 - val_accuracy: 0.2720 - val_top-4-accuracy: 0.8020\n",
      "Epoch 100/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7328 - accuracy: 0.3016 - top-4-accuracy: 0.8092 - val_loss: 1.7883 - val_accuracy: 0.2620 - val_top-4-accuracy: 0.8220\n",
      "Epoch 101/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7779 - accuracy: 0.2793 - top-4-accuracy: 0.7995 - val_loss: 1.8293 - val_accuracy: 0.2680 - val_top-4-accuracy: 0.7860\n",
      "Epoch 102/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7757 - accuracy: 0.2792 - top-4-accuracy: 0.8063 - val_loss: 1.7983 - val_accuracy: 0.2700 - val_top-4-accuracy: 0.7900\n",
      "Epoch 103/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7507 - accuracy: 0.2961 - top-4-accuracy: 0.8061 - val_loss: 1.8205 - val_accuracy: 0.2560 - val_top-4-accuracy: 0.7780\n",
      "Epoch 104/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7647 - accuracy: 0.2769 - top-4-accuracy: 0.8058 - val_loss: 1.7866 - val_accuracy: 0.2900 - val_top-4-accuracy: 0.8080\n",
      "Epoch 105/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.7599 - accuracy: 0.2796 - top-4-accuracy: 0.8072 - val_loss: 1.7932 - val_accuracy: 0.2960 - val_top-4-accuracy: 0.8220\n",
      "Epoch 106/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7764 - accuracy: 0.2730 - top-4-accuracy: 0.8029 - val_loss: 1.7803 - val_accuracy: 0.2720 - val_top-4-accuracy: 0.8040\n",
      "Epoch 107/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7253 - accuracy: 0.3094 - top-4-accuracy: 0.8247 - val_loss: 1.7623 - val_accuracy: 0.3040 - val_top-4-accuracy: 0.8280\n",
      "Epoch 108/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7524 - accuracy: 0.2856 - top-4-accuracy: 0.8083 - val_loss: 1.7906 - val_accuracy: 0.2700 - val_top-4-accuracy: 0.7880\n",
      "Epoch 109/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7248 - accuracy: 0.3084 - top-4-accuracy: 0.8152 - val_loss: 1.7314 - val_accuracy: 0.2740 - val_top-4-accuracy: 0.8460\n",
      "Epoch 110/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7240 - accuracy: 0.3060 - top-4-accuracy: 0.8309 - val_loss: 1.7451 - val_accuracy: 0.2560 - val_top-4-accuracy: 0.8260\n",
      "Epoch 111/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.6938 - accuracy: 0.3129 - top-4-accuracy: 0.8403 - val_loss: 1.8035 - val_accuracy: 0.2680 - val_top-4-accuracy: 0.7840\n",
      "Epoch 112/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7137 - accuracy: 0.3104 - top-4-accuracy: 0.8240 - val_loss: 1.7369 - val_accuracy: 0.2780 - val_top-4-accuracy: 0.8100\n",
      "Epoch 113/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7057 - accuracy: 0.2962 - top-4-accuracy: 0.8260 - val_loss: 1.7646 - val_accuracy: 0.2880 - val_top-4-accuracy: 0.8180\n",
      "Epoch 114/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.7306 - accuracy: 0.2925 - top-4-accuracy: 0.8269 - val_loss: 1.7315 - val_accuracy: 0.3200 - val_top-4-accuracy: 0.8040\n",
      "Epoch 115/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7045 - accuracy: 0.3112 - top-4-accuracy: 0.8374 - val_loss: 1.7246 - val_accuracy: 0.3080 - val_top-4-accuracy: 0.8280\n",
      "Epoch 116/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7177 - accuracy: 0.3142 - top-4-accuracy: 0.8269 - val_loss: 1.7509 - val_accuracy: 0.2640 - val_top-4-accuracy: 0.8060\n",
      "Epoch 117/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.7063 - accuracy: 0.3023 - top-4-accuracy: 0.8385 - val_loss: 1.7255 - val_accuracy: 0.2900 - val_top-4-accuracy: 0.8320\n",
      "Epoch 118/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.6930 - accuracy: 0.3272 - top-4-accuracy: 0.8317 - val_loss: 1.7231 - val_accuracy: 0.2920 - val_top-4-accuracy: 0.8220\n",
      "Epoch 119/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6819 - accuracy: 0.3208 - top-4-accuracy: 0.8427 - val_loss: 1.6988 - val_accuracy: 0.3280 - val_top-4-accuracy: 0.8300\n",
      "Epoch 120/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6867 - accuracy: 0.3152 - top-4-accuracy: 0.8368 - val_loss: 1.7038 - val_accuracy: 0.2960 - val_top-4-accuracy: 0.8400\n",
      "Epoch 121/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.6745 - accuracy: 0.3127 - top-4-accuracy: 0.8473 - val_loss: 1.7176 - val_accuracy: 0.2820 - val_top-4-accuracy: 0.8400\n",
      "Epoch 122/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6851 - accuracy: 0.3284 - top-4-accuracy: 0.8408 - val_loss: 1.7067 - val_accuracy: 0.2940 - val_top-4-accuracy: 0.8340\n",
      "Epoch 123/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.6586 - accuracy: 0.3316 - top-4-accuracy: 0.8497 - val_loss: 1.7295 - val_accuracy: 0.2820 - val_top-4-accuracy: 0.8240\n",
      "Epoch 124/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6823 - accuracy: 0.3120 - top-4-accuracy: 0.8504 - val_loss: 1.6964 - val_accuracy: 0.3020 - val_top-4-accuracy: 0.8100\n",
      "Epoch 125/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6547 - accuracy: 0.3311 - top-4-accuracy: 0.8580 - val_loss: 1.7013 - val_accuracy: 0.2920 - val_top-4-accuracy: 0.8140\n",
      "Epoch 126/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6510 - accuracy: 0.3299 - top-4-accuracy: 0.8547 - val_loss: 1.7045 - val_accuracy: 0.3160 - val_top-4-accuracy: 0.8420\n",
      "Epoch 127/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6480 - accuracy: 0.3346 - top-4-accuracy: 0.8555 - val_loss: 1.6895 - val_accuracy: 0.2840 - val_top-4-accuracy: 0.8580\n",
      "Epoch 128/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6581 - accuracy: 0.3293 - top-4-accuracy: 0.8599 - val_loss: 1.7001 - val_accuracy: 0.2900 - val_top-4-accuracy: 0.8260\n",
      "Epoch 129/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6508 - accuracy: 0.3333 - top-4-accuracy: 0.8535 - val_loss: 1.6826 - val_accuracy: 0.3240 - val_top-4-accuracy: 0.8320\n",
      "Epoch 130/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6443 - accuracy: 0.3152 - top-4-accuracy: 0.8570 - val_loss: 1.7068 - val_accuracy: 0.2860 - val_top-4-accuracy: 0.8560\n",
      "Epoch 131/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6564 - accuracy: 0.3280 - top-4-accuracy: 0.8444 - val_loss: 1.6574 - val_accuracy: 0.3360 - val_top-4-accuracy: 0.8600\n",
      "Epoch 132/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6442 - accuracy: 0.3450 - top-4-accuracy: 0.8628 - val_loss: 1.6853 - val_accuracy: 0.2980 - val_top-4-accuracy: 0.8340\n",
      "Epoch 133/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6421 - accuracy: 0.3375 - top-4-accuracy: 0.8652 - val_loss: 1.6531 - val_accuracy: 0.2860 - val_top-4-accuracy: 0.8520\n",
      "Epoch 134/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6123 - accuracy: 0.3509 - top-4-accuracy: 0.8737 - val_loss: 1.6645 - val_accuracy: 0.2860 - val_top-4-accuracy: 0.8580\n",
      "Epoch 135/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6170 - accuracy: 0.3510 - top-4-accuracy: 0.8647 - val_loss: 1.6867 - val_accuracy: 0.3100 - val_top-4-accuracy: 0.8520\n",
      "Epoch 136/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.6119 - accuracy: 0.3405 - top-4-accuracy: 0.8707 - val_loss: 1.6800 - val_accuracy: 0.3080 - val_top-4-accuracy: 0.8480\n",
      "Epoch 137/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6014 - accuracy: 0.3560 - top-4-accuracy: 0.8655 - val_loss: 1.6764 - val_accuracy: 0.3300 - val_top-4-accuracy: 0.8440\n",
      "Epoch 138/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5775 - accuracy: 0.3675 - top-4-accuracy: 0.8729 - val_loss: 1.6714 - val_accuracy: 0.3240 - val_top-4-accuracy: 0.8540\n",
      "Epoch 139/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6075 - accuracy: 0.3410 - top-4-accuracy: 0.8729 - val_loss: 1.6638 - val_accuracy: 0.3120 - val_top-4-accuracy: 0.8520\n",
      "Epoch 140/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5993 - accuracy: 0.3601 - top-4-accuracy: 0.8722 - val_loss: 1.6573 - val_accuracy: 0.3240 - val_top-4-accuracy: 0.8660\n",
      "Epoch 141/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.6043 - accuracy: 0.3476 - top-4-accuracy: 0.8793 - val_loss: 1.6609 - val_accuracy: 0.3180 - val_top-4-accuracy: 0.8500\n",
      "Epoch 142/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5934 - accuracy: 0.3465 - top-4-accuracy: 0.8733 - val_loss: 1.6503 - val_accuracy: 0.3260 - val_top-4-accuracy: 0.8420\n",
      "Epoch 143/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5906 - accuracy: 0.3461 - top-4-accuracy: 0.8762 - val_loss: 1.6778 - val_accuracy: 0.3040 - val_top-4-accuracy: 0.8420\n",
      "Epoch 144/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5822 - accuracy: 0.3533 - top-4-accuracy: 0.8931 - val_loss: 1.6398 - val_accuracy: 0.3340 - val_top-4-accuracy: 0.8540\n",
      "Epoch 145/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5725 - accuracy: 0.3659 - top-4-accuracy: 0.8788 - val_loss: 1.6300 - val_accuracy: 0.3340 - val_top-4-accuracy: 0.8760\n",
      "Epoch 146/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5726 - accuracy: 0.3662 - top-4-accuracy: 0.8733 - val_loss: 1.6423 - val_accuracy: 0.2920 - val_top-4-accuracy: 0.8640\n",
      "Epoch 147/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5845 - accuracy: 0.3552 - top-4-accuracy: 0.8791 - val_loss: 1.6260 - val_accuracy: 0.3060 - val_top-4-accuracy: 0.8560\n",
      "Epoch 148/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5485 - accuracy: 0.3742 - top-4-accuracy: 0.8874 - val_loss: 1.6291 - val_accuracy: 0.3300 - val_top-4-accuracy: 0.8640\n",
      "Epoch 149/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5645 - accuracy: 0.3717 - top-4-accuracy: 0.8798 - val_loss: 1.6511 - val_accuracy: 0.3240 - val_top-4-accuracy: 0.8720\n",
      "Epoch 150/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5445 - accuracy: 0.3861 - top-4-accuracy: 0.8846 - val_loss: 1.6206 - val_accuracy: 0.3320 - val_top-4-accuracy: 0.8780\n",
      "Epoch 151/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5730 - accuracy: 0.3737 - top-4-accuracy: 0.8823 - val_loss: 1.6440 - val_accuracy: 0.3200 - val_top-4-accuracy: 0.8580\n",
      "Epoch 152/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5541 - accuracy: 0.3699 - top-4-accuracy: 0.8942 - val_loss: 1.6185 - val_accuracy: 0.3360 - val_top-4-accuracy: 0.8660\n",
      "Epoch 153/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5794 - accuracy: 0.3733 - top-4-accuracy: 0.8820 - val_loss: 1.5886 - val_accuracy: 0.3120 - val_top-4-accuracy: 0.8900\n",
      "Epoch 154/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5472 - accuracy: 0.3696 - top-4-accuracy: 0.8809 - val_loss: 1.6123 - val_accuracy: 0.3580 - val_top-4-accuracy: 0.8800\n",
      "Epoch 155/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.5622 - accuracy: 0.3722 - top-4-accuracy: 0.8890 - val_loss: 1.6169 - val_accuracy: 0.3420 - val_top-4-accuracy: 0.8880\n",
      "Epoch 156/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5345 - accuracy: 0.3822 - top-4-accuracy: 0.8934 - val_loss: 1.6238 - val_accuracy: 0.3460 - val_top-4-accuracy: 0.8720\n",
      "Epoch 157/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5351 - accuracy: 0.3769 - top-4-accuracy: 0.9004 - val_loss: 1.6848 - val_accuracy: 0.3040 - val_top-4-accuracy: 0.8640\n",
      "Epoch 158/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5665 - accuracy: 0.3543 - top-4-accuracy: 0.8797 - val_loss: 1.6300 - val_accuracy: 0.3300 - val_top-4-accuracy: 0.8680\n",
      "Epoch 159/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5155 - accuracy: 0.3996 - top-4-accuracy: 0.8980 - val_loss: 1.6124 - val_accuracy: 0.3580 - val_top-4-accuracy: 0.8600\n",
      "Epoch 160/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5154 - accuracy: 0.3862 - top-4-accuracy: 0.8970 - val_loss: 1.6238 - val_accuracy: 0.3300 - val_top-4-accuracy: 0.8820\n",
      "Epoch 161/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5174 - accuracy: 0.3754 - top-4-accuracy: 0.8992 - val_loss: 1.6095 - val_accuracy: 0.3360 - val_top-4-accuracy: 0.8900\n",
      "Epoch 162/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5359 - accuracy: 0.3840 - top-4-accuracy: 0.8940 - val_loss: 1.6169 - val_accuracy: 0.3180 - val_top-4-accuracy: 0.8740\n",
      "Epoch 163/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5065 - accuracy: 0.3838 - top-4-accuracy: 0.9008 - val_loss: 1.6215 - val_accuracy: 0.3160 - val_top-4-accuracy: 0.8760\n",
      "Epoch 164/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5216 - accuracy: 0.3930 - top-4-accuracy: 0.8929 - val_loss: 1.6090 - val_accuracy: 0.3200 - val_top-4-accuracy: 0.8780\n",
      "Epoch 165/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5274 - accuracy: 0.3784 - top-4-accuracy: 0.8921 - val_loss: 1.6509 - val_accuracy: 0.3160 - val_top-4-accuracy: 0.8620\n",
      "Epoch 166/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5306 - accuracy: 0.3831 - top-4-accuracy: 0.8988 - val_loss: 1.6105 - val_accuracy: 0.3520 - val_top-4-accuracy: 0.8960\n",
      "Epoch 167/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4954 - accuracy: 0.3978 - top-4-accuracy: 0.9045 - val_loss: 1.6105 - val_accuracy: 0.3540 - val_top-4-accuracy: 0.8700\n",
      "Epoch 168/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4837 - accuracy: 0.3997 - top-4-accuracy: 0.9066 - val_loss: 1.6197 - val_accuracy: 0.3360 - val_top-4-accuracy: 0.8820\n",
      "Epoch 169/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4946 - accuracy: 0.3999 - top-4-accuracy: 0.9057 - val_loss: 1.6289 - val_accuracy: 0.3480 - val_top-4-accuracy: 0.8760\n",
      "Epoch 170/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.5046 - accuracy: 0.3831 - top-4-accuracy: 0.9027 - val_loss: 1.6088 - val_accuracy: 0.3280 - val_top-4-accuracy: 0.8800\n",
      "Epoch 171/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4748 - accuracy: 0.3995 - top-4-accuracy: 0.9098 - val_loss: 1.6170 - val_accuracy: 0.3380 - val_top-4-accuracy: 0.8800\n",
      "Epoch 172/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4736 - accuracy: 0.3992 - top-4-accuracy: 0.9059 - val_loss: 1.6108 - val_accuracy: 0.3300 - val_top-4-accuracy: 0.8860\n",
      "Epoch 173/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4881 - accuracy: 0.3999 - top-4-accuracy: 0.9082 - val_loss: 1.5655 - val_accuracy: 0.3640 - val_top-4-accuracy: 0.9000\n",
      "Epoch 174/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4863 - accuracy: 0.3944 - top-4-accuracy: 0.9128 - val_loss: 1.6217 - val_accuracy: 0.3260 - val_top-4-accuracy: 0.8740\n",
      "Epoch 175/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4740 - accuracy: 0.3972 - top-4-accuracy: 0.9069 - val_loss: 1.6048 - val_accuracy: 0.3400 - val_top-4-accuracy: 0.8800\n",
      "Epoch 176/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4569 - accuracy: 0.4073 - top-4-accuracy: 0.9134 - val_loss: 1.6216 - val_accuracy: 0.3420 - val_top-4-accuracy: 0.8860\n",
      "Epoch 177/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4629 - accuracy: 0.4091 - top-4-accuracy: 0.9062 - val_loss: 1.6066 - val_accuracy: 0.3420 - val_top-4-accuracy: 0.8780\n",
      "Epoch 178/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4763 - accuracy: 0.4083 - top-4-accuracy: 0.9151 - val_loss: 1.6192 - val_accuracy: 0.3320 - val_top-4-accuracy: 0.8620\n",
      "Epoch 179/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4971 - accuracy: 0.3903 - top-4-accuracy: 0.9002 - val_loss: 1.5735 - val_accuracy: 0.3360 - val_top-4-accuracy: 0.8860\n",
      "Epoch 180/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4725 - accuracy: 0.4021 - top-4-accuracy: 0.9087 - val_loss: 1.5469 - val_accuracy: 0.3660 - val_top-4-accuracy: 0.8940\n",
      "Epoch 181/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4427 - accuracy: 0.4097 - top-4-accuracy: 0.9123 - val_loss: 1.5973 - val_accuracy: 0.3520 - val_top-4-accuracy: 0.8860\n",
      "Epoch 182/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4596 - accuracy: 0.4074 - top-4-accuracy: 0.9148 - val_loss: 1.5600 - val_accuracy: 0.3400 - val_top-4-accuracy: 0.8940\n",
      "Epoch 183/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4376 - accuracy: 0.4128 - top-4-accuracy: 0.9160 - val_loss: 1.5777 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.8920\n",
      "Epoch 184/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4655 - accuracy: 0.4078 - top-4-accuracy: 0.9190 - val_loss: 1.5684 - val_accuracy: 0.3400 - val_top-4-accuracy: 0.8880\n",
      "Epoch 185/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4621 - accuracy: 0.4184 - top-4-accuracy: 0.9192 - val_loss: 1.5811 - val_accuracy: 0.3500 - val_top-4-accuracy: 0.8920\n",
      "Epoch 186/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4308 - accuracy: 0.4204 - top-4-accuracy: 0.9281 - val_loss: 1.6119 - val_accuracy: 0.3360 - val_top-4-accuracy: 0.8940\n",
      "Epoch 187/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4346 - accuracy: 0.4238 - top-4-accuracy: 0.9245 - val_loss: 1.5771 - val_accuracy: 0.3480 - val_top-4-accuracy: 0.8860\n",
      "Epoch 188/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.5098 - accuracy: 0.3915 - top-4-accuracy: 0.8992 - val_loss: 1.5973 - val_accuracy: 0.3600 - val_top-4-accuracy: 0.8800\n",
      "Epoch 189/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4283 - accuracy: 0.4133 - top-4-accuracy: 0.9155 - val_loss: 1.6126 - val_accuracy: 0.3680 - val_top-4-accuracy: 0.8680\n",
      "Epoch 190/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4673 - accuracy: 0.4246 - top-4-accuracy: 0.9174 - val_loss: 1.5813 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.8940\n",
      "Epoch 191/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4348 - accuracy: 0.4222 - top-4-accuracy: 0.9270 - val_loss: 1.5904 - val_accuracy: 0.3580 - val_top-4-accuracy: 0.8840\n",
      "Epoch 192/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4096 - accuracy: 0.4135 - top-4-accuracy: 0.9272 - val_loss: 1.5841 - val_accuracy: 0.3560 - val_top-4-accuracy: 0.8820\n",
      "Epoch 193/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4224 - accuracy: 0.4319 - top-4-accuracy: 0.9213 - val_loss: 1.6479 - val_accuracy: 0.3480 - val_top-4-accuracy: 0.8620\n",
      "Epoch 194/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4312 - accuracy: 0.4223 - top-4-accuracy: 0.9171 - val_loss: 1.5775 - val_accuracy: 0.3680 - val_top-4-accuracy: 0.8960\n",
      "Epoch 195/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4021 - accuracy: 0.4258 - top-4-accuracy: 0.9332 - val_loss: 1.5486 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.9100\n",
      "Epoch 196/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4471 - accuracy: 0.4145 - top-4-accuracy: 0.9182 - val_loss: 1.6121 - val_accuracy: 0.3520 - val_top-4-accuracy: 0.8860\n",
      "Epoch 197/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4103 - accuracy: 0.4343 - top-4-accuracy: 0.9286 - val_loss: 1.5960 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.8880\n",
      "Epoch 198/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4256 - accuracy: 0.4255 - top-4-accuracy: 0.9221 - val_loss: 1.5510 - val_accuracy: 0.3440 - val_top-4-accuracy: 0.9040\n",
      "Epoch 199/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4087 - accuracy: 0.4271 - top-4-accuracy: 0.9277 - val_loss: 1.5604 - val_accuracy: 0.3660 - val_top-4-accuracy: 0.8920\n",
      "Epoch 200/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4290 - accuracy: 0.4216 - top-4-accuracy: 0.9249 - val_loss: 1.5606 - val_accuracy: 0.3600 - val_top-4-accuracy: 0.9000\n",
      "Epoch 201/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4120 - accuracy: 0.4329 - top-4-accuracy: 0.9255 - val_loss: 1.6359 - val_accuracy: 0.3420 - val_top-4-accuracy: 0.8960\n",
      "Epoch 202/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4553 - accuracy: 0.4121 - top-4-accuracy: 0.9211 - val_loss: 1.5745 - val_accuracy: 0.3640 - val_top-4-accuracy: 0.8940\n",
      "Epoch 203/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4077 - accuracy: 0.4330 - top-4-accuracy: 0.9198 - val_loss: 1.5916 - val_accuracy: 0.3460 - val_top-4-accuracy: 0.8740\n",
      "Epoch 204/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3786 - accuracy: 0.4575 - top-4-accuracy: 0.9302 - val_loss: 1.6148 - val_accuracy: 0.3320 - val_top-4-accuracy: 0.8940\n",
      "Epoch 205/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.4057 - accuracy: 0.4403 - top-4-accuracy: 0.9253 - val_loss: 1.5970 - val_accuracy: 0.3500 - val_top-4-accuracy: 0.8980\n",
      "Epoch 206/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3944 - accuracy: 0.4516 - top-4-accuracy: 0.9306 - val_loss: 1.5669 - val_accuracy: 0.3480 - val_top-4-accuracy: 0.8880\n",
      "Epoch 207/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4049 - accuracy: 0.4280 - top-4-accuracy: 0.9239 - val_loss: 1.6259 - val_accuracy: 0.3500 - val_top-4-accuracy: 0.8840\n",
      "Epoch 208/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4001 - accuracy: 0.4264 - top-4-accuracy: 0.9326 - val_loss: 1.5828 - val_accuracy: 0.3640 - val_top-4-accuracy: 0.8780\n",
      "Epoch 209/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3597 - accuracy: 0.4492 - top-4-accuracy: 0.9332 - val_loss: 1.6124 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.8820\n",
      "Epoch 210/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3780 - accuracy: 0.4359 - top-4-accuracy: 0.9302 - val_loss: 1.6026 - val_accuracy: 0.3440 - val_top-4-accuracy: 0.8900\n",
      "Epoch 211/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.4093 - accuracy: 0.4348 - top-4-accuracy: 0.9211 - val_loss: 1.6382 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.8860\n",
      "Epoch 212/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.4403 - accuracy: 0.4261 - top-4-accuracy: 0.9204 - val_loss: 1.6389 - val_accuracy: 0.3420 - val_top-4-accuracy: 0.8860\n",
      "Epoch 213/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3688 - accuracy: 0.4409 - top-4-accuracy: 0.9334 - val_loss: 1.5854 - val_accuracy: 0.3420 - val_top-4-accuracy: 0.9000\n",
      "Epoch 214/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3739 - accuracy: 0.4483 - top-4-accuracy: 0.9310 - val_loss: 1.6035 - val_accuracy: 0.3680 - val_top-4-accuracy: 0.8980\n",
      "Epoch 215/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3955 - accuracy: 0.4353 - top-4-accuracy: 0.9272 - val_loss: 1.5640 - val_accuracy: 0.3560 - val_top-4-accuracy: 0.8980\n",
      "Epoch 216/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3530 - accuracy: 0.4553 - top-4-accuracy: 0.9363 - val_loss: 1.6088 - val_accuracy: 0.3420 - val_top-4-accuracy: 0.8920\n",
      "Epoch 217/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3323 - accuracy: 0.4555 - top-4-accuracy: 0.9459 - val_loss: 1.5982 - val_accuracy: 0.3440 - val_top-4-accuracy: 0.8880\n",
      "Epoch 218/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3727 - accuracy: 0.4611 - top-4-accuracy: 0.9330 - val_loss: 1.5900 - val_accuracy: 0.3120 - val_top-4-accuracy: 0.9080\n",
      "Epoch 219/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3699 - accuracy: 0.4493 - top-4-accuracy: 0.9337 - val_loss: 1.5965 - val_accuracy: 0.3640 - val_top-4-accuracy: 0.8940\n",
      "Epoch 220/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3663 - accuracy: 0.4540 - top-4-accuracy: 0.9319 - val_loss: 1.5802 - val_accuracy: 0.3720 - val_top-4-accuracy: 0.9100\n",
      "Epoch 221/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3126 - accuracy: 0.4498 - top-4-accuracy: 0.9510 - val_loss: 1.5915 - val_accuracy: 0.3680 - val_top-4-accuracy: 0.8920\n",
      "Epoch 222/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3435 - accuracy: 0.4646 - top-4-accuracy: 0.9354 - val_loss: 1.5763 - val_accuracy: 0.3540 - val_top-4-accuracy: 0.9000\n",
      "Epoch 223/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.3320 - accuracy: 0.4552 - top-4-accuracy: 0.9379 - val_loss: 1.6150 - val_accuracy: 0.3600 - val_top-4-accuracy: 0.9040\n",
      "Epoch 224/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3459 - accuracy: 0.4653 - top-4-accuracy: 0.9379 - val_loss: 1.6050 - val_accuracy: 0.3420 - val_top-4-accuracy: 0.9000\n",
      "Epoch 225/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3292 - accuracy: 0.4561 - top-4-accuracy: 0.9401 - val_loss: 1.5757 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.8960\n",
      "Epoch 226/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3875 - accuracy: 0.4551 - top-4-accuracy: 0.9248 - val_loss: 1.5822 - val_accuracy: 0.3380 - val_top-4-accuracy: 0.9040\n",
      "Epoch 227/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3636 - accuracy: 0.4419 - top-4-accuracy: 0.9404 - val_loss: 1.6229 - val_accuracy: 0.3380 - val_top-4-accuracy: 0.8880\n",
      "Epoch 228/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3099 - accuracy: 0.4881 - top-4-accuracy: 0.9426 - val_loss: 1.6057 - val_accuracy: 0.3460 - val_top-4-accuracy: 0.8980\n",
      "Epoch 229/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3571 - accuracy: 0.4432 - top-4-accuracy: 0.9370 - val_loss: 1.6137 - val_accuracy: 0.3300 - val_top-4-accuracy: 0.9100\n",
      "Epoch 230/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3581 - accuracy: 0.4555 - top-4-accuracy: 0.9364 - val_loss: 1.5619 - val_accuracy: 0.3600 - val_top-4-accuracy: 0.9060\n",
      "Epoch 231/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3093 - accuracy: 0.4754 - top-4-accuracy: 0.9426 - val_loss: 1.5914 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.8980\n",
      "Epoch 232/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3451 - accuracy: 0.4683 - top-4-accuracy: 0.9324 - val_loss: 1.5426 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9100\n",
      "Epoch 233/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3006 - accuracy: 0.4733 - top-4-accuracy: 0.9440 - val_loss: 1.5656 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.9120\n",
      "Epoch 234/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3040 - accuracy: 0.4704 - top-4-accuracy: 0.9424 - val_loss: 1.5966 - val_accuracy: 0.3440 - val_top-4-accuracy: 0.8880\n",
      "Epoch 235/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3097 - accuracy: 0.4781 - top-4-accuracy: 0.9494 - val_loss: 1.5711 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.8880\n",
      "Epoch 236/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2977 - accuracy: 0.4729 - top-4-accuracy: 0.9524 - val_loss: 1.6115 - val_accuracy: 0.3400 - val_top-4-accuracy: 0.9080\n",
      "Epoch 237/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.3497 - accuracy: 0.4559 - top-4-accuracy: 0.9260 - val_loss: 1.5869 - val_accuracy: 0.3420 - val_top-4-accuracy: 0.8960\n",
      "Epoch 238/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3072 - accuracy: 0.4841 - top-4-accuracy: 0.9377 - val_loss: 1.5995 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9020\n",
      "Epoch 239/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3167 - accuracy: 0.4604 - top-4-accuracy: 0.9451 - val_loss: 1.6032 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.8860\n",
      "Epoch 240/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3220 - accuracy: 0.4728 - top-4-accuracy: 0.9389 - val_loss: 1.5899 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.9200\n",
      "Epoch 241/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2945 - accuracy: 0.4693 - top-4-accuracy: 0.9448 - val_loss: 1.6045 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.8780\n",
      "Epoch 242/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3270 - accuracy: 0.4522 - top-4-accuracy: 0.9447 - val_loss: 1.5391 - val_accuracy: 0.3620 - val_top-4-accuracy: 0.9140\n",
      "Epoch 243/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3262 - accuracy: 0.4735 - top-4-accuracy: 0.9483 - val_loss: 1.5877 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.8940\n",
      "Epoch 244/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3061 - accuracy: 0.4649 - top-4-accuracy: 0.9441 - val_loss: 1.6146 - val_accuracy: 0.3760 - val_top-4-accuracy: 0.8980\n",
      "Epoch 245/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2942 - accuracy: 0.4815 - top-4-accuracy: 0.9433 - val_loss: 1.5981 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.8820\n",
      "Epoch 246/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3117 - accuracy: 0.4537 - top-4-accuracy: 0.9471 - val_loss: 1.6119 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.8900\n",
      "Epoch 247/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3236 - accuracy: 0.4733 - top-4-accuracy: 0.9473 - val_loss: 1.6162 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.9040\n",
      "Epoch 248/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2981 - accuracy: 0.4745 - top-4-accuracy: 0.9497 - val_loss: 1.5698 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.8980\n",
      "Epoch 249/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2656 - accuracy: 0.4968 - top-4-accuracy: 0.9480 - val_loss: 1.6058 - val_accuracy: 0.3640 - val_top-4-accuracy: 0.9040\n",
      "Epoch 250/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2847 - accuracy: 0.5002 - top-4-accuracy: 0.9416 - val_loss: 1.5594 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9020\n",
      "Epoch 251/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3285 - accuracy: 0.4665 - top-4-accuracy: 0.9381 - val_loss: 1.5786 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9100\n",
      "Epoch 252/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3015 - accuracy: 0.4724 - top-4-accuracy: 0.9458 - val_loss: 1.5646 - val_accuracy: 0.3760 - val_top-4-accuracy: 0.9180\n",
      "Epoch 253/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3232 - accuracy: 0.4698 - top-4-accuracy: 0.9319 - val_loss: 1.6168 - val_accuracy: 0.3640 - val_top-4-accuracy: 0.8960\n",
      "Epoch 254/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2772 - accuracy: 0.4890 - top-4-accuracy: 0.9457 - val_loss: 1.5896 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9080\n",
      "Epoch 255/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2789 - accuracy: 0.4971 - top-4-accuracy: 0.9502 - val_loss: 1.5855 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.9140\n",
      "Epoch 256/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3109 - accuracy: 0.4699 - top-4-accuracy: 0.9455 - val_loss: 1.6077 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9040\n",
      "Epoch 257/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3057 - accuracy: 0.4724 - top-4-accuracy: 0.9432 - val_loss: 1.5834 - val_accuracy: 0.3760 - val_top-4-accuracy: 0.9120\n",
      "Epoch 258/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2931 - accuracy: 0.4796 - top-4-accuracy: 0.9479 - val_loss: 1.6249 - val_accuracy: 0.3660 - val_top-4-accuracy: 0.9020\n",
      "Epoch 259/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3092 - accuracy: 0.4724 - top-4-accuracy: 0.9463 - val_loss: 1.6075 - val_accuracy: 0.3720 - val_top-4-accuracy: 0.9220\n",
      "Epoch 260/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2548 - accuracy: 0.4934 - top-4-accuracy: 0.9466 - val_loss: 1.6425 - val_accuracy: 0.3640 - val_top-4-accuracy: 0.8940\n",
      "Epoch 261/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2981 - accuracy: 0.4750 - top-4-accuracy: 0.9508 - val_loss: 1.5911 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.8940\n",
      "Epoch 262/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2500 - accuracy: 0.5047 - top-4-accuracy: 0.9535 - val_loss: 1.6063 - val_accuracy: 0.3760 - val_top-4-accuracy: 0.9060\n",
      "Epoch 263/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2592 - accuracy: 0.4927 - top-4-accuracy: 0.9503 - val_loss: 1.5883 - val_accuracy: 0.3620 - val_top-4-accuracy: 0.9140\n",
      "Epoch 264/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2745 - accuracy: 0.4690 - top-4-accuracy: 0.9495 - val_loss: 1.6395 - val_accuracy: 0.3620 - val_top-4-accuracy: 0.9080\n",
      "Epoch 265/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2916 - accuracy: 0.4786 - top-4-accuracy: 0.9459 - val_loss: 1.5847 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9140\n",
      "Epoch 266/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2498 - accuracy: 0.5162 - top-4-accuracy: 0.9552 - val_loss: 1.5916 - val_accuracy: 0.3500 - val_top-4-accuracy: 0.9140\n",
      "Epoch 267/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2664 - accuracy: 0.4901 - top-4-accuracy: 0.9496 - val_loss: 1.6483 - val_accuracy: 0.3560 - val_top-4-accuracy: 0.8900\n",
      "Epoch 268/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3407 - accuracy: 0.4699 - top-4-accuracy: 0.9343 - val_loss: 1.5885 - val_accuracy: 0.3780 - val_top-4-accuracy: 0.9000\n",
      "Epoch 269/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2961 - accuracy: 0.4865 - top-4-accuracy: 0.9484 - val_loss: 1.6275 - val_accuracy: 0.3620 - val_top-4-accuracy: 0.9200\n",
      "Epoch 270/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3383 - accuracy: 0.4709 - top-4-accuracy: 0.9358 - val_loss: 1.5628 - val_accuracy: 0.3680 - val_top-4-accuracy: 0.9180\n",
      "Epoch 271/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2747 - accuracy: 0.4790 - top-4-accuracy: 0.9477 - val_loss: 1.5664 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9260\n",
      "Epoch 272/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3162 - accuracy: 0.4690 - top-4-accuracy: 0.9470 - val_loss: 1.5640 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9040\n",
      "Epoch 273/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2568 - accuracy: 0.4996 - top-4-accuracy: 0.9569 - val_loss: 1.6106 - val_accuracy: 0.3820 - val_top-4-accuracy: 0.9160\n",
      "Epoch 274/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2797 - accuracy: 0.5003 - top-4-accuracy: 0.9431 - val_loss: 1.5971 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9160\n",
      "Epoch 275/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2409 - accuracy: 0.5039 - top-4-accuracy: 0.9538 - val_loss: 1.6123 - val_accuracy: 0.3660 - val_top-4-accuracy: 0.9160\n",
      "Epoch 276/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2843 - accuracy: 0.4882 - top-4-accuracy: 0.9481 - val_loss: 1.5927 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.9060\n",
      "Epoch 277/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2673 - accuracy: 0.4970 - top-4-accuracy: 0.9451 - val_loss: 1.5580 - val_accuracy: 0.3820 - val_top-4-accuracy: 0.9140\n",
      "Epoch 278/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2677 - accuracy: 0.4960 - top-4-accuracy: 0.9410 - val_loss: 1.6005 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.9180\n",
      "Epoch 279/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2777 - accuracy: 0.4702 - top-4-accuracy: 0.9532 - val_loss: 1.5508 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9200\n",
      "Epoch 280/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2558 - accuracy: 0.5046 - top-4-accuracy: 0.9470 - val_loss: 1.6672 - val_accuracy: 0.3780 - val_top-4-accuracy: 0.8920\n",
      "Epoch 281/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2862 - accuracy: 0.4750 - top-4-accuracy: 0.9514 - val_loss: 1.5668 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.9180\n",
      "Epoch 282/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2676 - accuracy: 0.4866 - top-4-accuracy: 0.9499 - val_loss: 1.5605 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9220\n",
      "Epoch 283/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2432 - accuracy: 0.5050 - top-4-accuracy: 0.9519 - val_loss: 1.5770 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9160\n",
      "Epoch 284/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2417 - accuracy: 0.4898 - top-4-accuracy: 0.9549 - val_loss: 1.6266 - val_accuracy: 0.3760 - val_top-4-accuracy: 0.9180\n",
      "Epoch 285/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2510 - accuracy: 0.4898 - top-4-accuracy: 0.9549 - val_loss: 1.6157 - val_accuracy: 0.3500 - val_top-4-accuracy: 0.9120\n",
      "Epoch 286/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2455 - accuracy: 0.4881 - top-4-accuracy: 0.9580 - val_loss: 1.5921 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.9180\n",
      "Epoch 287/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2293 - accuracy: 0.4969 - top-4-accuracy: 0.9624 - val_loss: 1.5694 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9260\n",
      "Epoch 288/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2532 - accuracy: 0.5111 - top-4-accuracy: 0.9485 - val_loss: 1.5839 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9280\n",
      "Epoch 289/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2299 - accuracy: 0.5097 - top-4-accuracy: 0.9431 - val_loss: 1.5898 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9140\n",
      "Epoch 290/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2593 - accuracy: 0.4962 - top-4-accuracy: 0.9549 - val_loss: 1.6035 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9260\n",
      "Epoch 291/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2681 - accuracy: 0.4859 - top-4-accuracy: 0.9494 - val_loss: 1.5639 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9220\n",
      "Epoch 292/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2395 - accuracy: 0.5068 - top-4-accuracy: 0.9536 - val_loss: 1.6196 - val_accuracy: 0.3500 - val_top-4-accuracy: 0.9080\n",
      "Epoch 293/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2257 - accuracy: 0.4880 - top-4-accuracy: 0.9568 - val_loss: 1.5784 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9200\n",
      "Epoch 294/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2212 - accuracy: 0.5352 - top-4-accuracy: 0.9575 - val_loss: 1.5603 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9300\n",
      "Epoch 295/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2364 - accuracy: 0.5059 - top-4-accuracy: 0.9525 - val_loss: 1.5765 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9120\n",
      "Epoch 296/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2099 - accuracy: 0.5043 - top-4-accuracy: 0.9545 - val_loss: 1.5862 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9020\n",
      "Epoch 297/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2249 - accuracy: 0.5042 - top-4-accuracy: 0.9572 - val_loss: 1.5553 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9080\n",
      "Epoch 298/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2413 - accuracy: 0.4986 - top-4-accuracy: 0.9542 - val_loss: 1.6111 - val_accuracy: 0.3640 - val_top-4-accuracy: 0.9160\n",
      "Epoch 299/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2205 - accuracy: 0.5115 - top-4-accuracy: 0.9555 - val_loss: 1.6313 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9020\n",
      "Epoch 300/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2313 - accuracy: 0.5077 - top-4-accuracy: 0.9552 - val_loss: 1.5768 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9160\n",
      "Epoch 301/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1909 - accuracy: 0.5160 - top-4-accuracy: 0.9630 - val_loss: 1.5815 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9180\n",
      "Epoch 302/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2172 - accuracy: 0.5016 - top-4-accuracy: 0.9567 - val_loss: 1.6208 - val_accuracy: 0.3480 - val_top-4-accuracy: 0.9020\n",
      "Epoch 303/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2443 - accuracy: 0.4932 - top-4-accuracy: 0.9541 - val_loss: 1.5911 - val_accuracy: 0.3680 - val_top-4-accuracy: 0.9080\n",
      "Epoch 304/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2381 - accuracy: 0.4999 - top-4-accuracy: 0.9563 - val_loss: 1.5616 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.9280\n",
      "Epoch 305/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2487 - accuracy: 0.5073 - top-4-accuracy: 0.9496 - val_loss: 1.5976 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9140\n",
      "Epoch 306/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2519 - accuracy: 0.5033 - top-4-accuracy: 0.9504 - val_loss: 1.5806 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9240\n",
      "Epoch 307/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2720 - accuracy: 0.4893 - top-4-accuracy: 0.9456 - val_loss: 1.5739 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.9120\n",
      "Epoch 308/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2028 - accuracy: 0.5237 - top-4-accuracy: 0.9582 - val_loss: 1.5696 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.9120\n",
      "Epoch 309/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2416 - accuracy: 0.5202 - top-4-accuracy: 0.9527 - val_loss: 1.6040 - val_accuracy: 0.3540 - val_top-4-accuracy: 0.9240\n",
      "Epoch 310/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2595 - accuracy: 0.4924 - top-4-accuracy: 0.9469 - val_loss: 1.6091 - val_accuracy: 0.3780 - val_top-4-accuracy: 0.9060\n",
      "Epoch 311/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1984 - accuracy: 0.5071 - top-4-accuracy: 0.9590 - val_loss: 1.6134 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9140\n",
      "Epoch 312/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2261 - accuracy: 0.5037 - top-4-accuracy: 0.9550 - val_loss: 1.5893 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.9100\n",
      "Epoch 313/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2517 - accuracy: 0.5000 - top-4-accuracy: 0.9534 - val_loss: 1.6179 - val_accuracy: 0.3780 - val_top-4-accuracy: 0.9180\n",
      "Epoch 314/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1850 - accuracy: 0.5352 - top-4-accuracy: 0.9677 - val_loss: 1.5991 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9080\n",
      "Epoch 315/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2506 - accuracy: 0.4968 - top-4-accuracy: 0.9523 - val_loss: 1.6115 - val_accuracy: 0.3820 - val_top-4-accuracy: 0.9240\n",
      "Epoch 316/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2321 - accuracy: 0.5032 - top-4-accuracy: 0.9500 - val_loss: 1.6340 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9080\n",
      "Epoch 317/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2211 - accuracy: 0.4995 - top-4-accuracy: 0.9579 - val_loss: 1.5703 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9080\n",
      "Epoch 318/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1999 - accuracy: 0.5215 - top-4-accuracy: 0.9561 - val_loss: 1.5744 - val_accuracy: 0.3720 - val_top-4-accuracy: 0.9320\n",
      "Epoch 319/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2558 - accuracy: 0.4884 - top-4-accuracy: 0.9518 - val_loss: 1.5511 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9240\n",
      "Epoch 320/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2314 - accuracy: 0.5143 - top-4-accuracy: 0.9522 - val_loss: 1.5287 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9360\n",
      "Epoch 321/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2088 - accuracy: 0.5200 - top-4-accuracy: 0.9592 - val_loss: 1.5921 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9300\n",
      "Epoch 322/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2168 - accuracy: 0.5151 - top-4-accuracy: 0.9573 - val_loss: 1.5953 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9140\n",
      "Epoch 323/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2211 - accuracy: 0.5134 - top-4-accuracy: 0.9567 - val_loss: 1.5889 - val_accuracy: 0.3720 - val_top-4-accuracy: 0.9240\n",
      "Epoch 324/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2016 - accuracy: 0.5157 - top-4-accuracy: 0.9605 - val_loss: 1.5589 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9280\n",
      "Epoch 325/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2170 - accuracy: 0.5112 - top-4-accuracy: 0.9581 - val_loss: 1.5722 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9240\n",
      "Epoch 326/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1955 - accuracy: 0.5366 - top-4-accuracy: 0.9553 - val_loss: 1.5977 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9100\n",
      "Epoch 327/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2527 - accuracy: 0.5138 - top-4-accuracy: 0.9485 - val_loss: 1.5776 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.9180\n",
      "Epoch 328/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1894 - accuracy: 0.5184 - top-4-accuracy: 0.9613 - val_loss: 1.6118 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9020\n",
      "Epoch 329/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2398 - accuracy: 0.5131 - top-4-accuracy: 0.9514 - val_loss: 1.5563 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9140\n",
      "Epoch 330/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1964 - accuracy: 0.5268 - top-4-accuracy: 0.9638 - val_loss: 1.6066 - val_accuracy: 0.3780 - val_top-4-accuracy: 0.9200\n",
      "Epoch 331/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2075 - accuracy: 0.5202 - top-4-accuracy: 0.9583 - val_loss: 1.5944 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9180\n",
      "Epoch 332/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2030 - accuracy: 0.5193 - top-4-accuracy: 0.9566 - val_loss: 1.5842 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9280\n",
      "Epoch 333/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2186 - accuracy: 0.5251 - top-4-accuracy: 0.9559 - val_loss: 1.5475 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9200\n",
      "Epoch 334/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1980 - accuracy: 0.5260 - top-4-accuracy: 0.9599 - val_loss: 1.5434 - val_accuracy: 0.3820 - val_top-4-accuracy: 0.9160\n",
      "Epoch 335/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2056 - accuracy: 0.5112 - top-4-accuracy: 0.9567 - val_loss: 1.5838 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.9320\n",
      "Epoch 336/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.2141 - accuracy: 0.5246 - top-4-accuracy: 0.9534 - val_loss: 1.5764 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9300\n",
      "Epoch 337/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2360 - accuracy: 0.5007 - top-4-accuracy: 0.9588 - val_loss: 1.5290 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9380\n",
      "Epoch 338/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1895 - accuracy: 0.5167 - top-4-accuracy: 0.9580 - val_loss: 1.5640 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9180\n",
      "Epoch 339/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2177 - accuracy: 0.5197 - top-4-accuracy: 0.9534 - val_loss: 1.5201 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9340\n",
      "Epoch 340/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2215 - accuracy: 0.5088 - top-4-accuracy: 0.9637 - val_loss: 1.5717 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9180\n",
      "Epoch 341/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1877 - accuracy: 0.5249 - top-4-accuracy: 0.9587 - val_loss: 1.5853 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9240\n",
      "Epoch 342/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2020 - accuracy: 0.5273 - top-4-accuracy: 0.9607 - val_loss: 1.5213 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9320\n",
      "Epoch 343/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2108 - accuracy: 0.5179 - top-4-accuracy: 0.9545 - val_loss: 1.5554 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.9160\n",
      "Epoch 344/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1832 - accuracy: 0.5292 - top-4-accuracy: 0.9605 - val_loss: 1.5143 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9340\n",
      "Epoch 345/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1581 - accuracy: 0.5307 - top-4-accuracy: 0.9650 - val_loss: 1.5126 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9220\n",
      "Epoch 346/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2146 - accuracy: 0.5246 - top-4-accuracy: 0.9547 - val_loss: 1.5471 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.9320\n",
      "Epoch 347/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2208 - accuracy: 0.5261 - top-4-accuracy: 0.9502 - val_loss: 1.5667 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9140\n",
      "Epoch 348/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1937 - accuracy: 0.5292 - top-4-accuracy: 0.9590 - val_loss: 1.5621 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9240\n",
      "Epoch 349/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1737 - accuracy: 0.5399 - top-4-accuracy: 0.9616 - val_loss: 1.5720 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9080\n",
      "Epoch 350/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1896 - accuracy: 0.5283 - top-4-accuracy: 0.9609 - val_loss: 1.5188 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9320\n",
      "Epoch 351/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1565 - accuracy: 0.5310 - top-4-accuracy: 0.9640 - val_loss: 1.5506 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9160\n",
      "Epoch 352/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1748 - accuracy: 0.5242 - top-4-accuracy: 0.9596 - val_loss: 1.5854 - val_accuracy: 0.3720 - val_top-4-accuracy: 0.9280\n",
      "Epoch 353/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1861 - accuracy: 0.5184 - top-4-accuracy: 0.9577 - val_loss: 1.5813 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9340\n",
      "Epoch 354/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2066 - accuracy: 0.5077 - top-4-accuracy: 0.9600 - val_loss: 1.5472 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9240\n",
      "Epoch 355/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1795 - accuracy: 0.5390 - top-4-accuracy: 0.9572 - val_loss: 1.6091 - val_accuracy: 0.3760 - val_top-4-accuracy: 0.9200\n",
      "Epoch 356/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.2468 - accuracy: 0.5028 - top-4-accuracy: 0.9535 - val_loss: 1.5699 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9080\n",
      "Epoch 357/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1400 - accuracy: 0.5480 - top-4-accuracy: 0.9685 - val_loss: 1.5867 - val_accuracy: 0.3740 - val_top-4-accuracy: 0.9240\n",
      "Epoch 358/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1673 - accuracy: 0.5353 - top-4-accuracy: 0.9663 - val_loss: 1.6165 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.8980\n",
      "Epoch 359/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1563 - accuracy: 0.5190 - top-4-accuracy: 0.9601 - val_loss: 1.5996 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.9080\n",
      "Epoch 360/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2176 - accuracy: 0.5331 - top-4-accuracy: 0.9496 - val_loss: 1.6452 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9140\n",
      "Epoch 361/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2013 - accuracy: 0.5278 - top-4-accuracy: 0.9526 - val_loss: 1.5968 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9180\n",
      "Epoch 362/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2023 - accuracy: 0.5184 - top-4-accuracy: 0.9582 - val_loss: 1.5817 - val_accuracy: 0.3760 - val_top-4-accuracy: 0.9120\n",
      "Epoch 363/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2207 - accuracy: 0.5103 - top-4-accuracy: 0.9560 - val_loss: 1.5776 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9200\n",
      "Epoch 364/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1593 - accuracy: 0.5365 - top-4-accuracy: 0.9655 - val_loss: 1.6123 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9240\n",
      "Epoch 365/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1703 - accuracy: 0.5231 - top-4-accuracy: 0.9676 - val_loss: 1.5444 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9340\n",
      "Epoch 366/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1881 - accuracy: 0.5346 - top-4-accuracy: 0.9550 - val_loss: 1.5704 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9140\n",
      "Epoch 367/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1642 - accuracy: 0.5372 - top-4-accuracy: 0.9580 - val_loss: 1.6075 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9260\n",
      "Epoch 368/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1634 - accuracy: 0.5271 - top-4-accuracy: 0.9580 - val_loss: 1.5535 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9300\n",
      "Epoch 369/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1568 - accuracy: 0.5430 - top-4-accuracy: 0.9613 - val_loss: 1.5539 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9360\n",
      "Epoch 370/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2307 - accuracy: 0.5047 - top-4-accuracy: 0.9617 - val_loss: 1.5327 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9380\n",
      "Epoch 371/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2001 - accuracy: 0.5285 - top-4-accuracy: 0.9548 - val_loss: 1.5343 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9240\n",
      "Epoch 372/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2161 - accuracy: 0.5044 - top-4-accuracy: 0.9601 - val_loss: 1.5422 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9260\n",
      "Epoch 373/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1577 - accuracy: 0.5416 - top-4-accuracy: 0.9614 - val_loss: 1.5432 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9400\n",
      "Epoch 374/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1848 - accuracy: 0.5286 - top-4-accuracy: 0.9544 - val_loss: 1.6466 - val_accuracy: 0.3640 - val_top-4-accuracy: 0.9120\n",
      "Epoch 375/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1858 - accuracy: 0.5256 - top-4-accuracy: 0.9556 - val_loss: 1.5496 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9220\n",
      "Epoch 376/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1704 - accuracy: 0.5429 - top-4-accuracy: 0.9626 - val_loss: 1.5502 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9220\n",
      "Epoch 377/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1918 - accuracy: 0.5274 - top-4-accuracy: 0.9586 - val_loss: 1.5121 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9320\n",
      "Epoch 378/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1718 - accuracy: 0.5446 - top-4-accuracy: 0.9611 - val_loss: 1.5553 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9300\n",
      "Epoch 379/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1795 - accuracy: 0.5384 - top-4-accuracy: 0.9587 - val_loss: 1.5041 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9320\n",
      "Epoch 380/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1611 - accuracy: 0.5397 - top-4-accuracy: 0.9605 - val_loss: 1.5074 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9400\n",
      "Epoch 381/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1900 - accuracy: 0.5229 - top-4-accuracy: 0.9602 - val_loss: 1.5084 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9200\n",
      "Epoch 382/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1883 - accuracy: 0.5365 - top-4-accuracy: 0.9616 - val_loss: 1.5638 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9240\n",
      "Epoch 383/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1749 - accuracy: 0.5357 - top-4-accuracy: 0.9613 - val_loss: 1.5709 - val_accuracy: 0.3780 - val_top-4-accuracy: 0.9240\n",
      "Epoch 384/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1821 - accuracy: 0.5346 - top-4-accuracy: 0.9595 - val_loss: 1.5484 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9340\n",
      "Epoch 385/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1369 - accuracy: 0.5394 - top-4-accuracy: 0.9629 - val_loss: 1.5873 - val_accuracy: 0.3720 - val_top-4-accuracy: 0.9240\n",
      "Epoch 386/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2472 - accuracy: 0.5096 - top-4-accuracy: 0.9518 - val_loss: 1.5097 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9380\n",
      "Epoch 387/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1807 - accuracy: 0.5289 - top-4-accuracy: 0.9610 - val_loss: 1.5488 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9280\n",
      "Epoch 388/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1587 - accuracy: 0.5482 - top-4-accuracy: 0.9673 - val_loss: 1.5499 - val_accuracy: 0.3780 - val_top-4-accuracy: 0.9400\n",
      "Epoch 389/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1797 - accuracy: 0.5313 - top-4-accuracy: 0.9618 - val_loss: 1.5514 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9320\n",
      "Epoch 390/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1438 - accuracy: 0.5345 - top-4-accuracy: 0.9662 - val_loss: 1.5448 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9320\n",
      "Epoch 391/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1578 - accuracy: 0.5356 - top-4-accuracy: 0.9648 - val_loss: 1.5388 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9300\n",
      "Epoch 392/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1772 - accuracy: 0.5310 - top-4-accuracy: 0.9616 - val_loss: 1.5026 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9380\n",
      "Epoch 393/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2225 - accuracy: 0.5229 - top-4-accuracy: 0.9560 - val_loss: 1.5167 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9280\n",
      "Epoch 394/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1505 - accuracy: 0.5492 - top-4-accuracy: 0.9608 - val_loss: 1.5100 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9440\n",
      "Epoch 395/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1814 - accuracy: 0.5265 - top-4-accuracy: 0.9565 - val_loss: 1.5018 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9420\n",
      "Epoch 396/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1895 - accuracy: 0.5155 - top-4-accuracy: 0.9656 - val_loss: 1.5258 - val_accuracy: 0.3720 - val_top-4-accuracy: 0.9240\n",
      "Epoch 397/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1892 - accuracy: 0.5236 - top-4-accuracy: 0.9557 - val_loss: 1.5449 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9320\n",
      "Epoch 398/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1965 - accuracy: 0.5356 - top-4-accuracy: 0.9583 - val_loss: 1.5153 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9360\n",
      "Epoch 399/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1850 - accuracy: 0.5380 - top-4-accuracy: 0.9577 - val_loss: 1.5161 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9300\n",
      "Epoch 400/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1715 - accuracy: 0.5327 - top-4-accuracy: 0.9621 - val_loss: 1.5268 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9360\n",
      "Epoch 401/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1695 - accuracy: 0.5297 - top-4-accuracy: 0.9629 - val_loss: 1.5332 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9500\n",
      "Epoch 402/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1866 - accuracy: 0.5329 - top-4-accuracy: 0.9586 - val_loss: 1.5147 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9340\n",
      "Epoch 403/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1848 - accuracy: 0.5194 - top-4-accuracy: 0.9564 - val_loss: 1.5848 - val_accuracy: 0.3720 - val_top-4-accuracy: 0.9260\n",
      "Epoch 404/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1827 - accuracy: 0.5304 - top-4-accuracy: 0.9613 - val_loss: 1.5324 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9180\n",
      "Epoch 405/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1443 - accuracy: 0.5591 - top-4-accuracy: 0.9675 - val_loss: 1.5508 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9400\n",
      "Epoch 406/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1812 - accuracy: 0.5244 - top-4-accuracy: 0.9678 - val_loss: 1.4822 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9380\n",
      "Epoch 407/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2004 - accuracy: 0.5250 - top-4-accuracy: 0.9590 - val_loss: 1.5604 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9300\n",
      "Epoch 408/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1627 - accuracy: 0.5212 - top-4-accuracy: 0.9688 - val_loss: 1.5514 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9200\n",
      "Epoch 409/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1798 - accuracy: 0.5438 - top-4-accuracy: 0.9616 - val_loss: 1.5299 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9400\n",
      "Epoch 410/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1563 - accuracy: 0.5393 - top-4-accuracy: 0.9675 - val_loss: 1.5538 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9240\n",
      "Epoch 411/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1613 - accuracy: 0.5402 - top-4-accuracy: 0.9648 - val_loss: 1.5223 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9400\n",
      "Epoch 412/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1736 - accuracy: 0.5405 - top-4-accuracy: 0.9595 - val_loss: 1.4781 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9460\n",
      "Epoch 413/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1359 - accuracy: 0.5486 - top-4-accuracy: 0.9659 - val_loss: 1.5586 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9300\n",
      "Epoch 414/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1512 - accuracy: 0.5489 - top-4-accuracy: 0.9604 - val_loss: 1.5811 - val_accuracy: 0.3620 - val_top-4-accuracy: 0.9300\n",
      "Epoch 415/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1813 - accuracy: 0.5264 - top-4-accuracy: 0.9594 - val_loss: 1.5305 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9220\n",
      "Epoch 416/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1977 - accuracy: 0.5221 - top-4-accuracy: 0.9499 - val_loss: 1.5426 - val_accuracy: 0.3680 - val_top-4-accuracy: 0.9400\n",
      "Epoch 417/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1705 - accuracy: 0.5299 - top-4-accuracy: 0.9620 - val_loss: 1.4921 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9340\n",
      "Epoch 418/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1744 - accuracy: 0.5291 - top-4-accuracy: 0.9644 - val_loss: 1.4791 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9380\n",
      "Epoch 419/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1445 - accuracy: 0.5421 - top-4-accuracy: 0.9633 - val_loss: 1.5388 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9340\n",
      "Epoch 420/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1394 - accuracy: 0.5478 - top-4-accuracy: 0.9627 - val_loss: 1.5378 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9420\n",
      "Epoch 421/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1557 - accuracy: 0.5378 - top-4-accuracy: 0.9615 - val_loss: 1.4908 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9300\n",
      "Epoch 422/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1275 - accuracy: 0.5698 - top-4-accuracy: 0.9649 - val_loss: 1.5422 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9260\n",
      "Epoch 423/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1870 - accuracy: 0.5348 - top-4-accuracy: 0.9612 - val_loss: 1.5291 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9280\n",
      "Epoch 424/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1342 - accuracy: 0.5372 - top-4-accuracy: 0.9708 - val_loss: 1.4991 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9340\n",
      "Epoch 425/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1642 - accuracy: 0.5335 - top-4-accuracy: 0.9610 - val_loss: 1.5616 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9140\n",
      "Epoch 426/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1987 - accuracy: 0.5287 - top-4-accuracy: 0.9543 - val_loss: 1.4877 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9300\n",
      "Epoch 427/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2369 - accuracy: 0.5140 - top-4-accuracy: 0.9488 - val_loss: 1.5605 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9220\n",
      "Epoch 428/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1498 - accuracy: 0.5330 - top-4-accuracy: 0.9625 - val_loss: 1.5352 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9400\n",
      "Epoch 429/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1823 - accuracy: 0.5435 - top-4-accuracy: 0.9622 - val_loss: 1.5580 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9080\n",
      "Epoch 430/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2107 - accuracy: 0.5178 - top-4-accuracy: 0.9588 - val_loss: 1.4862 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9300\n",
      "Epoch 431/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1466 - accuracy: 0.5528 - top-4-accuracy: 0.9622 - val_loss: 1.5525 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9300\n",
      "Epoch 432/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1851 - accuracy: 0.5245 - top-4-accuracy: 0.9644 - val_loss: 1.5566 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9120\n",
      "Epoch 433/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2242 - accuracy: 0.5231 - top-4-accuracy: 0.9495 - val_loss: 1.5149 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9260\n",
      "Epoch 434/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1606 - accuracy: 0.5399 - top-4-accuracy: 0.9620 - val_loss: 1.5395 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9260\n",
      "Epoch 435/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2121 - accuracy: 0.5314 - top-4-accuracy: 0.9540 - val_loss: 1.5349 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9340\n",
      "Epoch 436/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1216 - accuracy: 0.5504 - top-4-accuracy: 0.9673 - val_loss: 1.4912 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9320\n",
      "Epoch 437/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1532 - accuracy: 0.5370 - top-4-accuracy: 0.9616 - val_loss: 1.5075 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9280\n",
      "Epoch 438/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1483 - accuracy: 0.5401 - top-4-accuracy: 0.9610 - val_loss: 1.5398 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9300\n",
      "Epoch 439/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1079 - accuracy: 0.5723 - top-4-accuracy: 0.9679 - val_loss: 1.6139 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9260\n",
      "Epoch 440/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1840 - accuracy: 0.5271 - top-4-accuracy: 0.9560 - val_loss: 1.4938 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9400\n",
      "Epoch 441/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1262 - accuracy: 0.5525 - top-4-accuracy: 0.9664 - val_loss: 1.5632 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9240\n",
      "Epoch 442/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2074 - accuracy: 0.5265 - top-4-accuracy: 0.9596 - val_loss: 1.4563 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9520\n",
      "Epoch 443/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1762 - accuracy: 0.5333 - top-4-accuracy: 0.9647 - val_loss: 1.5249 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9220\n",
      "Epoch 444/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1694 - accuracy: 0.5236 - top-4-accuracy: 0.9659 - val_loss: 1.4862 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9340\n",
      "Epoch 445/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1810 - accuracy: 0.5365 - top-4-accuracy: 0.9596 - val_loss: 1.5635 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9400\n",
      "Epoch 446/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1079 - accuracy: 0.5577 - top-4-accuracy: 0.9663 - val_loss: 1.5528 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9300\n",
      "Epoch 447/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1611 - accuracy: 0.5589 - top-4-accuracy: 0.9583 - val_loss: 1.4865 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9340\n",
      "Epoch 448/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1213 - accuracy: 0.5584 - top-4-accuracy: 0.9672 - val_loss: 1.5757 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9120\n",
      "Epoch 449/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1922 - accuracy: 0.5499 - top-4-accuracy: 0.9530 - val_loss: 1.5331 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9380\n",
      "Epoch 450/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1618 - accuracy: 0.5528 - top-4-accuracy: 0.9658 - val_loss: 1.5044 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9360\n",
      "Epoch 451/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1237 - accuracy: 0.5552 - top-4-accuracy: 0.9695 - val_loss: 1.5492 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9360\n",
      "Epoch 452/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1381 - accuracy: 0.5534 - top-4-accuracy: 0.9671 - val_loss: 1.4883 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9400\n",
      "Epoch 453/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1405 - accuracy: 0.5564 - top-4-accuracy: 0.9658 - val_loss: 1.5394 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9260\n",
      "Epoch 454/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2013 - accuracy: 0.5255 - top-4-accuracy: 0.9637 - val_loss: 1.5412 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9420\n",
      "Epoch 455/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1710 - accuracy: 0.5350 - top-4-accuracy: 0.9609 - val_loss: 1.5603 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9100\n",
      "Epoch 456/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2156 - accuracy: 0.5343 - top-4-accuracy: 0.9534 - val_loss: 1.5447 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9400\n",
      "Epoch 457/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1131 - accuracy: 0.5611 - top-4-accuracy: 0.9650 - val_loss: 1.5564 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9280\n",
      "Epoch 458/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1801 - accuracy: 0.5236 - top-4-accuracy: 0.9601 - val_loss: 1.5223 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9200\n",
      "Epoch 459/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1093 - accuracy: 0.5672 - top-4-accuracy: 0.9659 - val_loss: 1.4725 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9300\n",
      "Epoch 460/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1984 - accuracy: 0.5321 - top-4-accuracy: 0.9580 - val_loss: 1.4794 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9360\n",
      "Epoch 461/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1184 - accuracy: 0.5514 - top-4-accuracy: 0.9656 - val_loss: 1.6080 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9300\n",
      "Epoch 462/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1766 - accuracy: 0.5390 - top-4-accuracy: 0.9637 - val_loss: 1.5559 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9280\n",
      "Epoch 463/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1036 - accuracy: 0.5779 - top-4-accuracy: 0.9640 - val_loss: 1.5162 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9400\n",
      "Epoch 464/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1122 - accuracy: 0.5566 - top-4-accuracy: 0.9687 - val_loss: 1.5193 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9340\n",
      "Epoch 465/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1391 - accuracy: 0.5552 - top-4-accuracy: 0.9660 - val_loss: 1.5320 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9500\n",
      "Epoch 466/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1316 - accuracy: 0.5441 - top-4-accuracy: 0.9698 - val_loss: 1.5205 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9420\n",
      "Epoch 467/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1636 - accuracy: 0.5375 - top-4-accuracy: 0.9600 - val_loss: 1.5325 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9240\n",
      "Epoch 468/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1660 - accuracy: 0.5359 - top-4-accuracy: 0.9576 - val_loss: 1.4546 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9540\n",
      "Epoch 469/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1329 - accuracy: 0.5495 - top-4-accuracy: 0.9708 - val_loss: 1.4863 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9360\n",
      "Epoch 470/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1238 - accuracy: 0.5529 - top-4-accuracy: 0.9680 - val_loss: 1.5105 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9400\n",
      "Epoch 471/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1265 - accuracy: 0.5450 - top-4-accuracy: 0.9665 - val_loss: 1.5788 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.9320\n",
      "Epoch 472/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1530 - accuracy: 0.5350 - top-4-accuracy: 0.9665 - val_loss: 1.4985 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9300\n",
      "Epoch 473/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1097 - accuracy: 0.5623 - top-4-accuracy: 0.9627 - val_loss: 1.5461 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9420\n",
      "Epoch 474/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1420 - accuracy: 0.5453 - top-4-accuracy: 0.9641 - val_loss: 1.4863 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9440\n",
      "Epoch 475/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1502 - accuracy: 0.5379 - top-4-accuracy: 0.9675 - val_loss: 1.4788 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9400\n",
      "Epoch 476/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1608 - accuracy: 0.5514 - top-4-accuracy: 0.9625 - val_loss: 1.4936 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9300\n",
      "Epoch 477/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1432 - accuracy: 0.5535 - top-4-accuracy: 0.9610 - val_loss: 1.5762 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9340\n",
      "Epoch 478/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1727 - accuracy: 0.5329 - top-4-accuracy: 0.9627 - val_loss: 1.4828 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9420\n",
      "Epoch 479/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1269 - accuracy: 0.5608 - top-4-accuracy: 0.9638 - val_loss: 1.5398 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9440\n",
      "Epoch 480/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1541 - accuracy: 0.5372 - top-4-accuracy: 0.9626 - val_loss: 1.5066 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9340\n",
      "Epoch 481/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0909 - accuracy: 0.5665 - top-4-accuracy: 0.9671 - val_loss: 1.5715 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9140\n",
      "Epoch 482/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2117 - accuracy: 0.5359 - top-4-accuracy: 0.9566 - val_loss: 1.4517 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9480\n",
      "Epoch 483/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1260 - accuracy: 0.5505 - top-4-accuracy: 0.9685 - val_loss: 1.5330 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9320\n",
      "Epoch 484/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1493 - accuracy: 0.5424 - top-4-accuracy: 0.9642 - val_loss: 1.5530 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9260\n",
      "Epoch 485/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1473 - accuracy: 0.5338 - top-4-accuracy: 0.9697 - val_loss: 1.5264 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9340\n",
      "Epoch 486/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1457 - accuracy: 0.5655 - top-4-accuracy: 0.9609 - val_loss: 1.4889 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9420\n",
      "Epoch 487/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1156 - accuracy: 0.5590 - top-4-accuracy: 0.9682 - val_loss: 1.5460 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9280\n",
      "Epoch 488/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0981 - accuracy: 0.5673 - top-4-accuracy: 0.9764 - val_loss: 1.5018 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9260\n",
      "Epoch 489/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1240 - accuracy: 0.5618 - top-4-accuracy: 0.9648 - val_loss: 1.4905 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9420\n",
      "Epoch 490/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1234 - accuracy: 0.5619 - top-4-accuracy: 0.9572 - val_loss: 1.5572 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9180\n",
      "Epoch 491/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1452 - accuracy: 0.5394 - top-4-accuracy: 0.9654 - val_loss: 1.5044 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9360\n",
      "Epoch 492/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1522 - accuracy: 0.5436 - top-4-accuracy: 0.9650 - val_loss: 1.5385 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9260\n",
      "Epoch 493/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1677 - accuracy: 0.5438 - top-4-accuracy: 0.9613 - val_loss: 1.4902 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9340\n",
      "Epoch 494/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1251 - accuracy: 0.5664 - top-4-accuracy: 0.9647 - val_loss: 1.5662 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9300\n",
      "Epoch 495/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1118 - accuracy: 0.5618 - top-4-accuracy: 0.9692 - val_loss: 1.5054 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9440\n",
      "Epoch 496/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1444 - accuracy: 0.5548 - top-4-accuracy: 0.9621 - val_loss: 1.5171 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9420\n",
      "Epoch 497/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1320 - accuracy: 0.5534 - top-4-accuracy: 0.9680 - val_loss: 1.5536 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9320\n",
      "Epoch 498/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1548 - accuracy: 0.5524 - top-4-accuracy: 0.9664 - val_loss: 1.5548 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9280\n",
      "Epoch 499/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1717 - accuracy: 0.5401 - top-4-accuracy: 0.9572 - val_loss: 1.5534 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9340\n",
      "Epoch 500/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1621 - accuracy: 0.5481 - top-4-accuracy: 0.9621 - val_loss: 1.5842 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9240\n",
      "Epoch 501/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1318 - accuracy: 0.5511 - top-4-accuracy: 0.9646 - val_loss: 1.5405 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9300\n",
      "Epoch 502/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1230 - accuracy: 0.5474 - top-4-accuracy: 0.9681 - val_loss: 1.5243 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9440\n",
      "Epoch 503/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1844 - accuracy: 0.5403 - top-4-accuracy: 0.9598 - val_loss: 1.5397 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9360\n",
      "Epoch 504/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1368 - accuracy: 0.5468 - top-4-accuracy: 0.9692 - val_loss: 1.4945 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9340\n",
      "Epoch 505/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1277 - accuracy: 0.5541 - top-4-accuracy: 0.9641 - val_loss: 1.5443 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9320\n",
      "Epoch 506/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0984 - accuracy: 0.5665 - top-4-accuracy: 0.9714 - val_loss: 1.4923 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9420\n",
      "Epoch 507/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1382 - accuracy: 0.5518 - top-4-accuracy: 0.9624 - val_loss: 1.5255 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9320\n",
      "Epoch 508/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1639 - accuracy: 0.5438 - top-4-accuracy: 0.9573 - val_loss: 1.5170 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9400\n",
      "Epoch 509/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1884 - accuracy: 0.5335 - top-4-accuracy: 0.9548 - val_loss: 1.4901 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9260\n",
      "Epoch 510/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1294 - accuracy: 0.5615 - top-4-accuracy: 0.9645 - val_loss: 1.5099 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9320\n",
      "Epoch 511/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1531 - accuracy: 0.5481 - top-4-accuracy: 0.9607 - val_loss: 1.5472 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9320\n",
      "Epoch 512/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1502 - accuracy: 0.5631 - top-4-accuracy: 0.9624 - val_loss: 1.5145 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9280\n",
      "Epoch 513/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1522 - accuracy: 0.5525 - top-4-accuracy: 0.9614 - val_loss: 1.4820 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9480\n",
      "Epoch 514/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1213 - accuracy: 0.5479 - top-4-accuracy: 0.9659 - val_loss: 1.5159 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9320\n",
      "Epoch 515/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0979 - accuracy: 0.5722 - top-4-accuracy: 0.9664 - val_loss: 1.5288 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9320\n",
      "Epoch 516/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1443 - accuracy: 0.5412 - top-4-accuracy: 0.9614 - val_loss: 1.5522 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9240\n",
      "Epoch 517/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1154 - accuracy: 0.5696 - top-4-accuracy: 0.9665 - val_loss: 1.5301 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9200\n",
      "Epoch 518/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1466 - accuracy: 0.5660 - top-4-accuracy: 0.9591 - val_loss: 1.4999 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9360\n",
      "Epoch 519/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1146 - accuracy: 0.5559 - top-4-accuracy: 0.9668 - val_loss: 1.4683 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9400\n",
      "Epoch 520/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1253 - accuracy: 0.5476 - top-4-accuracy: 0.9694 - val_loss: 1.5114 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9360\n",
      "Epoch 521/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1497 - accuracy: 0.5596 - top-4-accuracy: 0.9609 - val_loss: 1.5014 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9320\n",
      "Epoch 522/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1172 - accuracy: 0.5560 - top-4-accuracy: 0.9660 - val_loss: 1.5281 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9360\n",
      "Epoch 523/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1485 - accuracy: 0.5564 - top-4-accuracy: 0.9689 - val_loss: 1.5731 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9280\n",
      "Epoch 524/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1048 - accuracy: 0.5796 - top-4-accuracy: 0.9674 - val_loss: 1.4656 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9360\n",
      "Epoch 525/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1014 - accuracy: 0.5650 - top-4-accuracy: 0.9727 - val_loss: 1.5041 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9340\n",
      "Epoch 526/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1775 - accuracy: 0.5330 - top-4-accuracy: 0.9575 - val_loss: 1.5010 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9340\n",
      "Epoch 527/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1263 - accuracy: 0.5491 - top-4-accuracy: 0.9667 - val_loss: 1.5642 - val_accuracy: 0.3700 - val_top-4-accuracy: 0.9100\n",
      "Epoch 528/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1463 - accuracy: 0.5433 - top-4-accuracy: 0.9671 - val_loss: 1.5667 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9260\n",
      "Epoch 529/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1423 - accuracy: 0.5589 - top-4-accuracy: 0.9604 - val_loss: 1.5105 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9360\n",
      "Epoch 530/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1501 - accuracy: 0.5468 - top-4-accuracy: 0.9608 - val_loss: 1.5294 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9320\n",
      "Epoch 531/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1359 - accuracy: 0.5702 - top-4-accuracy: 0.9647 - val_loss: 1.5022 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9340\n",
      "Epoch 532/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1241 - accuracy: 0.5684 - top-4-accuracy: 0.9646 - val_loss: 1.5040 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9420\n",
      "Epoch 533/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1171 - accuracy: 0.5472 - top-4-accuracy: 0.9683 - val_loss: 1.5913 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9220\n",
      "Epoch 534/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1395 - accuracy: 0.5455 - top-4-accuracy: 0.9629 - val_loss: 1.5372 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9320\n",
      "Epoch 535/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1583 - accuracy: 0.5514 - top-4-accuracy: 0.9582 - val_loss: 1.4852 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9340\n",
      "Epoch 536/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1481 - accuracy: 0.5541 - top-4-accuracy: 0.9572 - val_loss: 1.4954 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9360\n",
      "Epoch 537/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1273 - accuracy: 0.5600 - top-4-accuracy: 0.9675 - val_loss: 1.4483 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9460\n",
      "Epoch 538/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1200 - accuracy: 0.5601 - top-4-accuracy: 0.9673 - val_loss: 1.5311 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9280\n",
      "Epoch 539/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1535 - accuracy: 0.5546 - top-4-accuracy: 0.9612 - val_loss: 1.5332 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9400\n",
      "Epoch 540/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1391 - accuracy: 0.5552 - top-4-accuracy: 0.9653 - val_loss: 1.4972 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9280\n",
      "Epoch 541/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1324 - accuracy: 0.5459 - top-4-accuracy: 0.9641 - val_loss: 1.4754 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9480\n",
      "Epoch 542/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1464 - accuracy: 0.5393 - top-4-accuracy: 0.9696 - val_loss: 1.4532 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9420\n",
      "Epoch 543/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1632 - accuracy: 0.5273 - top-4-accuracy: 0.9678 - val_loss: 1.4883 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9340\n",
      "Epoch 544/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1398 - accuracy: 0.5490 - top-4-accuracy: 0.9647 - val_loss: 1.3923 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9520\n",
      "Epoch 545/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0955 - accuracy: 0.5735 - top-4-accuracy: 0.9657 - val_loss: 1.4875 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9360\n",
      "Epoch 546/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1526 - accuracy: 0.5434 - top-4-accuracy: 0.9630 - val_loss: 1.4934 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9420\n",
      "Epoch 547/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1482 - accuracy: 0.5420 - top-4-accuracy: 0.9624 - val_loss: 1.5080 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9360\n",
      "Epoch 548/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0852 - accuracy: 0.5689 - top-4-accuracy: 0.9712 - val_loss: 1.5216 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9400\n",
      "Epoch 549/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1319 - accuracy: 0.5587 - top-4-accuracy: 0.9611 - val_loss: 1.4928 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9460\n",
      "Epoch 550/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1616 - accuracy: 0.5514 - top-4-accuracy: 0.9555 - val_loss: 1.4976 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9340\n",
      "Epoch 551/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1271 - accuracy: 0.5602 - top-4-accuracy: 0.9664 - val_loss: 1.5176 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9300\n",
      "Epoch 552/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1193 - accuracy: 0.5468 - top-4-accuracy: 0.9654 - val_loss: 1.5611 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9240\n",
      "Epoch 553/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1646 - accuracy: 0.5503 - top-4-accuracy: 0.9640 - val_loss: 1.4590 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9360\n",
      "Epoch 554/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1107 - accuracy: 0.5596 - top-4-accuracy: 0.9648 - val_loss: 1.5236 - val_accuracy: 0.3920 - val_top-4-accuracy: 0.9460\n",
      "Epoch 555/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1278 - accuracy: 0.5595 - top-4-accuracy: 0.9638 - val_loss: 1.4967 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9380\n",
      "Epoch 556/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0872 - accuracy: 0.5659 - top-4-accuracy: 0.9751 - val_loss: 1.5127 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9340\n",
      "Epoch 557/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0921 - accuracy: 0.5737 - top-4-accuracy: 0.9672 - val_loss: 1.4739 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9560\n",
      "Epoch 558/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1634 - accuracy: 0.5544 - top-4-accuracy: 0.9608 - val_loss: 1.4754 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9400\n",
      "Epoch 559/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0820 - accuracy: 0.5737 - top-4-accuracy: 0.9650 - val_loss: 1.5820 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9360\n",
      "Epoch 560/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1707 - accuracy: 0.5403 - top-4-accuracy: 0.9637 - val_loss: 1.5134 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9540\n",
      "Epoch 561/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1004 - accuracy: 0.5677 - top-4-accuracy: 0.9690 - val_loss: 1.4901 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9260\n",
      "Epoch 562/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1160 - accuracy: 0.5635 - top-4-accuracy: 0.9578 - val_loss: 1.6067 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9040\n",
      "Epoch 563/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1916 - accuracy: 0.5539 - top-4-accuracy: 0.9586 - val_loss: 1.5131 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9400\n",
      "Epoch 564/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1493 - accuracy: 0.5622 - top-4-accuracy: 0.9613 - val_loss: 1.5351 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9340\n",
      "Epoch 565/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1327 - accuracy: 0.5521 - top-4-accuracy: 0.9638 - val_loss: 1.5745 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9220\n",
      "Epoch 566/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1259 - accuracy: 0.5515 - top-4-accuracy: 0.9677 - val_loss: 1.5412 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9340\n",
      "Epoch 567/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1158 - accuracy: 0.5554 - top-4-accuracy: 0.9689 - val_loss: 1.5067 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9300\n",
      "Epoch 568/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1414 - accuracy: 0.5510 - top-4-accuracy: 0.9632 - val_loss: 1.5132 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9280\n",
      "Epoch 569/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0806 - accuracy: 0.5692 - top-4-accuracy: 0.9724 - val_loss: 1.4849 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9480\n",
      "Epoch 570/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1211 - accuracy: 0.5692 - top-4-accuracy: 0.9623 - val_loss: 1.5173 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9460\n",
      "Epoch 571/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1084 - accuracy: 0.5685 - top-4-accuracy: 0.9678 - val_loss: 1.5456 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9340\n",
      "Epoch 572/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0930 - accuracy: 0.5780 - top-4-accuracy: 0.9675 - val_loss: 1.4415 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9460\n",
      "Epoch 573/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1363 - accuracy: 0.5618 - top-4-accuracy: 0.9696 - val_loss: 1.5742 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9300\n",
      "Epoch 574/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1206 - accuracy: 0.5454 - top-4-accuracy: 0.9637 - val_loss: 1.5379 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9480\n",
      "Epoch 575/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1201 - accuracy: 0.5714 - top-4-accuracy: 0.9645 - val_loss: 1.5218 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9340\n",
      "Epoch 576/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1183 - accuracy: 0.5741 - top-4-accuracy: 0.9611 - val_loss: 1.5797 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.9240\n",
      "Epoch 577/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1653 - accuracy: 0.5445 - top-4-accuracy: 0.9611 - val_loss: 1.5178 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9200\n",
      "Epoch 578/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1458 - accuracy: 0.5422 - top-4-accuracy: 0.9681 - val_loss: 1.5315 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9300\n",
      "Epoch 579/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1443 - accuracy: 0.5569 - top-4-accuracy: 0.9557 - val_loss: 1.5234 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9300\n",
      "Epoch 580/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1438 - accuracy: 0.5531 - top-4-accuracy: 0.9600 - val_loss: 1.5163 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9400\n",
      "Epoch 581/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1137 - accuracy: 0.5751 - top-4-accuracy: 0.9695 - val_loss: 1.5157 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9280\n",
      "Epoch 582/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1221 - accuracy: 0.5460 - top-4-accuracy: 0.9620 - val_loss: 1.5227 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9260\n",
      "Epoch 583/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1290 - accuracy: 0.5576 - top-4-accuracy: 0.9677 - val_loss: 1.5391 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9340\n",
      "Epoch 584/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1166 - accuracy: 0.5663 - top-4-accuracy: 0.9661 - val_loss: 1.5492 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9320\n",
      "Epoch 585/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1509 - accuracy: 0.5414 - top-4-accuracy: 0.9662 - val_loss: 1.5241 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9240\n",
      "Epoch 586/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1214 - accuracy: 0.5757 - top-4-accuracy: 0.9671 - val_loss: 1.5013 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9360\n",
      "Epoch 587/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1159 - accuracy: 0.5769 - top-4-accuracy: 0.9663 - val_loss: 1.5508 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9340\n",
      "Epoch 588/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1307 - accuracy: 0.5532 - top-4-accuracy: 0.9648 - val_loss: 1.5246 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9380\n",
      "Epoch 589/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1323 - accuracy: 0.5659 - top-4-accuracy: 0.9617 - val_loss: 1.5420 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9320\n",
      "Epoch 590/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1029 - accuracy: 0.5601 - top-4-accuracy: 0.9725 - val_loss: 1.5441 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9240\n",
      "Epoch 591/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0725 - accuracy: 0.5908 - top-4-accuracy: 0.9688 - val_loss: 1.5716 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9320\n",
      "Epoch 592/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1543 - accuracy: 0.5509 - top-4-accuracy: 0.9640 - val_loss: 1.5084 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9360\n",
      "Epoch 593/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1266 - accuracy: 0.5631 - top-4-accuracy: 0.9676 - val_loss: 1.4937 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9400\n",
      "Epoch 594/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0999 - accuracy: 0.5593 - top-4-accuracy: 0.9669 - val_loss: 1.5023 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9320\n",
      "Epoch 595/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1150 - accuracy: 0.5680 - top-4-accuracy: 0.9649 - val_loss: 1.5475 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9160\n",
      "Epoch 596/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1399 - accuracy: 0.5523 - top-4-accuracy: 0.9663 - val_loss: 1.5336 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9380\n",
      "Epoch 597/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0767 - accuracy: 0.5752 - top-4-accuracy: 0.9680 - val_loss: 1.4945 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9300\n",
      "Epoch 598/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1282 - accuracy: 0.5441 - top-4-accuracy: 0.9706 - val_loss: 1.5595 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9140\n",
      "Epoch 599/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1158 - accuracy: 0.5663 - top-4-accuracy: 0.9685 - val_loss: 1.4796 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9460\n",
      "Epoch 600/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1068 - accuracy: 0.5763 - top-4-accuracy: 0.9652 - val_loss: 1.5217 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9340\n",
      "Epoch 601/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1079 - accuracy: 0.5610 - top-4-accuracy: 0.9660 - val_loss: 1.5307 - val_accuracy: 0.3800 - val_top-4-accuracy: 0.9280\n",
      "Epoch 602/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1099 - accuracy: 0.5759 - top-4-accuracy: 0.9568 - val_loss: 1.5044 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9440\n",
      "Epoch 603/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1148 - accuracy: 0.5791 - top-4-accuracy: 0.9624 - val_loss: 1.4704 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9460\n",
      "Epoch 604/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1612 - accuracy: 0.5425 - top-4-accuracy: 0.9599 - val_loss: 1.5019 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9340\n",
      "Epoch 605/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1229 - accuracy: 0.5587 - top-4-accuracy: 0.9654 - val_loss: 1.5352 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9200\n",
      "Epoch 606/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1443 - accuracy: 0.5646 - top-4-accuracy: 0.9580 - val_loss: 1.4097 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9440\n",
      "Epoch 607/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1079 - accuracy: 0.5694 - top-4-accuracy: 0.9627 - val_loss: 1.5038 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9420\n",
      "Epoch 608/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1287 - accuracy: 0.5627 - top-4-accuracy: 0.9663 - val_loss: 1.5032 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9260\n",
      "Epoch 609/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1243 - accuracy: 0.5477 - top-4-accuracy: 0.9713 - val_loss: 1.4797 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9340\n",
      "Epoch 610/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1218 - accuracy: 0.5709 - top-4-accuracy: 0.9657 - val_loss: 1.4665 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9380\n",
      "Epoch 611/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1162 - accuracy: 0.5638 - top-4-accuracy: 0.9644 - val_loss: 1.4732 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9280\n",
      "Epoch 612/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1082 - accuracy: 0.5720 - top-4-accuracy: 0.9654 - val_loss: 1.5430 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9420\n",
      "Epoch 613/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1269 - accuracy: 0.5532 - top-4-accuracy: 0.9692 - val_loss: 1.5130 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9260\n",
      "Epoch 614/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1229 - accuracy: 0.5652 - top-4-accuracy: 0.9644 - val_loss: 1.4727 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9440\n",
      "Epoch 615/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1060 - accuracy: 0.5558 - top-4-accuracy: 0.9663 - val_loss: 1.4928 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9480\n",
      "Epoch 616/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1202 - accuracy: 0.5769 - top-4-accuracy: 0.9604 - val_loss: 1.5012 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9280\n",
      "Epoch 617/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0749 - accuracy: 0.5818 - top-4-accuracy: 0.9726 - val_loss: 1.4956 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9320\n",
      "Epoch 618/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0777 - accuracy: 0.5866 - top-4-accuracy: 0.9702 - val_loss: 1.5660 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9200\n",
      "Epoch 619/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1126 - accuracy: 0.5640 - top-4-accuracy: 0.9692 - val_loss: 1.5628 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9180\n",
      "Epoch 620/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0923 - accuracy: 0.5614 - top-4-accuracy: 0.9637 - val_loss: 1.5610 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9420\n",
      "Epoch 621/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1515 - accuracy: 0.5438 - top-4-accuracy: 0.9585 - val_loss: 1.4800 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9280\n",
      "Epoch 622/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1371 - accuracy: 0.5497 - top-4-accuracy: 0.9645 - val_loss: 1.4414 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9420\n",
      "Epoch 623/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1041 - accuracy: 0.5587 - top-4-accuracy: 0.9703 - val_loss: 1.4688 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9380\n",
      "Epoch 624/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0785 - accuracy: 0.5706 - top-4-accuracy: 0.9741 - val_loss: 1.4793 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9320\n",
      "Epoch 625/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1156 - accuracy: 0.5582 - top-4-accuracy: 0.9681 - val_loss: 1.4966 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9340\n",
      "Epoch 626/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1220 - accuracy: 0.5688 - top-4-accuracy: 0.9689 - val_loss: 1.5394 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9380\n",
      "Epoch 627/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1428 - accuracy: 0.5401 - top-4-accuracy: 0.9673 - val_loss: 1.5169 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9320\n",
      "Epoch 628/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0910 - accuracy: 0.5637 - top-4-accuracy: 0.9705 - val_loss: 1.5074 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9300\n",
      "Epoch 629/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0863 - accuracy: 0.5744 - top-4-accuracy: 0.9691 - val_loss: 1.4709 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9440\n",
      "Epoch 630/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1476 - accuracy: 0.5575 - top-4-accuracy: 0.9597 - val_loss: 1.4766 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9400\n",
      "Epoch 631/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1203 - accuracy: 0.5753 - top-4-accuracy: 0.9657 - val_loss: 1.5055 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9380\n",
      "Epoch 632/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1303 - accuracy: 0.5667 - top-4-accuracy: 0.9602 - val_loss: 1.5294 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9280\n",
      "Epoch 633/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1346 - accuracy: 0.5520 - top-4-accuracy: 0.9622 - val_loss: 1.5404 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9180\n",
      "Epoch 634/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1204 - accuracy: 0.5670 - top-4-accuracy: 0.9632 - val_loss: 1.5254 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9420\n",
      "Epoch 635/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1432 - accuracy: 0.5524 - top-4-accuracy: 0.9601 - val_loss: 1.4993 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9300\n",
      "Epoch 636/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1323 - accuracy: 0.5689 - top-4-accuracy: 0.9644 - val_loss: 1.4792 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9440\n",
      "Epoch 637/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0749 - accuracy: 0.5757 - top-4-accuracy: 0.9692 - val_loss: 1.4736 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9420\n",
      "Epoch 638/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1027 - accuracy: 0.5612 - top-4-accuracy: 0.9695 - val_loss: 1.4882 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9360\n",
      "Epoch 639/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1146 - accuracy: 0.5761 - top-4-accuracy: 0.9642 - val_loss: 1.4329 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9480\n",
      "Epoch 640/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1344 - accuracy: 0.5628 - top-4-accuracy: 0.9638 - val_loss: 1.4732 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9300\n",
      "Epoch 641/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1135 - accuracy: 0.5753 - top-4-accuracy: 0.9609 - val_loss: 1.5635 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9280\n",
      "Epoch 642/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1018 - accuracy: 0.5915 - top-4-accuracy: 0.9697 - val_loss: 1.5556 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9280\n",
      "Epoch 643/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1231 - accuracy: 0.5570 - top-4-accuracy: 0.9656 - val_loss: 1.4861 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9520\n",
      "Epoch 644/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1271 - accuracy: 0.5567 - top-4-accuracy: 0.9623 - val_loss: 1.4916 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9440\n",
      "Epoch 645/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1211 - accuracy: 0.5682 - top-4-accuracy: 0.9613 - val_loss: 1.4329 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9460\n",
      "Epoch 646/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1175 - accuracy: 0.5528 - top-4-accuracy: 0.9678 - val_loss: 1.5058 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9340\n",
      "Epoch 647/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1377 - accuracy: 0.5599 - top-4-accuracy: 0.9643 - val_loss: 1.4539 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9400\n",
      "Epoch 648/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1312 - accuracy: 0.5637 - top-4-accuracy: 0.9614 - val_loss: 1.4655 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9360\n",
      "Epoch 649/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1233 - accuracy: 0.5637 - top-4-accuracy: 0.9676 - val_loss: 1.5840 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9300\n",
      "Epoch 650/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1378 - accuracy: 0.5545 - top-4-accuracy: 0.9650 - val_loss: 1.4846 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9220\n",
      "Epoch 651/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0969 - accuracy: 0.5768 - top-4-accuracy: 0.9611 - val_loss: 1.4374 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9380\n",
      "Epoch 652/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0944 - accuracy: 0.5739 - top-4-accuracy: 0.9651 - val_loss: 1.4683 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9420\n",
      "Epoch 653/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0991 - accuracy: 0.5805 - top-4-accuracy: 0.9666 - val_loss: 1.5514 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9300\n",
      "Epoch 654/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1618 - accuracy: 0.5495 - top-4-accuracy: 0.9608 - val_loss: 1.5247 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9300\n",
      "Epoch 655/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1190 - accuracy: 0.5815 - top-4-accuracy: 0.9667 - val_loss: 1.4300 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9480\n",
      "Epoch 656/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1194 - accuracy: 0.5675 - top-4-accuracy: 0.9687 - val_loss: 1.4589 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9400\n",
      "Epoch 657/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0671 - accuracy: 0.5852 - top-4-accuracy: 0.9655 - val_loss: 1.4993 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9320\n",
      "Epoch 658/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1271 - accuracy: 0.5566 - top-4-accuracy: 0.9626 - val_loss: 1.5425 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9340\n",
      "Epoch 659/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1442 - accuracy: 0.5580 - top-4-accuracy: 0.9607 - val_loss: 1.5394 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9340\n",
      "Epoch 660/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1178 - accuracy: 0.5659 - top-4-accuracy: 0.9614 - val_loss: 1.4764 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9500\n",
      "Epoch 661/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1275 - accuracy: 0.5661 - top-4-accuracy: 0.9645 - val_loss: 1.4577 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9460\n",
      "Epoch 662/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1337 - accuracy: 0.5582 - top-4-accuracy: 0.9591 - val_loss: 1.4763 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9480\n",
      "Epoch 663/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0678 - accuracy: 0.5733 - top-4-accuracy: 0.9735 - val_loss: 1.4681 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9420\n",
      "Epoch 664/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0922 - accuracy: 0.5714 - top-4-accuracy: 0.9721 - val_loss: 1.5318 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9240\n",
      "Epoch 665/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1350 - accuracy: 0.5385 - top-4-accuracy: 0.9619 - val_loss: 1.5260 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9320\n",
      "Epoch 666/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1001 - accuracy: 0.5746 - top-4-accuracy: 0.9669 - val_loss: 1.4817 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9320\n",
      "Epoch 667/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1118 - accuracy: 0.5641 - top-4-accuracy: 0.9683 - val_loss: 1.4633 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9320\n",
      "Epoch 668/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1193 - accuracy: 0.5457 - top-4-accuracy: 0.9692 - val_loss: 1.4382 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9440\n",
      "Epoch 669/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0827 - accuracy: 0.5685 - top-4-accuracy: 0.9725 - val_loss: 1.4856 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9480\n",
      "Epoch 670/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1466 - accuracy: 0.5482 - top-4-accuracy: 0.9644 - val_loss: 1.5077 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9280\n",
      "Epoch 671/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1212 - accuracy: 0.5787 - top-4-accuracy: 0.9647 - val_loss: 1.4028 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9500\n",
      "Epoch 672/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0535 - accuracy: 0.6058 - top-4-accuracy: 0.9740 - val_loss: 1.4527 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9500\n",
      "Epoch 673/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1031 - accuracy: 0.5825 - top-4-accuracy: 0.9706 - val_loss: 1.4811 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9460\n",
      "Epoch 674/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1292 - accuracy: 0.5653 - top-4-accuracy: 0.9663 - val_loss: 1.4486 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9480\n",
      "Epoch 675/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0985 - accuracy: 0.5675 - top-4-accuracy: 0.9628 - val_loss: 1.5321 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9420\n",
      "Epoch 676/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1104 - accuracy: 0.5641 - top-4-accuracy: 0.9687 - val_loss: 1.5344 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9360\n",
      "Epoch 677/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1119 - accuracy: 0.5706 - top-4-accuracy: 0.9642 - val_loss: 1.4963 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9360\n",
      "Epoch 678/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1123 - accuracy: 0.5631 - top-4-accuracy: 0.9677 - val_loss: 1.4885 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9300\n",
      "Epoch 679/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1140 - accuracy: 0.5727 - top-4-accuracy: 0.9631 - val_loss: 1.4751 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9360\n",
      "Epoch 680/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1547 - accuracy: 0.5515 - top-4-accuracy: 0.9570 - val_loss: 1.4570 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9460\n",
      "Epoch 681/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1392 - accuracy: 0.5617 - top-4-accuracy: 0.9613 - val_loss: 1.4636 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9420\n",
      "Epoch 682/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1184 - accuracy: 0.5699 - top-4-accuracy: 0.9644 - val_loss: 1.5171 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9300\n",
      "Epoch 683/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1223 - accuracy: 0.5612 - top-4-accuracy: 0.9608 - val_loss: 1.4568 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9380\n",
      "Epoch 684/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1223 - accuracy: 0.5540 - top-4-accuracy: 0.9700 - val_loss: 1.4837 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9420\n",
      "Epoch 685/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1007 - accuracy: 0.5663 - top-4-accuracy: 0.9667 - val_loss: 1.4978 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9480\n",
      "Epoch 686/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1218 - accuracy: 0.5683 - top-4-accuracy: 0.9676 - val_loss: 1.4716 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9440\n",
      "Epoch 687/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0824 - accuracy: 0.5834 - top-4-accuracy: 0.9636 - val_loss: 1.4560 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9540\n",
      "Epoch 688/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1416 - accuracy: 0.5444 - top-4-accuracy: 0.9610 - val_loss: 1.4335 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9480\n",
      "Epoch 689/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0954 - accuracy: 0.5672 - top-4-accuracy: 0.9682 - val_loss: 1.5763 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9280\n",
      "Epoch 690/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1366 - accuracy: 0.5597 - top-4-accuracy: 0.9686 - val_loss: 1.4638 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9580\n",
      "Epoch 691/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1118 - accuracy: 0.5687 - top-4-accuracy: 0.9658 - val_loss: 1.4365 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9480\n",
      "Epoch 692/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1207 - accuracy: 0.5585 - top-4-accuracy: 0.9663 - val_loss: 1.5136 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9200\n",
      "Epoch 693/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0954 - accuracy: 0.5659 - top-4-accuracy: 0.9652 - val_loss: 1.4898 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9400\n",
      "Epoch 694/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1541 - accuracy: 0.5560 - top-4-accuracy: 0.9639 - val_loss: 1.4695 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9360\n",
      "Epoch 695/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1140 - accuracy: 0.5667 - top-4-accuracy: 0.9663 - val_loss: 1.4438 - val_accuracy: 0.3900 - val_top-4-accuracy: 0.9460\n",
      "Epoch 696/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0824 - accuracy: 0.5762 - top-4-accuracy: 0.9678 - val_loss: 1.4525 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9520\n",
      "Epoch 697/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0898 - accuracy: 0.5779 - top-4-accuracy: 0.9705 - val_loss: 1.4922 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9320\n",
      "Epoch 698/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0821 - accuracy: 0.5852 - top-4-accuracy: 0.9690 - val_loss: 1.4535 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9420\n",
      "Epoch 699/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1179 - accuracy: 0.5623 - top-4-accuracy: 0.9645 - val_loss: 1.3726 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9620\n",
      "Epoch 700/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1231 - accuracy: 0.5625 - top-4-accuracy: 0.9634 - val_loss: 1.3951 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9360\n",
      "Epoch 701/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1216 - accuracy: 0.5499 - top-4-accuracy: 0.9683 - val_loss: 1.4876 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9260\n",
      "Epoch 702/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1009 - accuracy: 0.5760 - top-4-accuracy: 0.9713 - val_loss: 1.4843 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9300\n",
      "Epoch 703/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1302 - accuracy: 0.5643 - top-4-accuracy: 0.9678 - val_loss: 1.3982 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9580\n",
      "Epoch 704/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0756 - accuracy: 0.5870 - top-4-accuracy: 0.9685 - val_loss: 1.4448 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9540\n",
      "Epoch 705/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1437 - accuracy: 0.5592 - top-4-accuracy: 0.9600 - val_loss: 1.4471 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9460\n",
      "Epoch 706/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1120 - accuracy: 0.5643 - top-4-accuracy: 0.9669 - val_loss: 1.4774 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9320\n",
      "Epoch 707/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0943 - accuracy: 0.5655 - top-4-accuracy: 0.9643 - val_loss: 1.4832 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9440\n",
      "Epoch 708/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1070 - accuracy: 0.5680 - top-4-accuracy: 0.9712 - val_loss: 1.4227 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9340\n",
      "Epoch 709/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1053 - accuracy: 0.5819 - top-4-accuracy: 0.9597 - val_loss: 1.5223 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9460\n",
      "Epoch 710/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0969 - accuracy: 0.5751 - top-4-accuracy: 0.9674 - val_loss: 1.4478 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9400\n",
      "Epoch 711/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1128 - accuracy: 0.5731 - top-4-accuracy: 0.9626 - val_loss: 1.4125 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9580\n",
      "Epoch 712/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0813 - accuracy: 0.5772 - top-4-accuracy: 0.9666 - val_loss: 1.4692 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9500\n",
      "Epoch 713/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1407 - accuracy: 0.5625 - top-4-accuracy: 0.9607 - val_loss: 1.4516 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9500\n",
      "Epoch 714/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0786 - accuracy: 0.5738 - top-4-accuracy: 0.9692 - val_loss: 1.4834 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9360\n",
      "Epoch 715/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1084 - accuracy: 0.5738 - top-4-accuracy: 0.9702 - val_loss: 1.4288 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9480\n",
      "Epoch 716/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1238 - accuracy: 0.5713 - top-4-accuracy: 0.9600 - val_loss: 1.4504 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9340\n",
      "Epoch 717/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1105 - accuracy: 0.5564 - top-4-accuracy: 0.9648 - val_loss: 1.4819 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9360\n",
      "Epoch 718/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0993 - accuracy: 0.5718 - top-4-accuracy: 0.9639 - val_loss: 1.4675 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9420\n",
      "Epoch 719/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0763 - accuracy: 0.5910 - top-4-accuracy: 0.9662 - val_loss: 1.4870 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9480\n",
      "Epoch 720/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1305 - accuracy: 0.5668 - top-4-accuracy: 0.9692 - val_loss: 1.4819 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9380\n",
      "Epoch 721/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1298 - accuracy: 0.5544 - top-4-accuracy: 0.9638 - val_loss: 1.4571 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9480\n",
      "Epoch 722/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0642 - accuracy: 0.5733 - top-4-accuracy: 0.9734 - val_loss: 1.4714 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9280\n",
      "Epoch 723/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1212 - accuracy: 0.5532 - top-4-accuracy: 0.9708 - val_loss: 1.4388 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9540\n",
      "Epoch 724/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1516 - accuracy: 0.5410 - top-4-accuracy: 0.9588 - val_loss: 1.4865 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9420\n",
      "Epoch 725/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1314 - accuracy: 0.5585 - top-4-accuracy: 0.9629 - val_loss: 1.4080 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9520\n",
      "Epoch 726/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1078 - accuracy: 0.5623 - top-4-accuracy: 0.9632 - val_loss: 1.4548 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9480\n",
      "Epoch 727/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0991 - accuracy: 0.5705 - top-4-accuracy: 0.9657 - val_loss: 1.4622 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9440\n",
      "Epoch 728/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0723 - accuracy: 0.5944 - top-4-accuracy: 0.9715 - val_loss: 1.4454 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9420\n",
      "Epoch 729/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0996 - accuracy: 0.5656 - top-4-accuracy: 0.9671 - val_loss: 1.4439 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9380\n",
      "Epoch 730/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0891 - accuracy: 0.5817 - top-4-accuracy: 0.9617 - val_loss: 1.4519 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9340\n",
      "Epoch 731/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1412 - accuracy: 0.5664 - top-4-accuracy: 0.9618 - val_loss: 1.4677 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9380\n",
      "Epoch 732/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1044 - accuracy: 0.5642 - top-4-accuracy: 0.9661 - val_loss: 1.4518 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9460\n",
      "Epoch 733/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1510 - accuracy: 0.5517 - top-4-accuracy: 0.9641 - val_loss: 1.4614 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9420\n",
      "Epoch 734/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1565 - accuracy: 0.5449 - top-4-accuracy: 0.9643 - val_loss: 1.4457 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9380\n",
      "Epoch 735/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1364 - accuracy: 0.5694 - top-4-accuracy: 0.9627 - val_loss: 1.5067 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9340\n",
      "Epoch 736/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0855 - accuracy: 0.5742 - top-4-accuracy: 0.9683 - val_loss: 1.5291 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9320\n",
      "Epoch 737/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1352 - accuracy: 0.5621 - top-4-accuracy: 0.9646 - val_loss: 1.4313 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9420\n",
      "Epoch 738/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1512 - accuracy: 0.5521 - top-4-accuracy: 0.9616 - val_loss: 1.5058 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9220\n",
      "Epoch 739/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1558 - accuracy: 0.5554 - top-4-accuracy: 0.9605 - val_loss: 1.4674 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9300\n",
      "Epoch 740/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1022 - accuracy: 0.5696 - top-4-accuracy: 0.9652 - val_loss: 1.4353 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9500\n",
      "Epoch 741/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0980 - accuracy: 0.5600 - top-4-accuracy: 0.9675 - val_loss: 1.4330 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9400\n",
      "Epoch 742/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1435 - accuracy: 0.5598 - top-4-accuracy: 0.9593 - val_loss: 1.4154 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9480\n",
      "Epoch 743/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1296 - accuracy: 0.5665 - top-4-accuracy: 0.9570 - val_loss: 1.4649 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9460\n",
      "Epoch 744/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1040 - accuracy: 0.5692 - top-4-accuracy: 0.9669 - val_loss: 1.4484 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9460\n",
      "Epoch 745/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1577 - accuracy: 0.5449 - top-4-accuracy: 0.9596 - val_loss: 1.4406 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9320\n",
      "Epoch 746/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0956 - accuracy: 0.5831 - top-4-accuracy: 0.9639 - val_loss: 1.4662 - val_accuracy: 0.4660 - val_top-4-accuracy: 0.9380\n",
      "Epoch 747/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1227 - accuracy: 0.5635 - top-4-accuracy: 0.9663 - val_loss: 1.4199 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9420\n",
      "Epoch 748/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1534 - accuracy: 0.5464 - top-4-accuracy: 0.9628 - val_loss: 1.3983 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9360\n",
      "Epoch 749/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0619 - accuracy: 0.5786 - top-4-accuracy: 0.9749 - val_loss: 1.4281 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9500\n",
      "Epoch 750/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1203 - accuracy: 0.5696 - top-4-accuracy: 0.9613 - val_loss: 1.4264 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9480\n",
      "Epoch 751/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1425 - accuracy: 0.5527 - top-4-accuracy: 0.9640 - val_loss: 1.4467 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9400\n",
      "Epoch 752/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0894 - accuracy: 0.5756 - top-4-accuracy: 0.9655 - val_loss: 1.4211 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9460\n",
      "Epoch 753/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1299 - accuracy: 0.5579 - top-4-accuracy: 0.9662 - val_loss: 1.4493 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9380\n",
      "Epoch 754/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1343 - accuracy: 0.5725 - top-4-accuracy: 0.9578 - val_loss: 1.4166 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9500\n",
      "Epoch 755/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0788 - accuracy: 0.5836 - top-4-accuracy: 0.9675 - val_loss: 1.4463 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9440\n",
      "Epoch 756/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0864 - accuracy: 0.5741 - top-4-accuracy: 0.9686 - val_loss: 1.5480 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9220\n",
      "Epoch 757/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1542 - accuracy: 0.5586 - top-4-accuracy: 0.9617 - val_loss: 1.4543 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9420\n",
      "Epoch 758/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1556 - accuracy: 0.5582 - top-4-accuracy: 0.9612 - val_loss: 1.4759 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9340\n",
      "Epoch 759/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0952 - accuracy: 0.5758 - top-4-accuracy: 0.9698 - val_loss: 1.3880 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9480\n",
      "Epoch 760/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1017 - accuracy: 0.5761 - top-4-accuracy: 0.9626 - val_loss: 1.4608 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9400\n",
      "Epoch 761/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1234 - accuracy: 0.5664 - top-4-accuracy: 0.9645 - val_loss: 1.4778 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9480\n",
      "Epoch 762/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1350 - accuracy: 0.5677 - top-4-accuracy: 0.9575 - val_loss: 1.4065 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9400\n",
      "Epoch 763/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1439 - accuracy: 0.5478 - top-4-accuracy: 0.9575 - val_loss: 1.5479 - val_accuracy: 0.3660 - val_top-4-accuracy: 0.9400\n",
      "Epoch 764/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1309 - accuracy: 0.5582 - top-4-accuracy: 0.9661 - val_loss: 1.4447 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9440\n",
      "Epoch 765/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0954 - accuracy: 0.5844 - top-4-accuracy: 0.9706 - val_loss: 1.4244 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9440\n",
      "Epoch 766/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1176 - accuracy: 0.5558 - top-4-accuracy: 0.9590 - val_loss: 1.4530 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9420\n",
      "Epoch 767/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1170 - accuracy: 0.5754 - top-4-accuracy: 0.9629 - val_loss: 1.4824 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9380\n",
      "Epoch 768/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1164 - accuracy: 0.5680 - top-4-accuracy: 0.9698 - val_loss: 1.4462 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9520\n",
      "Epoch 769/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1361 - accuracy: 0.5625 - top-4-accuracy: 0.9614 - val_loss: 1.4029 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9460\n",
      "Epoch 770/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1681 - accuracy: 0.5470 - top-4-accuracy: 0.9609 - val_loss: 1.4692 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9520\n",
      "Epoch 771/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1120 - accuracy: 0.5809 - top-4-accuracy: 0.9651 - val_loss: 1.4324 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9400\n",
      "Epoch 772/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0966 - accuracy: 0.5743 - top-4-accuracy: 0.9691 - val_loss: 1.4116 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9420\n",
      "Epoch 773/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1209 - accuracy: 0.5604 - top-4-accuracy: 0.9611 - val_loss: 1.4228 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9380\n",
      "Epoch 774/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1168 - accuracy: 0.5663 - top-4-accuracy: 0.9672 - val_loss: 1.4548 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9440\n",
      "Epoch 775/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1826 - accuracy: 0.5437 - top-4-accuracy: 0.9568 - val_loss: 1.4046 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9400\n",
      "Epoch 776/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1393 - accuracy: 0.5434 - top-4-accuracy: 0.9650 - val_loss: 1.4773 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9520\n",
      "Epoch 777/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1227 - accuracy: 0.5701 - top-4-accuracy: 0.9670 - val_loss: 1.4509 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9420\n",
      "Epoch 778/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0476 - accuracy: 0.5928 - top-4-accuracy: 0.9732 - val_loss: 1.4149 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9560\n",
      "Epoch 779/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1508 - accuracy: 0.5413 - top-4-accuracy: 0.9618 - val_loss: 1.4027 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9500\n",
      "Epoch 780/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1218 - accuracy: 0.5699 - top-4-accuracy: 0.9662 - val_loss: 1.3953 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9520\n",
      "Epoch 781/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0995 - accuracy: 0.5766 - top-4-accuracy: 0.9641 - val_loss: 1.3969 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9520\n",
      "Epoch 782/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0778 - accuracy: 0.5717 - top-4-accuracy: 0.9673 - val_loss: 1.4841 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9280\n",
      "Epoch 783/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1190 - accuracy: 0.5596 - top-4-accuracy: 0.9633 - val_loss: 1.4495 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9480\n",
      "Epoch 784/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0698 - accuracy: 0.5867 - top-4-accuracy: 0.9712 - val_loss: 1.4374 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9480\n",
      "Epoch 785/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0879 - accuracy: 0.5769 - top-4-accuracy: 0.9677 - val_loss: 1.4381 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9480\n",
      "Epoch 786/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1080 - accuracy: 0.5698 - top-4-accuracy: 0.9592 - val_loss: 1.3617 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9540\n",
      "Epoch 787/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0947 - accuracy: 0.5570 - top-4-accuracy: 0.9733 - val_loss: 1.4253 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9520\n",
      "Epoch 788/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1673 - accuracy: 0.5535 - top-4-accuracy: 0.9550 - val_loss: 1.3799 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9580\n",
      "Epoch 789/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0884 - accuracy: 0.5915 - top-4-accuracy: 0.9692 - val_loss: 1.4220 - val_accuracy: 0.4660 - val_top-4-accuracy: 0.9480\n",
      "Epoch 790/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1441 - accuracy: 0.5569 - top-4-accuracy: 0.9609 - val_loss: 1.4456 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9520\n",
      "Epoch 791/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1366 - accuracy: 0.5340 - top-4-accuracy: 0.9623 - val_loss: 1.4341 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9460\n",
      "Epoch 792/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1096 - accuracy: 0.5741 - top-4-accuracy: 0.9632 - val_loss: 1.4738 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9520\n",
      "Epoch 793/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1195 - accuracy: 0.5609 - top-4-accuracy: 0.9665 - val_loss: 1.4106 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9640\n",
      "Epoch 794/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1227 - accuracy: 0.5613 - top-4-accuracy: 0.9656 - val_loss: 1.4674 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9560\n",
      "Epoch 795/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1698 - accuracy: 0.5446 - top-4-accuracy: 0.9555 - val_loss: 1.4415 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9480\n",
      "Epoch 796/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0930 - accuracy: 0.5757 - top-4-accuracy: 0.9672 - val_loss: 1.4310 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9520\n",
      "Epoch 797/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0681 - accuracy: 0.5761 - top-4-accuracy: 0.9742 - val_loss: 1.4285 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9480\n",
      "Epoch 798/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1539 - accuracy: 0.5613 - top-4-accuracy: 0.9595 - val_loss: 1.4782 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9420\n",
      "Epoch 799/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1195 - accuracy: 0.5661 - top-4-accuracy: 0.9671 - val_loss: 1.4368 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9400\n",
      "Epoch 800/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0824 - accuracy: 0.5780 - top-4-accuracy: 0.9686 - val_loss: 1.4220 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9460\n",
      "Epoch 801/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1519 - accuracy: 0.5494 - top-4-accuracy: 0.9650 - val_loss: 1.4126 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9460\n",
      "Epoch 802/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0978 - accuracy: 0.5838 - top-4-accuracy: 0.9630 - val_loss: 1.3907 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9440\n",
      "Epoch 803/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0928 - accuracy: 0.5859 - top-4-accuracy: 0.9664 - val_loss: 1.4499 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9600\n",
      "Epoch 804/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1439 - accuracy: 0.5529 - top-4-accuracy: 0.9634 - val_loss: 1.4178 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9560\n",
      "Epoch 805/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0857 - accuracy: 0.5732 - top-4-accuracy: 0.9662 - val_loss: 1.4646 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9400\n",
      "Epoch 806/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1415 - accuracy: 0.5712 - top-4-accuracy: 0.9619 - val_loss: 1.3978 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9440\n",
      "Epoch 807/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1954 - accuracy: 0.5411 - top-4-accuracy: 0.9546 - val_loss: 1.4267 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9580\n",
      "Epoch 808/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1143 - accuracy: 0.5661 - top-4-accuracy: 0.9653 - val_loss: 1.3911 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9600\n",
      "Epoch 809/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1326 - accuracy: 0.5502 - top-4-accuracy: 0.9645 - val_loss: 1.3809 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9560\n",
      "Epoch 810/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0698 - accuracy: 0.5877 - top-4-accuracy: 0.9694 - val_loss: 1.3852 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9500\n",
      "Epoch 811/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0905 - accuracy: 0.5684 - top-4-accuracy: 0.9681 - val_loss: 1.4548 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9420\n",
      "Epoch 812/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1426 - accuracy: 0.5553 - top-4-accuracy: 0.9569 - val_loss: 1.4376 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9360\n",
      "Epoch 813/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1042 - accuracy: 0.5560 - top-4-accuracy: 0.9668 - val_loss: 1.4158 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9620\n",
      "Epoch 814/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0873 - accuracy: 0.5857 - top-4-accuracy: 0.9707 - val_loss: 1.4324 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9540\n",
      "Epoch 815/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1257 - accuracy: 0.5599 - top-4-accuracy: 0.9650 - val_loss: 1.4218 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9620\n",
      "Epoch 816/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0993 - accuracy: 0.5697 - top-4-accuracy: 0.9628 - val_loss: 1.3780 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9620\n",
      "Epoch 817/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1165 - accuracy: 0.5586 - top-4-accuracy: 0.9614 - val_loss: 1.3936 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9540\n",
      "Epoch 818/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1062 - accuracy: 0.5711 - top-4-accuracy: 0.9728 - val_loss: 1.4410 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9540\n",
      "Epoch 819/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1545 - accuracy: 0.5620 - top-4-accuracy: 0.9598 - val_loss: 1.4174 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9600\n",
      "Epoch 820/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0753 - accuracy: 0.5852 - top-4-accuracy: 0.9710 - val_loss: 1.4525 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9360\n",
      "Epoch 821/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1130 - accuracy: 0.5729 - top-4-accuracy: 0.9599 - val_loss: 1.4335 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9420\n",
      "Epoch 822/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1680 - accuracy: 0.5575 - top-4-accuracy: 0.9549 - val_loss: 1.4128 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9460\n",
      "Epoch 823/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1143 - accuracy: 0.5636 - top-4-accuracy: 0.9675 - val_loss: 1.4788 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9340\n",
      "Epoch 824/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1497 - accuracy: 0.5457 - top-4-accuracy: 0.9649 - val_loss: 1.3871 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9500\n",
      "Epoch 825/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0825 - accuracy: 0.5792 - top-4-accuracy: 0.9642 - val_loss: 1.4668 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9400\n",
      "Epoch 826/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1223 - accuracy: 0.5735 - top-4-accuracy: 0.9674 - val_loss: 1.5172 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9220\n",
      "Epoch 827/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2021 - accuracy: 0.5513 - top-4-accuracy: 0.9527 - val_loss: 1.4192 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9380\n",
      "Epoch 828/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1218 - accuracy: 0.5544 - top-4-accuracy: 0.9652 - val_loss: 1.4004 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9440\n",
      "Epoch 829/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0826 - accuracy: 0.5750 - top-4-accuracy: 0.9696 - val_loss: 1.3894 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9460\n",
      "Epoch 830/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0881 - accuracy: 0.5563 - top-4-accuracy: 0.9700 - val_loss: 1.3942 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9540\n",
      "Epoch 831/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0863 - accuracy: 0.5746 - top-4-accuracy: 0.9731 - val_loss: 1.4682 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9480\n",
      "Epoch 832/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0769 - accuracy: 0.5956 - top-4-accuracy: 0.9655 - val_loss: 1.3620 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9560\n",
      "Epoch 833/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0602 - accuracy: 0.5760 - top-4-accuracy: 0.9747 - val_loss: 1.4020 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9480\n",
      "Epoch 834/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1277 - accuracy: 0.5574 - top-4-accuracy: 0.9651 - val_loss: 1.3883 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9440\n",
      "Epoch 835/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1144 - accuracy: 0.5698 - top-4-accuracy: 0.9722 - val_loss: 1.4185 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9460\n",
      "Epoch 836/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1384 - accuracy: 0.5649 - top-4-accuracy: 0.9570 - val_loss: 1.4262 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9420\n",
      "Epoch 837/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1385 - accuracy: 0.5539 - top-4-accuracy: 0.9647 - val_loss: 1.4068 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9460\n",
      "Epoch 838/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1011 - accuracy: 0.5831 - top-4-accuracy: 0.9653 - val_loss: 1.4033 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9520\n",
      "Epoch 839/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0968 - accuracy: 0.5636 - top-4-accuracy: 0.9658 - val_loss: 1.3841 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9520\n",
      "Epoch 840/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1293 - accuracy: 0.5557 - top-4-accuracy: 0.9642 - val_loss: 1.3650 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9480\n",
      "Epoch 841/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0851 - accuracy: 0.5836 - top-4-accuracy: 0.9656 - val_loss: 1.4378 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9460\n",
      "Epoch 842/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1302 - accuracy: 0.5541 - top-4-accuracy: 0.9697 - val_loss: 1.3791 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9520\n",
      "Epoch 843/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1348 - accuracy: 0.5539 - top-4-accuracy: 0.9575 - val_loss: 1.3995 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9480\n",
      "Epoch 844/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1003 - accuracy: 0.5741 - top-4-accuracy: 0.9607 - val_loss: 1.4022 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9380\n",
      "Epoch 845/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0823 - accuracy: 0.5745 - top-4-accuracy: 0.9699 - val_loss: 1.4423 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9400\n",
      "Epoch 846/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1690 - accuracy: 0.5601 - top-4-accuracy: 0.9557 - val_loss: 1.3972 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9500\n",
      "Epoch 847/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1227 - accuracy: 0.5768 - top-4-accuracy: 0.9651 - val_loss: 1.3786 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9580\n",
      "Epoch 848/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1507 - accuracy: 0.5600 - top-4-accuracy: 0.9642 - val_loss: 1.3913 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9540\n",
      "Epoch 849/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1125 - accuracy: 0.5707 - top-4-accuracy: 0.9678 - val_loss: 1.4048 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9420\n",
      "Epoch 850/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0818 - accuracy: 0.5931 - top-4-accuracy: 0.9714 - val_loss: 1.4140 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9500\n",
      "Epoch 851/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0900 - accuracy: 0.5816 - top-4-accuracy: 0.9738 - val_loss: 1.3775 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9500\n",
      "Epoch 852/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0926 - accuracy: 0.5872 - top-4-accuracy: 0.9665 - val_loss: 1.3984 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9540\n",
      "Epoch 853/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1274 - accuracy: 0.5600 - top-4-accuracy: 0.9621 - val_loss: 1.4072 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9520\n",
      "Epoch 854/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0798 - accuracy: 0.5769 - top-4-accuracy: 0.9704 - val_loss: 1.4068 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9360\n",
      "Epoch 855/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0979 - accuracy: 0.5720 - top-4-accuracy: 0.9672 - val_loss: 1.3861 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9540\n",
      "Epoch 856/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1029 - accuracy: 0.5618 - top-4-accuracy: 0.9670 - val_loss: 1.4517 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9500\n",
      "Epoch 857/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1076 - accuracy: 0.5622 - top-4-accuracy: 0.9640 - val_loss: 1.4569 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9400\n",
      "Epoch 858/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1399 - accuracy: 0.5512 - top-4-accuracy: 0.9618 - val_loss: 1.4321 - val_accuracy: 0.3820 - val_top-4-accuracy: 0.9480\n",
      "Epoch 859/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1291 - accuracy: 0.5550 - top-4-accuracy: 0.9676 - val_loss: 1.4044 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9560\n",
      "Epoch 860/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1254 - accuracy: 0.5607 - top-4-accuracy: 0.9608 - val_loss: 1.4105 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9520\n",
      "Epoch 861/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0877 - accuracy: 0.5763 - top-4-accuracy: 0.9639 - val_loss: 1.4247 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9380\n",
      "Epoch 862/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1217 - accuracy: 0.5739 - top-4-accuracy: 0.9631 - val_loss: 1.4053 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9480\n",
      "Epoch 863/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1357 - accuracy: 0.5656 - top-4-accuracy: 0.9572 - val_loss: 1.4538 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9420\n",
      "Epoch 864/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1067 - accuracy: 0.5652 - top-4-accuracy: 0.9686 - val_loss: 1.3639 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9560\n",
      "Epoch 865/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1091 - accuracy: 0.5683 - top-4-accuracy: 0.9698 - val_loss: 1.4345 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9460\n",
      "Epoch 866/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1276 - accuracy: 0.5713 - top-4-accuracy: 0.9598 - val_loss: 1.3970 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9520\n",
      "Epoch 867/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0982 - accuracy: 0.5726 - top-4-accuracy: 0.9681 - val_loss: 1.4181 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9460\n",
      "Epoch 868/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1036 - accuracy: 0.5673 - top-4-accuracy: 0.9704 - val_loss: 1.3743 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9460\n",
      "Epoch 869/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0946 - accuracy: 0.5825 - top-4-accuracy: 0.9663 - val_loss: 1.5046 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9320\n",
      "Epoch 870/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1828 - accuracy: 0.5372 - top-4-accuracy: 0.9541 - val_loss: 1.3651 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9600\n",
      "Epoch 871/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0946 - accuracy: 0.5833 - top-4-accuracy: 0.9669 - val_loss: 1.4113 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9500\n",
      "Epoch 872/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1229 - accuracy: 0.5774 - top-4-accuracy: 0.9623 - val_loss: 1.3888 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9600\n",
      "Epoch 873/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0984 - accuracy: 0.5706 - top-4-accuracy: 0.9679 - val_loss: 1.3786 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9540\n",
      "Epoch 874/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1176 - accuracy: 0.5615 - top-4-accuracy: 0.9679 - val_loss: 1.4348 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9580\n",
      "Epoch 875/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1203 - accuracy: 0.5560 - top-4-accuracy: 0.9659 - val_loss: 1.4413 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9540\n",
      "Epoch 876/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1308 - accuracy: 0.5529 - top-4-accuracy: 0.9631 - val_loss: 1.4358 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9220\n",
      "Epoch 877/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1105 - accuracy: 0.5707 - top-4-accuracy: 0.9717 - val_loss: 1.3864 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9520\n",
      "Epoch 878/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1075 - accuracy: 0.5793 - top-4-accuracy: 0.9653 - val_loss: 1.4547 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9420\n",
      "Epoch 879/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1513 - accuracy: 0.5615 - top-4-accuracy: 0.9594 - val_loss: 1.3470 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9440\n",
      "Epoch 880/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1631 - accuracy: 0.5583 - top-4-accuracy: 0.9531 - val_loss: 1.3169 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9700\n",
      "Epoch 881/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1299 - accuracy: 0.5450 - top-4-accuracy: 0.9630 - val_loss: 1.3930 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9380\n",
      "Epoch 882/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1215 - accuracy: 0.5657 - top-4-accuracy: 0.9623 - val_loss: 1.3788 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9460\n",
      "Epoch 883/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1086 - accuracy: 0.5766 - top-4-accuracy: 0.9630 - val_loss: 1.4372 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9380\n",
      "Epoch 884/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1238 - accuracy: 0.5740 - top-4-accuracy: 0.9636 - val_loss: 1.4061 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9600\n",
      "Epoch 885/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1232 - accuracy: 0.5768 - top-4-accuracy: 0.9630 - val_loss: 1.3817 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9520\n",
      "Epoch 886/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1210 - accuracy: 0.5547 - top-4-accuracy: 0.9657 - val_loss: 1.4471 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9440\n",
      "Epoch 887/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1092 - accuracy: 0.5634 - top-4-accuracy: 0.9687 - val_loss: 1.4306 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9520\n",
      "Epoch 888/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1248 - accuracy: 0.5702 - top-4-accuracy: 0.9647 - val_loss: 1.4555 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9420\n",
      "Epoch 889/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0793 - accuracy: 0.5847 - top-4-accuracy: 0.9716 - val_loss: 1.3677 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9620\n",
      "Epoch 890/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0918 - accuracy: 0.5773 - top-4-accuracy: 0.9704 - val_loss: 1.4112 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9480\n",
      "Epoch 891/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1183 - accuracy: 0.5845 - top-4-accuracy: 0.9607 - val_loss: 1.3601 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9300\n",
      "Epoch 892/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1440 - accuracy: 0.5531 - top-4-accuracy: 0.9678 - val_loss: 1.4208 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9420\n",
      "Epoch 893/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1321 - accuracy: 0.5685 - top-4-accuracy: 0.9597 - val_loss: 1.3976 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9540\n",
      "Epoch 894/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1050 - accuracy: 0.5647 - top-4-accuracy: 0.9676 - val_loss: 1.4605 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9420\n",
      "Epoch 895/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1212 - accuracy: 0.5642 - top-4-accuracy: 0.9664 - val_loss: 1.3510 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9480\n",
      "Epoch 896/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1052 - accuracy: 0.5652 - top-4-accuracy: 0.9728 - val_loss: 1.3907 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9440\n",
      "Epoch 897/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1001 - accuracy: 0.5774 - top-4-accuracy: 0.9663 - val_loss: 1.3566 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9620\n",
      "Epoch 898/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1434 - accuracy: 0.5489 - top-4-accuracy: 0.9594 - val_loss: 1.3837 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9560\n",
      "Epoch 899/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1075 - accuracy: 0.5749 - top-4-accuracy: 0.9649 - val_loss: 1.4214 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9440\n",
      "Epoch 900/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1427 - accuracy: 0.5682 - top-4-accuracy: 0.9604 - val_loss: 1.4341 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9420\n",
      "Epoch 901/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0940 - accuracy: 0.5656 - top-4-accuracy: 0.9707 - val_loss: 1.3751 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9520\n",
      "Epoch 902/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1250 - accuracy: 0.5692 - top-4-accuracy: 0.9547 - val_loss: 1.3703 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9640\n",
      "Epoch 903/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1022 - accuracy: 0.5591 - top-4-accuracy: 0.9627 - val_loss: 1.3607 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9500\n",
      "Epoch 904/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1125 - accuracy: 0.5675 - top-4-accuracy: 0.9615 - val_loss: 1.3355 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9580\n",
      "Epoch 905/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1185 - accuracy: 0.5614 - top-4-accuracy: 0.9690 - val_loss: 1.3665 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9560\n",
      "Epoch 906/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0824 - accuracy: 0.5820 - top-4-accuracy: 0.9691 - val_loss: 1.3731 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9600\n",
      "Epoch 907/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1258 - accuracy: 0.5465 - top-4-accuracy: 0.9621 - val_loss: 1.3636 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9620\n",
      "Epoch 908/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1025 - accuracy: 0.5632 - top-4-accuracy: 0.9674 - val_loss: 1.3665 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9520\n",
      "Epoch 909/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1110 - accuracy: 0.5620 - top-4-accuracy: 0.9698 - val_loss: 1.3762 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9440\n",
      "Epoch 910/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1325 - accuracy: 0.5517 - top-4-accuracy: 0.9641 - val_loss: 1.3982 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9460\n",
      "Epoch 911/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1195 - accuracy: 0.5608 - top-4-accuracy: 0.9691 - val_loss: 1.4306 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9420\n",
      "Epoch 912/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1321 - accuracy: 0.5561 - top-4-accuracy: 0.9581 - val_loss: 1.3971 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9540\n",
      "Epoch 913/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1106 - accuracy: 0.5697 - top-4-accuracy: 0.9680 - val_loss: 1.3660 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9400\n",
      "Epoch 914/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1464 - accuracy: 0.5461 - top-4-accuracy: 0.9605 - val_loss: 1.3749 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9500\n",
      "Epoch 915/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1098 - accuracy: 0.5675 - top-4-accuracy: 0.9634 - val_loss: 1.3990 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9540\n",
      "Epoch 916/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1150 - accuracy: 0.5529 - top-4-accuracy: 0.9740 - val_loss: 1.4219 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9540\n",
      "Epoch 917/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0752 - accuracy: 0.5748 - top-4-accuracy: 0.9707 - val_loss: 1.4112 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9540\n",
      "Epoch 918/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1317 - accuracy: 0.5531 - top-4-accuracy: 0.9680 - val_loss: 1.3800 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9560\n",
      "Epoch 919/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0812 - accuracy: 0.5755 - top-4-accuracy: 0.9707 - val_loss: 1.4109 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9460\n",
      "Epoch 920/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1187 - accuracy: 0.5639 - top-4-accuracy: 0.9629 - val_loss: 1.4259 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9480\n",
      "Epoch 921/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1033 - accuracy: 0.5748 - top-4-accuracy: 0.9670 - val_loss: 1.4073 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9360\n",
      "Epoch 922/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1327 - accuracy: 0.5445 - top-4-accuracy: 0.9606 - val_loss: 1.3962 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9520\n",
      "Epoch 923/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1063 - accuracy: 0.5697 - top-4-accuracy: 0.9694 - val_loss: 1.4780 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9400\n",
      "Epoch 924/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0938 - accuracy: 0.5653 - top-4-accuracy: 0.9643 - val_loss: 1.3984 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9400\n",
      "Epoch 925/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1280 - accuracy: 0.5643 - top-4-accuracy: 0.9545 - val_loss: 1.4051 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9460\n",
      "Epoch 926/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1287 - accuracy: 0.5622 - top-4-accuracy: 0.9642 - val_loss: 1.3879 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9520\n",
      "Epoch 927/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1055 - accuracy: 0.5688 - top-4-accuracy: 0.9638 - val_loss: 1.4049 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9420\n",
      "Epoch 928/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1398 - accuracy: 0.5649 - top-4-accuracy: 0.9574 - val_loss: 1.3417 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9520\n",
      "Epoch 929/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1216 - accuracy: 0.5510 - top-4-accuracy: 0.9704 - val_loss: 1.3368 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9500\n",
      "Epoch 930/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1660 - accuracy: 0.5608 - top-4-accuracy: 0.9596 - val_loss: 1.3671 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9560\n",
      "Epoch 931/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1046 - accuracy: 0.5697 - top-4-accuracy: 0.9598 - val_loss: 1.4106 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9460\n",
      "Epoch 932/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1108 - accuracy: 0.5632 - top-4-accuracy: 0.9675 - val_loss: 1.3564 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9560\n",
      "Epoch 933/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1396 - accuracy: 0.5590 - top-4-accuracy: 0.9590 - val_loss: 1.3609 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9440\n",
      "Epoch 934/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1285 - accuracy: 0.5613 - top-4-accuracy: 0.9595 - val_loss: 1.3324 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9560\n",
      "Epoch 935/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1268 - accuracy: 0.5634 - top-4-accuracy: 0.9642 - val_loss: 1.3600 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9600\n",
      "Epoch 936/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0886 - accuracy: 0.5798 - top-4-accuracy: 0.9684 - val_loss: 1.3875 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9560\n",
      "Epoch 937/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0806 - accuracy: 0.5673 - top-4-accuracy: 0.9704 - val_loss: 1.4516 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9420\n",
      "Epoch 938/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1353 - accuracy: 0.5579 - top-4-accuracy: 0.9687 - val_loss: 1.4118 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9400\n",
      "Epoch 939/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1208 - accuracy: 0.5622 - top-4-accuracy: 0.9707 - val_loss: 1.4221 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9600\n",
      "Epoch 940/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1629 - accuracy: 0.5445 - top-4-accuracy: 0.9653 - val_loss: 1.3480 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9520\n",
      "Epoch 941/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1600 - accuracy: 0.5535 - top-4-accuracy: 0.9570 - val_loss: 1.4325 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9340\n",
      "Epoch 942/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1406 - accuracy: 0.5508 - top-4-accuracy: 0.9616 - val_loss: 1.3436 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9600\n",
      "Epoch 943/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1151 - accuracy: 0.5610 - top-4-accuracy: 0.9649 - val_loss: 1.3941 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9480\n",
      "Epoch 944/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0850 - accuracy: 0.5853 - top-4-accuracy: 0.9699 - val_loss: 1.3321 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9580\n",
      "Epoch 945/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1387 - accuracy: 0.5637 - top-4-accuracy: 0.9616 - val_loss: 1.3860 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9500\n",
      "Epoch 946/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1004 - accuracy: 0.5699 - top-4-accuracy: 0.9697 - val_loss: 1.3371 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9560\n",
      "Epoch 947/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0939 - accuracy: 0.5798 - top-4-accuracy: 0.9709 - val_loss: 1.3887 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9440\n",
      "Epoch 948/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1367 - accuracy: 0.5517 - top-4-accuracy: 0.9612 - val_loss: 1.3309 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9560\n",
      "Epoch 949/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1081 - accuracy: 0.5789 - top-4-accuracy: 0.9634 - val_loss: 1.4415 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9500\n",
      "Epoch 950/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1433 - accuracy: 0.5574 - top-4-accuracy: 0.9658 - val_loss: 1.3791 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9520\n",
      "Epoch 951/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1177 - accuracy: 0.5650 - top-4-accuracy: 0.9644 - val_loss: 1.3861 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9560\n",
      "Epoch 952/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1377 - accuracy: 0.5556 - top-4-accuracy: 0.9636 - val_loss: 1.4279 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9440\n",
      "Epoch 953/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1148 - accuracy: 0.5621 - top-4-accuracy: 0.9659 - val_loss: 1.3989 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9440\n",
      "Epoch 954/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1327 - accuracy: 0.5561 - top-4-accuracy: 0.9619 - val_loss: 1.3974 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9560\n",
      "Epoch 955/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0770 - accuracy: 0.5713 - top-4-accuracy: 0.9722 - val_loss: 1.3864 - val_accuracy: 0.4660 - val_top-4-accuracy: 0.9520\n",
      "Epoch 956/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1165 - accuracy: 0.5692 - top-4-accuracy: 0.9681 - val_loss: 1.4063 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9500\n",
      "Epoch 957/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1297 - accuracy: 0.5582 - top-4-accuracy: 0.9575 - val_loss: 1.3981 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9480\n",
      "Epoch 958/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1323 - accuracy: 0.5547 - top-4-accuracy: 0.9648 - val_loss: 1.4150 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9480\n",
      "Epoch 959/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1579 - accuracy: 0.5586 - top-4-accuracy: 0.9567 - val_loss: 1.3883 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9600\n",
      "Epoch 960/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1228 - accuracy: 0.5735 - top-4-accuracy: 0.9612 - val_loss: 1.3541 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9520\n",
      "Epoch 961/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0877 - accuracy: 0.5720 - top-4-accuracy: 0.9647 - val_loss: 1.3842 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9540\n",
      "Epoch 962/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0913 - accuracy: 0.5753 - top-4-accuracy: 0.9673 - val_loss: 1.3930 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9540\n",
      "Epoch 963/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1362 - accuracy: 0.5525 - top-4-accuracy: 0.9638 - val_loss: 1.4062 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9400\n",
      "Epoch 964/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1095 - accuracy: 0.5763 - top-4-accuracy: 0.9672 - val_loss: 1.3286 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9660\n",
      "Epoch 965/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1246 - accuracy: 0.5541 - top-4-accuracy: 0.9601 - val_loss: 1.3681 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9560\n",
      "Epoch 966/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1479 - accuracy: 0.5458 - top-4-accuracy: 0.9667 - val_loss: 1.4523 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9480\n",
      "Epoch 967/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1227 - accuracy: 0.5613 - top-4-accuracy: 0.9658 - val_loss: 1.4190 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9360\n",
      "Epoch 968/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0860 - accuracy: 0.5769 - top-4-accuracy: 0.9664 - val_loss: 1.3589 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9560\n",
      "Epoch 969/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1299 - accuracy: 0.5556 - top-4-accuracy: 0.9685 - val_loss: 1.3897 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9460\n",
      "Epoch 970/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1215 - accuracy: 0.5558 - top-4-accuracy: 0.9710 - val_loss: 1.4333 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9500\n",
      "Epoch 971/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1394 - accuracy: 0.5484 - top-4-accuracy: 0.9639 - val_loss: 1.3780 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9500\n",
      "Epoch 972/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0969 - accuracy: 0.5844 - top-4-accuracy: 0.9688 - val_loss: 1.3900 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9480\n",
      "Epoch 973/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0945 - accuracy: 0.5700 - top-4-accuracy: 0.9687 - val_loss: 1.4369 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9420\n",
      "Epoch 974/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1319 - accuracy: 0.5594 - top-4-accuracy: 0.9610 - val_loss: 1.4391 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9380\n",
      "Epoch 975/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1351 - accuracy: 0.5394 - top-4-accuracy: 0.9658 - val_loss: 1.3893 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9500\n",
      "Epoch 976/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1648 - accuracy: 0.5564 - top-4-accuracy: 0.9558 - val_loss: 1.3702 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9520\n",
      "Epoch 977/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1274 - accuracy: 0.5524 - top-4-accuracy: 0.9641 - val_loss: 1.3691 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9560\n",
      "Epoch 978/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1062 - accuracy: 0.5748 - top-4-accuracy: 0.9671 - val_loss: 1.3845 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9460\n",
      "Epoch 979/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1069 - accuracy: 0.5682 - top-4-accuracy: 0.9680 - val_loss: 1.3892 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9480\n",
      "Epoch 980/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1124 - accuracy: 0.5800 - top-4-accuracy: 0.9653 - val_loss: 1.3877 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9460\n",
      "Epoch 981/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1222 - accuracy: 0.5698 - top-4-accuracy: 0.9605 - val_loss: 1.3755 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9480\n",
      "Epoch 982/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.1495 - accuracy: 0.5421 - top-4-accuracy: 0.9616 - val_loss: 1.3805 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9500\n",
      "Epoch 983/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1086 - accuracy: 0.5594 - top-4-accuracy: 0.9656 - val_loss: 1.3419 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9580\n",
      "Epoch 984/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0690 - accuracy: 0.5640 - top-4-accuracy: 0.9692 - val_loss: 1.3953 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9480\n",
      "Epoch 985/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1013 - accuracy: 0.5634 - top-4-accuracy: 0.9660 - val_loss: 1.4170 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9420\n",
      "Epoch 986/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1275 - accuracy: 0.5438 - top-4-accuracy: 0.9697 - val_loss: 1.4157 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9520\n",
      "Epoch 987/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1928 - accuracy: 0.5375 - top-4-accuracy: 0.9506 - val_loss: 1.3060 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9540\n",
      "Epoch 988/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1175 - accuracy: 0.5615 - top-4-accuracy: 0.9630 - val_loss: 1.3511 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9580\n",
      "Epoch 989/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0784 - accuracy: 0.5734 - top-4-accuracy: 0.9671 - val_loss: 1.3417 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9620\n",
      "Epoch 990/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0968 - accuracy: 0.5896 - top-4-accuracy: 0.9658 - val_loss: 1.3711 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9340\n",
      "Epoch 991/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0867 - accuracy: 0.5892 - top-4-accuracy: 0.9632 - val_loss: 1.4056 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9600\n",
      "Epoch 992/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1642 - accuracy: 0.5462 - top-4-accuracy: 0.9612 - val_loss: 1.4069 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9520\n",
      "Epoch 993/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0908 - accuracy: 0.5727 - top-4-accuracy: 0.9677 - val_loss: 1.3614 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9480\n",
      "Epoch 994/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1407 - accuracy: 0.5672 - top-4-accuracy: 0.9589 - val_loss: 1.3307 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9540\n",
      "Epoch 995/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1233 - accuracy: 0.5765 - top-4-accuracy: 0.9632 - val_loss: 1.4008 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9500\n",
      "Epoch 996/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1370 - accuracy: 0.5695 - top-4-accuracy: 0.9565 - val_loss: 1.4167 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9520\n",
      "Epoch 997/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1144 - accuracy: 0.5612 - top-4-accuracy: 0.9645 - val_loss: 1.3789 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9540\n",
      "Epoch 998/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1172 - accuracy: 0.5680 - top-4-accuracy: 0.9639 - val_loss: 1.3511 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9460\n",
      "Epoch 999/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1171 - accuracy: 0.5611 - top-4-accuracy: 0.9676 - val_loss: 1.3319 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9580\n",
      "Epoch 1000/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0926 - accuracy: 0.5870 - top-4-accuracy: 0.9652 - val_loss: 1.3255 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9580\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3743 - accuracy: 0.4320 - top-4-accuracy: 0.9460\n",
      "Test accuracy: 43.2%\n",
      "Test top 5 accuracy: 94.6%\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    vit_classifier = create_vit_classifier()\n",
    "    history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "third-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional n epochs? - will overwrite history...\n",
    "# num_epochs = 20\n",
    "# history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "engaged-aviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)  \n",
    "  \n",
    "# summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "   \n",
    "# summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-charm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "71/71 [==============================] - 9s 57ms/step - loss: 1.1125 - accuracy: 0.5714 - top-4-accuracy: 0.9656 - val_loss: 1.2996 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9560\n",
      "Epoch 2/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 1.0759 - accuracy: 0.5816 - top-4-accuracy: 0.9733 - val_loss: 1.2632 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9680\n",
      "Epoch 3/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 1.0259 - accuracy: 0.6104 - top-4-accuracy: 0.9779 - val_loss: 1.2401 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9680\n",
      "Epoch 4/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 1.0047 - accuracy: 0.6164 - top-4-accuracy: 0.9779 - val_loss: 1.2504 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9720\n",
      "Epoch 5/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.9782 - accuracy: 0.6325 - top-4-accuracy: 0.9785 - val_loss: 1.2464 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9700\n",
      "Epoch 6/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 0.9782 - accuracy: 0.6363 - top-4-accuracy: 0.9789 - val_loss: 1.2526 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9660\n",
      "Epoch 7/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 0.9827 - accuracy: 0.6242 - top-4-accuracy: 0.9808 - val_loss: 1.2505 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9780\n",
      "Epoch 8/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 0.9945 - accuracy: 0.6208 - top-4-accuracy: 0.9805 - val_loss: 1.2829 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9660\n",
      "Epoch 9/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0004 - accuracy: 0.6149 - top-4-accuracy: 0.9780 - val_loss: 1.2585 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9700\n",
      "Epoch 10/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 0.9911 - accuracy: 0.6230 - top-4-accuracy: 0.9788 - val_loss: 1.2760 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9620\n",
      "Epoch 11/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0307 - accuracy: 0.6045 - top-4-accuracy: 0.9732 - val_loss: 1.2819 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9620\n",
      "Epoch 12/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 0.9923 - accuracy: 0.6194 - top-4-accuracy: 0.9796 - val_loss: 1.2831 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9700\n",
      "Epoch 13/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0291 - accuracy: 0.6095 - top-4-accuracy: 0.9737 - val_loss: 1.3081 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9660\n",
      "Epoch 14/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0151 - accuracy: 0.6144 - top-4-accuracy: 0.9757 - val_loss: 1.3255 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9580\n",
      "Epoch 15/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0260 - accuracy: 0.5971 - top-4-accuracy: 0.9747 - val_loss: 1.3139 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9620\n",
      "Epoch 16/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0601 - accuracy: 0.5960 - top-4-accuracy: 0.9730 - val_loss: 1.3738 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9500\n",
      "Epoch 17/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0936 - accuracy: 0.5830 - top-4-accuracy: 0.9708 - val_loss: 1.3484 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9600\n",
      "Epoch 18/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0770 - accuracy: 0.5870 - top-4-accuracy: 0.9697 - val_loss: 1.4018 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9440\n",
      "Epoch 19/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0484 - accuracy: 0.6081 - top-4-accuracy: 0.9720 - val_loss: 1.3471 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9620\n",
      "Epoch 20/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0875 - accuracy: 0.5784 - top-4-accuracy: 0.9769 - val_loss: 1.3770 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9580\n",
      "Epoch 21/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 1.1337 - accuracy: 0.5759 - top-4-accuracy: 0.9603 - val_loss: 1.3649 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9600\n",
      "Epoch 22/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1046 - accuracy: 0.5646 - top-4-accuracy: 0.9666 - val_loss: 1.4009 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9480\n",
      "Epoch 23/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1341 - accuracy: 0.5677 - top-4-accuracy: 0.9640 - val_loss: 1.3607 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9600\n",
      "Epoch 24/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1574 - accuracy: 0.5530 - top-4-accuracy: 0.9579 - val_loss: 1.3758 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9540\n",
      "Epoch 25/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1427 - accuracy: 0.5405 - top-4-accuracy: 0.9644 - val_loss: 1.3876 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9660\n",
      "Epoch 26/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1664 - accuracy: 0.5461 - top-4-accuracy: 0.9556 - val_loss: 1.3456 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9560\n",
      "Epoch 27/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1382 - accuracy: 0.5643 - top-4-accuracy: 0.9619 - val_loss: 1.3558 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9620\n",
      "Epoch 28/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1714 - accuracy: 0.5331 - top-4-accuracy: 0.9613 - val_loss: 1.3888 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9540\n",
      "Epoch 29/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1404 - accuracy: 0.5683 - top-4-accuracy: 0.9625 - val_loss: 1.4097 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9500\n",
      "Epoch 30/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1560 - accuracy: 0.5451 - top-4-accuracy: 0.9654 - val_loss: 1.4178 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9380\n",
      "Epoch 31/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1789 - accuracy: 0.5249 - top-4-accuracy: 0.9529 - val_loss: 1.4760 - val_accuracy: 0.4080 - val_top-4-accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2376 - accuracy: 0.5142 - top-4-accuracy: 0.9531 - val_loss: 1.3298 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9640\n",
      "Epoch 33/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1973 - accuracy: 0.5102 - top-4-accuracy: 0.9627 - val_loss: 1.4332 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9460\n",
      "Epoch 34/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2193 - accuracy: 0.5233 - top-4-accuracy: 0.9476 - val_loss: 1.4034 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1993 - accuracy: 0.5324 - top-4-accuracy: 0.9579 - val_loss: 1.3846 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9540\n",
      "Epoch 36/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1713 - accuracy: 0.5677 - top-4-accuracy: 0.9569 - val_loss: 1.3693 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9620\n",
      "Epoch 37/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1996 - accuracy: 0.5294 - top-4-accuracy: 0.9496 - val_loss: 1.3902 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2080 - accuracy: 0.5112 - top-4-accuracy: 0.9543 - val_loss: 1.4396 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2409 - accuracy: 0.5226 - top-4-accuracy: 0.9457 - val_loss: 1.3724 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9540\n",
      "Epoch 40/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2381 - accuracy: 0.5139 - top-4-accuracy: 0.9485 - val_loss: 1.4420 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9340\n",
      "Epoch 41/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2557 - accuracy: 0.5160 - top-4-accuracy: 0.9481 - val_loss: 1.3655 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9460\n",
      "Epoch 42/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1972 - accuracy: 0.5338 - top-4-accuracy: 0.9555 - val_loss: 1.4201 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9480\n",
      "Epoch 43/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2240 - accuracy: 0.5350 - top-4-accuracy: 0.9536 - val_loss: 1.4441 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9260\n",
      "Epoch 44/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2826 - accuracy: 0.4933 - top-4-accuracy: 0.9445 - val_loss: 1.4320 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9480\n",
      "Epoch 45/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2323 - accuracy: 0.5078 - top-4-accuracy: 0.9561 - val_loss: 1.4090 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9380\n",
      "Epoch 46/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2393 - accuracy: 0.5075 - top-4-accuracy: 0.9550 - val_loss: 1.5163 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9060\n",
      "Epoch 47/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2880 - accuracy: 0.5027 - top-4-accuracy: 0.9386 - val_loss: 1.3621 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2433 - accuracy: 0.5070 - top-4-accuracy: 0.9495 - val_loss: 1.3935 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9360\n",
      "Epoch 49/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2699 - accuracy: 0.5029 - top-4-accuracy: 0.9463 - val_loss: 1.3433 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9520\n",
      "Epoch 50/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2804 - accuracy: 0.4979 - top-4-accuracy: 0.9351 - val_loss: 1.4427 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9400\n",
      "Epoch 51/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3099 - accuracy: 0.4930 - top-4-accuracy: 0.9413 - val_loss: 1.5029 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.9240\n",
      "Epoch 52/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3181 - accuracy: 0.4907 - top-4-accuracy: 0.9355 - val_loss: 1.3650 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2546 - accuracy: 0.4887 - top-4-accuracy: 0.9546 - val_loss: 1.3983 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9460\n",
      "Epoch 54/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2778 - accuracy: 0.4843 - top-4-accuracy: 0.9485 - val_loss: 1.3830 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9420\n",
      "Epoch 55/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3020 - accuracy: 0.4784 - top-4-accuracy: 0.9410 - val_loss: 1.3852 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9460\n",
      "Epoch 56/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2418 - accuracy: 0.5142 - top-4-accuracy: 0.9490 - val_loss: 1.4298 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9300\n",
      "Epoch 57/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2610 - accuracy: 0.5024 - top-4-accuracy: 0.9471 - val_loss: 1.4624 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9260\n",
      "Epoch 58/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3949 - accuracy: 0.4572 - top-4-accuracy: 0.9212 - val_loss: 1.4840 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9120\n",
      "Epoch 59/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2862 - accuracy: 0.4955 - top-4-accuracy: 0.9435 - val_loss: 1.4532 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9420\n",
      "Epoch 60/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2875 - accuracy: 0.4874 - top-4-accuracy: 0.9418 - val_loss: 1.4237 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9240\n",
      "Epoch 61/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2768 - accuracy: 0.5006 - top-4-accuracy: 0.9454 - val_loss: 1.4638 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9260\n",
      "Epoch 62/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2866 - accuracy: 0.5059 - top-4-accuracy: 0.9352 - val_loss: 1.4579 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9260\n",
      "Epoch 63/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3035 - accuracy: 0.4981 - top-4-accuracy: 0.9438 - val_loss: 1.3835 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9380\n",
      "Epoch 64/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2553 - accuracy: 0.5149 - top-4-accuracy: 0.9481 - val_loss: 1.4149 - val_accuracy: 0.3980 - val_top-4-accuracy: 0.9320\n",
      "Epoch 65/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3040 - accuracy: 0.4827 - top-4-accuracy: 0.9410 - val_loss: 1.4261 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9320\n",
      "Epoch 66/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2894 - accuracy: 0.5009 - top-4-accuracy: 0.9439 - val_loss: 1.4117 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9420\n",
      "Epoch 67/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2868 - accuracy: 0.4811 - top-4-accuracy: 0.9468 - val_loss: 1.4222 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2935 - accuracy: 0.4933 - top-4-accuracy: 0.9438 - val_loss: 1.3949 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9380\n",
      "Epoch 69/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3160 - accuracy: 0.4845 - top-4-accuracy: 0.9359 - val_loss: 1.4462 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9200\n",
      "Epoch 70/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3330 - accuracy: 0.4718 - top-4-accuracy: 0.9304 - val_loss: 1.4028 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3011 - accuracy: 0.4910 - top-4-accuracy: 0.9455 - val_loss: 1.3731 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9360\n",
      "Epoch 72/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2791 - accuracy: 0.5025 - top-4-accuracy: 0.9461 - val_loss: 1.4681 - val_accuracy: 0.3880 - val_top-4-accuracy: 0.9160\n",
      "Epoch 73/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3227 - accuracy: 0.4873 - top-4-accuracy: 0.9325 - val_loss: 1.4584 - val_accuracy: 0.4040 - val_top-4-accuracy: 0.9380\n",
      "Epoch 74/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2889 - accuracy: 0.4919 - top-4-accuracy: 0.9431 - val_loss: 1.4233 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9260\n",
      "Epoch 75/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3118 - accuracy: 0.4878 - top-4-accuracy: 0.9400 - val_loss: 1.4350 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9380\n",
      "Epoch 76/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2965 - accuracy: 0.4898 - top-4-accuracy: 0.9408 - val_loss: 1.4081 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9360\n",
      "Epoch 77/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2883 - accuracy: 0.4804 - top-4-accuracy: 0.9475 - val_loss: 1.4318 - val_accuracy: 0.4020 - val_top-4-accuracy: 0.9540\n",
      "Epoch 78/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3829 - accuracy: 0.4609 - top-4-accuracy: 0.9316 - val_loss: 1.3606 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9420\n",
      "Epoch 79/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2919 - accuracy: 0.4786 - top-4-accuracy: 0.9475 - val_loss: 1.4355 - val_accuracy: 0.4060 - val_top-4-accuracy: 0.9340\n",
      "Epoch 80/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.3350 - accuracy: 0.4720 - top-4-accuracy: 0.9314 - val_loss: 1.3458 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 1.3231 - accuracy: 0.4634 - top-4-accuracy: 0.9399 - val_loss: 1.3766 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9460\n",
      "Epoch 82/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2998 - accuracy: 0.4875 - top-4-accuracy: 0.9421 - val_loss: 1.3853 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9440\n",
      "Epoch 83/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2968 - accuracy: 0.4864 - top-4-accuracy: 0.9444 - val_loss: 1.4108 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9340\n",
      "Epoch 84/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3536 - accuracy: 0.4738 - top-4-accuracy: 0.9388 - val_loss: 1.4219 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9340\n",
      "Epoch 85/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3074 - accuracy: 0.4799 - top-4-accuracy: 0.9408 - val_loss: 1.4233 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9220\n",
      "Epoch 86/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3027 - accuracy: 0.4847 - top-4-accuracy: 0.9458 - val_loss: 1.4286 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9260\n",
      "Epoch 87/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2917 - accuracy: 0.4769 - top-4-accuracy: 0.9457 - val_loss: 1.5015 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9300\n",
      "Epoch 88/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3716 - accuracy: 0.4577 - top-4-accuracy: 0.9281 - val_loss: 1.4339 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9480\n",
      "Epoch 89/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3235 - accuracy: 0.4807 - top-4-accuracy: 0.9458 - val_loss: 1.4167 - val_accuracy: 0.4140 - val_top-4-accuracy: 0.9220\n",
      "Epoch 90/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3021 - accuracy: 0.4838 - top-4-accuracy: 0.9448 - val_loss: 1.4725 - val_accuracy: 0.3860 - val_top-4-accuracy: 0.9320\n",
      "Epoch 91/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.3027 - accuracy: 0.4699 - top-4-accuracy: 0.9402 - val_loss: 1.3776 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9440\n",
      "Epoch 92/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3063 - accuracy: 0.4905 - top-4-accuracy: 0.9403 - val_loss: 1.4000 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9440\n",
      "Epoch 93/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.3230 - accuracy: 0.4679 - top-4-accuracy: 0.9368 - val_loss: 1.4300 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9300\n",
      "Epoch 94/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3400 - accuracy: 0.4626 - top-4-accuracy: 0.9371 - val_loss: 1.4128 - val_accuracy: 0.4120 - val_top-4-accuracy: 0.9400\n",
      "Epoch 95/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3643 - accuracy: 0.4600 - top-4-accuracy: 0.9296 - val_loss: 1.3658 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9400\n",
      "Epoch 96/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2878 - accuracy: 0.4847 - top-4-accuracy: 0.9442 - val_loss: 1.4175 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9260\n",
      "Epoch 97/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3326 - accuracy: 0.4684 - top-4-accuracy: 0.9369 - val_loss: 1.3554 - val_accuracy: 0.4660 - val_top-4-accuracy: 0.9300\n",
      "Epoch 98/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3392 - accuracy: 0.4523 - top-4-accuracy: 0.9383 - val_loss: 1.4330 - val_accuracy: 0.4260 - val_top-4-accuracy: 0.9460\n",
      "Epoch 99/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3398 - accuracy: 0.4528 - top-4-accuracy: 0.9423 - val_loss: 1.4026 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9460\n",
      "Epoch 100/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3024 - accuracy: 0.4794 - top-4-accuracy: 0.9452 - val_loss: 1.3963 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9360\n",
      "Epoch 101/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2919 - accuracy: 0.4866 - top-4-accuracy: 0.9487 - val_loss: 1.3605 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9360\n",
      "Epoch 102/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3242 - accuracy: 0.4893 - top-4-accuracy: 0.9320 - val_loss: 1.3948 - val_accuracy: 0.4160 - val_top-4-accuracy: 0.9540\n",
      "Epoch 103/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3341 - accuracy: 0.4724 - top-4-accuracy: 0.9333 - val_loss: 1.3659 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9400\n",
      "Epoch 104/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2922 - accuracy: 0.4886 - top-4-accuracy: 0.9492 - val_loss: 1.3490 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9540\n",
      "Epoch 105/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3208 - accuracy: 0.4679 - top-4-accuracy: 0.9387 - val_loss: 1.4222 - val_accuracy: 0.3960 - val_top-4-accuracy: 0.9320\n",
      "Epoch 106/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3209 - accuracy: 0.4584 - top-4-accuracy: 0.9417 - val_loss: 1.3429 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9600\n",
      "Epoch 107/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2772 - accuracy: 0.4782 - top-4-accuracy: 0.9504 - val_loss: 1.3970 - val_accuracy: 0.4100 - val_top-4-accuracy: 0.9440\n",
      "Epoch 108/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2811 - accuracy: 0.4924 - top-4-accuracy: 0.9481 - val_loss: 1.3963 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9500\n",
      "Epoch 109/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2587 - accuracy: 0.4936 - top-4-accuracy: 0.9499 - val_loss: 1.5173 - val_accuracy: 0.3840 - val_top-4-accuracy: 0.9140\n",
      "Epoch 110/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.3918 - accuracy: 0.4409 - top-4-accuracy: 0.9326 - val_loss: 1.3773 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9440\n",
      "Epoch 111/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2723 - accuracy: 0.4843 - top-4-accuracy: 0.9460 - val_loss: 1.3883 - val_accuracy: 0.4240 - val_top-4-accuracy: 0.9340\n",
      "Epoch 112/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2664 - accuracy: 0.4831 - top-4-accuracy: 0.9524 - val_loss: 1.4508 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9300\n",
      "Epoch 113/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2545 - accuracy: 0.5000 - top-4-accuracy: 0.9519 - val_loss: 1.3794 - val_accuracy: 0.4220 - val_top-4-accuracy: 0.9600\n",
      "Epoch 114/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.3017 - accuracy: 0.4795 - top-4-accuracy: 0.9491 - val_loss: 1.3531 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9460\n",
      "Epoch 115/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2855 - accuracy: 0.4804 - top-4-accuracy: 0.9470 - val_loss: 1.3725 - val_accuracy: 0.4320 - val_top-4-accuracy: 0.9380\n",
      "Epoch 116/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2618 - accuracy: 0.4967 - top-4-accuracy: 0.9443 - val_loss: 1.3814 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9360\n",
      "Epoch 117/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2464 - accuracy: 0.5049 - top-4-accuracy: 0.9517 - val_loss: 1.3312 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9500\n",
      "Epoch 118/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2601 - accuracy: 0.5047 - top-4-accuracy: 0.9504 - val_loss: 1.4392 - val_accuracy: 0.4000 - val_top-4-accuracy: 0.9320\n",
      "Epoch 119/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2267 - accuracy: 0.5076 - top-4-accuracy: 0.9583 - val_loss: 1.3685 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9500\n",
      "Epoch 120/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2395 - accuracy: 0.5115 - top-4-accuracy: 0.9541 - val_loss: 1.4185 - val_accuracy: 0.4200 - val_top-4-accuracy: 0.9400\n",
      "Epoch 121/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2242 - accuracy: 0.4978 - top-4-accuracy: 0.9575 - val_loss: 1.3327 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9500\n",
      "Epoch 122/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2924 - accuracy: 0.4770 - top-4-accuracy: 0.9508 - val_loss: 1.3406 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9540\n",
      "Epoch 123/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1939 - accuracy: 0.5135 - top-4-accuracy: 0.9626 - val_loss: 1.3550 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9580\n",
      "Epoch 124/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.2001 - accuracy: 0.5180 - top-4-accuracy: 0.9598 - val_loss: 1.2642 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9600\n",
      "Epoch 125/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2351 - accuracy: 0.4996 - top-4-accuracy: 0.9569 - val_loss: 1.4198 - val_accuracy: 0.4180 - val_top-4-accuracy: 0.9500\n",
      "Epoch 126/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2436 - accuracy: 0.4852 - top-4-accuracy: 0.9553 - val_loss: 1.4489 - val_accuracy: 0.3940 - val_top-4-accuracy: 0.9320\n",
      "Epoch 127/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2456 - accuracy: 0.5178 - top-4-accuracy: 0.9542 - val_loss: 1.3485 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9580\n",
      "Epoch 128/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2372 - accuracy: 0.5231 - top-4-accuracy: 0.9521 - val_loss: 1.3734 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9400\n",
      "Epoch 129/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2357 - accuracy: 0.5008 - top-4-accuracy: 0.9563 - val_loss: 1.3373 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9540\n",
      "Epoch 130/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.1739 - accuracy: 0.5321 - top-4-accuracy: 0.9589 - val_loss: 1.3639 - val_accuracy: 0.4360 - val_top-4-accuracy: 0.9560\n",
      "Epoch 131/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2065 - accuracy: 0.5162 - top-4-accuracy: 0.9567 - val_loss: 1.3442 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9560\n",
      "Epoch 132/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2184 - accuracy: 0.4988 - top-4-accuracy: 0.9573 - val_loss: 1.2777 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9560\n",
      "Epoch 133/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.2214 - accuracy: 0.5134 - top-4-accuracy: 0.9548 - val_loss: 1.3688 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9560\n",
      "Epoch 134/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1765 - accuracy: 0.5361 - top-4-accuracy: 0.9631 - val_loss: 1.3163 - val_accuracy: 0.4380 - val_top-4-accuracy: 0.9680\n",
      "Epoch 135/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2486 - accuracy: 0.4990 - top-4-accuracy: 0.9550 - val_loss: 1.3766 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9380\n",
      "Epoch 136/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1897 - accuracy: 0.5250 - top-4-accuracy: 0.9620 - val_loss: 1.3770 - val_accuracy: 0.4300 - val_top-4-accuracy: 0.9540\n",
      "Epoch 137/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1591 - accuracy: 0.5270 - top-4-accuracy: 0.9683 - val_loss: 1.3283 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9500\n",
      "Epoch 138/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2393 - accuracy: 0.5080 - top-4-accuracy: 0.9511 - val_loss: 1.3438 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9600\n",
      "Epoch 139/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2249 - accuracy: 0.5165 - top-4-accuracy: 0.9544 - val_loss: 1.3282 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9560\n",
      "Epoch 140/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2421 - accuracy: 0.5066 - top-4-accuracy: 0.9506 - val_loss: 1.3667 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9540\n",
      "Epoch 141/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1574 - accuracy: 0.5442 - top-4-accuracy: 0.9553 - val_loss: 1.3763 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9500\n",
      "Epoch 142/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1886 - accuracy: 0.5349 - top-4-accuracy: 0.9587 - val_loss: 1.3089 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9680\n",
      "Epoch 143/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1621 - accuracy: 0.5344 - top-4-accuracy: 0.9600 - val_loss: 1.3120 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9700\n",
      "Epoch 144/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.2011 - accuracy: 0.5128 - top-4-accuracy: 0.9600 - val_loss: 1.3869 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9500\n",
      "Epoch 145/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1958 - accuracy: 0.5335 - top-4-accuracy: 0.9618 - val_loss: 1.3907 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9560\n",
      "Epoch 146/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1754 - accuracy: 0.5448 - top-4-accuracy: 0.9565 - val_loss: 1.3499 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9600\n",
      "Epoch 147/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1923 - accuracy: 0.5345 - top-4-accuracy: 0.9595 - val_loss: 1.3247 - val_accuracy: 0.4440 - val_top-4-accuracy: 0.9600\n",
      "Epoch 148/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1696 - accuracy: 0.5245 - top-4-accuracy: 0.9582 - val_loss: 1.3882 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9440\n",
      "Epoch 149/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1856 - accuracy: 0.5239 - top-4-accuracy: 0.9544 - val_loss: 1.3540 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9560\n",
      "Epoch 150/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1612 - accuracy: 0.5381 - top-4-accuracy: 0.9569 - val_loss: 1.3399 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9540\n",
      "Epoch 151/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1586 - accuracy: 0.5204 - top-4-accuracy: 0.9632 - val_loss: 1.3515 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9580\n",
      "Epoch 152/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1609 - accuracy: 0.5408 - top-4-accuracy: 0.9676 - val_loss: 1.3193 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9640\n",
      "Epoch 153/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0988 - accuracy: 0.5731 - top-4-accuracy: 0.9690 - val_loss: 1.3583 - val_accuracy: 0.4340 - val_top-4-accuracy: 0.9640\n",
      "Epoch 154/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1283 - accuracy: 0.5527 - top-4-accuracy: 0.9697 - val_loss: 1.3772 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9540\n",
      "Epoch 155/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1313 - accuracy: 0.5490 - top-4-accuracy: 0.9659 - val_loss: 1.4003 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9560\n",
      "Epoch 156/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1837 - accuracy: 0.5268 - top-4-accuracy: 0.9536 - val_loss: 1.3483 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9620\n",
      "Epoch 157/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1206 - accuracy: 0.5431 - top-4-accuracy: 0.9644 - val_loss: 1.3429 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9560\n",
      "Epoch 158/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1953 - accuracy: 0.5341 - top-4-accuracy: 0.9625 - val_loss: 1.4037 - val_accuracy: 0.4280 - val_top-4-accuracy: 0.9460\n",
      "Epoch 159/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1296 - accuracy: 0.5503 - top-4-accuracy: 0.9666 - val_loss: 1.3275 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9600\n",
      "Epoch 160/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1247 - accuracy: 0.5585 - top-4-accuracy: 0.9679 - val_loss: 1.3443 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9560\n",
      "Epoch 161/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1165 - accuracy: 0.5482 - top-4-accuracy: 0.9684 - val_loss: 1.3297 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9680\n",
      "Epoch 162/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1060 - accuracy: 0.5633 - top-4-accuracy: 0.9686 - val_loss: 1.3059 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9660\n",
      "Epoch 163/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1172 - accuracy: 0.5655 - top-4-accuracy: 0.9660 - val_loss: 1.3074 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9640\n",
      "Epoch 164/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1050 - accuracy: 0.5421 - top-4-accuracy: 0.9708 - val_loss: 1.3488 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9600\n",
      "Epoch 165/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1368 - accuracy: 0.5476 - top-4-accuracy: 0.9657 - val_loss: 1.3623 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9560\n",
      "Epoch 166/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1541 - accuracy: 0.5376 - top-4-accuracy: 0.9630 - val_loss: 1.3844 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9480\n",
      "Epoch 167/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1147 - accuracy: 0.5542 - top-4-accuracy: 0.9694 - val_loss: 1.3969 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9540\n",
      "Epoch 168/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0893 - accuracy: 0.5540 - top-4-accuracy: 0.9668 - val_loss: 1.3344 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9640\n",
      "Epoch 169/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0995 - accuracy: 0.5612 - top-4-accuracy: 0.9717 - val_loss: 1.3012 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9600\n",
      "Epoch 170/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0894 - accuracy: 0.5623 - top-4-accuracy: 0.9740 - val_loss: 1.3599 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9560\n",
      "Epoch 171/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1641 - accuracy: 0.5346 - top-4-accuracy: 0.9597 - val_loss: 1.3172 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9620\n",
      "Epoch 172/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1133 - accuracy: 0.5634 - top-4-accuracy: 0.9671 - val_loss: 1.3740 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9540\n",
      "Epoch 173/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1123 - accuracy: 0.5586 - top-4-accuracy: 0.9640 - val_loss: 1.4111 - val_accuracy: 0.4400 - val_top-4-accuracy: 0.9520\n",
      "Epoch 174/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1475 - accuracy: 0.5395 - top-4-accuracy: 0.9621 - val_loss: 1.3742 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9460\n",
      "Epoch 175/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0758 - accuracy: 0.5649 - top-4-accuracy: 0.9729 - val_loss: 1.3826 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9520\n",
      "Epoch 176/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1008 - accuracy: 0.5492 - top-4-accuracy: 0.9709 - val_loss: 1.4089 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9560\n",
      "Epoch 177/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1273 - accuracy: 0.5501 - top-4-accuracy: 0.9666 - val_loss: 1.3345 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9500\n",
      "Epoch 178/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0822 - accuracy: 0.5644 - top-4-accuracy: 0.9722 - val_loss: 1.3157 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9600\n",
      "Epoch 179/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0793 - accuracy: 0.5652 - top-4-accuracy: 0.9731 - val_loss: 1.2858 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9620\n",
      "Epoch 180/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1229 - accuracy: 0.5560 - top-4-accuracy: 0.9618 - val_loss: 1.3366 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9640\n",
      "Epoch 181/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1124 - accuracy: 0.5608 - top-4-accuracy: 0.9654 - val_loss: 1.3383 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9640\n",
      "Epoch 182/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0800 - accuracy: 0.5648 - top-4-accuracy: 0.9724 - val_loss: 1.3523 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9600\n",
      "Epoch 183/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0714 - accuracy: 0.5803 - top-4-accuracy: 0.9655 - val_loss: 1.3444 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9600\n",
      "Epoch 184/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0684 - accuracy: 0.5693 - top-4-accuracy: 0.9674 - val_loss: 1.3732 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9420\n",
      "Epoch 185/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0900 - accuracy: 0.5642 - top-4-accuracy: 0.9650 - val_loss: 1.2932 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9680\n",
      "Epoch 186/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0515 - accuracy: 0.5805 - top-4-accuracy: 0.9750 - val_loss: 1.4291 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9460\n",
      "Epoch 187/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0754 - accuracy: 0.5730 - top-4-accuracy: 0.9731 - val_loss: 1.3685 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9580\n",
      "Epoch 188/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1060 - accuracy: 0.5576 - top-4-accuracy: 0.9662 - val_loss: 1.4103 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9480\n",
      "Epoch 189/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0731 - accuracy: 0.5643 - top-4-accuracy: 0.9704 - val_loss: 1.3768 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9640\n",
      "Epoch 190/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1102 - accuracy: 0.5571 - top-4-accuracy: 0.9730 - val_loss: 1.3209 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9520\n",
      "Epoch 191/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0958 - accuracy: 0.5642 - top-4-accuracy: 0.9687 - val_loss: 1.3251 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9580\n",
      "Epoch 192/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1238 - accuracy: 0.5540 - top-4-accuracy: 0.9652 - val_loss: 1.3053 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9620\n",
      "Epoch 193/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0556 - accuracy: 0.5799 - top-4-accuracy: 0.9726 - val_loss: 1.3461 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9580\n",
      "Epoch 194/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0689 - accuracy: 0.5725 - top-4-accuracy: 0.9696 - val_loss: 1.3362 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9560\n",
      "Epoch 195/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0914 - accuracy: 0.5733 - top-4-accuracy: 0.9718 - val_loss: 1.3260 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9540\n",
      "Epoch 196/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.1066 - accuracy: 0.5751 - top-4-accuracy: 0.9670 - val_loss: 1.3530 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9540\n",
      "Epoch 197/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0826 - accuracy: 0.5692 - top-4-accuracy: 0.9739 - val_loss: 1.3468 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9600\n",
      "Epoch 198/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0826 - accuracy: 0.5775 - top-4-accuracy: 0.9668 - val_loss: 1.3331 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9620\n",
      "Epoch 199/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0694 - accuracy: 0.5703 - top-4-accuracy: 0.9751 - val_loss: 1.3538 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9660\n",
      "Epoch 200/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0999 - accuracy: 0.5620 - top-4-accuracy: 0.9712 - val_loss: 1.2643 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9600\n",
      "Epoch 201/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0369 - accuracy: 0.5903 - top-4-accuracy: 0.9789 - val_loss: 1.4161 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9520\n",
      "Epoch 202/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0578 - accuracy: 0.5965 - top-4-accuracy: 0.9741 - val_loss: 1.3724 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9700\n",
      "Epoch 203/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0293 - accuracy: 0.5883 - top-4-accuracy: 0.9715 - val_loss: 1.3697 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9520\n",
      "Epoch 204/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0725 - accuracy: 0.5756 - top-4-accuracy: 0.9761 - val_loss: 1.3959 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9520\n",
      "Epoch 205/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0643 - accuracy: 0.5708 - top-4-accuracy: 0.9731 - val_loss: 1.3440 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9520\n",
      "Epoch 206/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0524 - accuracy: 0.5972 - top-4-accuracy: 0.9737 - val_loss: 1.2915 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9660\n",
      "Epoch 207/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0734 - accuracy: 0.5802 - top-4-accuracy: 0.9679 - val_loss: 1.2998 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9680\n",
      "Epoch 208/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9859 - accuracy: 0.6162 - top-4-accuracy: 0.9790 - val_loss: 1.3530 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9580\n",
      "Epoch 209/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0379 - accuracy: 0.5901 - top-4-accuracy: 0.9769 - val_loss: 1.2626 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9600\n",
      "Epoch 210/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9772 - accuracy: 0.6173 - top-4-accuracy: 0.9779 - val_loss: 1.3482 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9520\n",
      "Epoch 211/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0386 - accuracy: 0.5843 - top-4-accuracy: 0.9764 - val_loss: 1.3287 - val_accuracy: 0.4660 - val_top-4-accuracy: 0.9680\n",
      "Epoch 212/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0112 - accuracy: 0.6083 - top-4-accuracy: 0.9730 - val_loss: 1.3619 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9560\n",
      "Epoch 213/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0157 - accuracy: 0.5869 - top-4-accuracy: 0.9826 - val_loss: 1.3211 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9560\n",
      "Epoch 214/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0822 - accuracy: 0.5704 - top-4-accuracy: 0.9719 - val_loss: 1.3671 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9500\n",
      "Epoch 215/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0339 - accuracy: 0.5893 - top-4-accuracy: 0.9789 - val_loss: 1.3616 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9520\n",
      "Epoch 216/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0370 - accuracy: 0.5872 - top-4-accuracy: 0.9741 - val_loss: 1.3474 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9580\n",
      "Epoch 217/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0498 - accuracy: 0.5847 - top-4-accuracy: 0.9779 - val_loss: 1.3064 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9620\n",
      "Epoch 218/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0087 - accuracy: 0.5998 - top-4-accuracy: 0.9740 - val_loss: 1.3820 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9500\n",
      "Epoch 219/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0269 - accuracy: 0.5866 - top-4-accuracy: 0.9760 - val_loss: 1.3697 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9640\n",
      "Epoch 220/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0364 - accuracy: 0.5912 - top-4-accuracy: 0.9723 - val_loss: 1.3538 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9620\n",
      "Epoch 221/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0515 - accuracy: 0.5869 - top-4-accuracy: 0.9767 - val_loss: 1.3084 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9620\n",
      "Epoch 222/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0366 - accuracy: 0.5789 - top-4-accuracy: 0.9791 - val_loss: 1.3356 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9660\n",
      "Epoch 223/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0313 - accuracy: 0.5838 - top-4-accuracy: 0.9754 - val_loss: 1.3412 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9580\n",
      "Epoch 224/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0223 - accuracy: 0.5814 - top-4-accuracy: 0.9743 - val_loss: 1.3323 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9540\n",
      "Epoch 225/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.1223 - accuracy: 0.5605 - top-4-accuracy: 0.9649 - val_loss: 1.3820 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9420\n",
      "Epoch 226/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0375 - accuracy: 0.6049 - top-4-accuracy: 0.9735 - val_loss: 1.3609 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9520\n",
      "Epoch 227/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0151 - accuracy: 0.6034 - top-4-accuracy: 0.9761 - val_loss: 1.4021 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9460\n",
      "Epoch 228/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0184 - accuracy: 0.5950 - top-4-accuracy: 0.9818 - val_loss: 1.3275 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9500\n",
      "Epoch 229/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0078 - accuracy: 0.6023 - top-4-accuracy: 0.9766 - val_loss: 1.4064 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9560\n",
      "Epoch 230/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 1.0123 - accuracy: 0.6001 - top-4-accuracy: 0.9767 - val_loss: 1.3123 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9660\n",
      "Epoch 231/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0348 - accuracy: 0.5847 - top-4-accuracy: 0.9737 - val_loss: 1.3974 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9540\n",
      "Epoch 232/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0628 - accuracy: 0.5847 - top-4-accuracy: 0.9749 - val_loss: 1.3452 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9660\n",
      "Epoch 233/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0191 - accuracy: 0.6002 - top-4-accuracy: 0.9757 - val_loss: 1.3293 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9560\n",
      "Epoch 234/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0123 - accuracy: 0.5966 - top-4-accuracy: 0.9766 - val_loss: 1.3361 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9540\n",
      "Epoch 235/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0587 - accuracy: 0.5855 - top-4-accuracy: 0.9721 - val_loss: 1.3084 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9600\n",
      "Epoch 236/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0207 - accuracy: 0.5975 - top-4-accuracy: 0.9780 - val_loss: 1.3288 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9560\n",
      "Epoch 237/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0211 - accuracy: 0.5997 - top-4-accuracy: 0.9818 - val_loss: 1.3711 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9440\n",
      "Epoch 238/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0126 - accuracy: 0.5884 - top-4-accuracy: 0.9747 - val_loss: 1.3973 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9440\n",
      "Epoch 239/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0035 - accuracy: 0.5989 - top-4-accuracy: 0.9784 - val_loss: 1.3702 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9620\n",
      "Epoch 240/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0144 - accuracy: 0.5992 - top-4-accuracy: 0.9780 - val_loss: 1.3065 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9580\n",
      "Epoch 241/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0253 - accuracy: 0.6061 - top-4-accuracy: 0.9726 - val_loss: 1.3111 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9560\n",
      "Epoch 242/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0037 - accuracy: 0.6002 - top-4-accuracy: 0.9767 - val_loss: 1.3547 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9600\n",
      "Epoch 243/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9977 - accuracy: 0.6052 - top-4-accuracy: 0.9759 - val_loss: 1.4810 - val_accuracy: 0.4500 - val_top-4-accuracy: 0.9320\n",
      "Epoch 244/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9855 - accuracy: 0.6053 - top-4-accuracy: 0.9809 - val_loss: 1.3538 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9520\n",
      "Epoch 245/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0005 - accuracy: 0.6150 - top-4-accuracy: 0.9735 - val_loss: 1.3755 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9480\n",
      "Epoch 246/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0115 - accuracy: 0.6122 - top-4-accuracy: 0.9710 - val_loss: 1.4069 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9500\n",
      "Epoch 247/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9983 - accuracy: 0.6078 - top-4-accuracy: 0.9771 - val_loss: 1.3811 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9460\n",
      "Epoch 248/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0260 - accuracy: 0.5884 - top-4-accuracy: 0.9751 - val_loss: 1.2949 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9640\n",
      "Epoch 249/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9673 - accuracy: 0.6137 - top-4-accuracy: 0.9816 - val_loss: 1.3999 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9520\n",
      "Epoch 250/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0214 - accuracy: 0.6087 - top-4-accuracy: 0.9731 - val_loss: 1.3359 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9600\n",
      "Epoch 251/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9468 - accuracy: 0.6245 - top-4-accuracy: 0.9803 - val_loss: 1.3866 - val_accuracy: 0.4480 - val_top-4-accuracy: 0.9580\n",
      "Epoch 252/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9999 - accuracy: 0.5996 - top-4-accuracy: 0.9767 - val_loss: 1.3695 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9500\n",
      "Epoch 253/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0030 - accuracy: 0.5997 - top-4-accuracy: 0.9823 - val_loss: 1.3363 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9580\n",
      "Epoch 254/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0129 - accuracy: 0.6114 - top-4-accuracy: 0.9781 - val_loss: 1.3282 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9540\n",
      "Epoch 255/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0346 - accuracy: 0.5907 - top-4-accuracy: 0.9719 - val_loss: 1.2958 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9660\n",
      "Epoch 256/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0003 - accuracy: 0.5992 - top-4-accuracy: 0.9769 - val_loss: 1.3468 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9640\n",
      "Epoch 257/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0336 - accuracy: 0.5876 - top-4-accuracy: 0.9719 - val_loss: 1.2598 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9680\n",
      "Epoch 258/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9805 - accuracy: 0.6086 - top-4-accuracy: 0.9785 - val_loss: 1.3378 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9620\n",
      "Epoch 259/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0184 - accuracy: 0.6024 - top-4-accuracy: 0.9793 - val_loss: 1.2957 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9600\n",
      "Epoch 260/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9518 - accuracy: 0.6219 - top-4-accuracy: 0.9806 - val_loss: 1.3741 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9560\n",
      "Epoch 261/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9811 - accuracy: 0.6114 - top-4-accuracy: 0.9798 - val_loss: 1.3642 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9580\n",
      "Epoch 262/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0453 - accuracy: 0.5904 - top-4-accuracy: 0.9705 - val_loss: 1.3398 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9560\n",
      "Epoch 263/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9662 - accuracy: 0.6254 - top-4-accuracy: 0.9791 - val_loss: 1.3128 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9620\n",
      "Epoch 264/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9636 - accuracy: 0.6181 - top-4-accuracy: 0.9769 - val_loss: 1.3726 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9480\n",
      "Epoch 265/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9663 - accuracy: 0.6240 - top-4-accuracy: 0.9836 - val_loss: 1.3533 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9500\n",
      "Epoch 266/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 0.9929 - accuracy: 0.6139 - top-4-accuracy: 0.9787 - val_loss: 1.3581 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9500\n",
      "Epoch 267/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0223 - accuracy: 0.6002 - top-4-accuracy: 0.9735 - val_loss: 1.4382 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9580\n",
      "Epoch 268/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9973 - accuracy: 0.6107 - top-4-accuracy: 0.9795 - val_loss: 1.3358 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9520\n",
      "Epoch 269/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9809 - accuracy: 0.6139 - top-4-accuracy: 0.9767 - val_loss: 1.3020 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9620\n",
      "Epoch 270/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0053 - accuracy: 0.6035 - top-4-accuracy: 0.9737 - val_loss: 1.3077 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9540\n",
      "Epoch 271/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9858 - accuracy: 0.6220 - top-4-accuracy: 0.9768 - val_loss: 1.3458 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9580\n",
      "Epoch 272/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0013 - accuracy: 0.6004 - top-4-accuracy: 0.9740 - val_loss: 1.4236 - val_accuracy: 0.4540 - val_top-4-accuracy: 0.9480\n",
      "Epoch 273/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9893 - accuracy: 0.6115 - top-4-accuracy: 0.9747 - val_loss: 1.2857 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9620\n",
      "Epoch 274/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9865 - accuracy: 0.6193 - top-4-accuracy: 0.9763 - val_loss: 1.4139 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9580\n",
      "Epoch 275/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9978 - accuracy: 0.6114 - top-4-accuracy: 0.9801 - val_loss: 1.2962 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9620\n",
      "Epoch 276/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9621 - accuracy: 0.6146 - top-4-accuracy: 0.9791 - val_loss: 1.2954 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9620\n",
      "Epoch 277/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9809 - accuracy: 0.6114 - top-4-accuracy: 0.9787 - val_loss: 1.3824 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9540\n",
      "Epoch 278/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0289 - accuracy: 0.5930 - top-4-accuracy: 0.9692 - val_loss: 1.3562 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9580\n",
      "Epoch 279/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9696 - accuracy: 0.6238 - top-4-accuracy: 0.9809 - val_loss: 1.3858 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9540\n",
      "Epoch 280/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0008 - accuracy: 0.6017 - top-4-accuracy: 0.9797 - val_loss: 1.4091 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9540\n",
      "Epoch 281/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9981 - accuracy: 0.6079 - top-4-accuracy: 0.9767 - val_loss: 1.2351 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9680\n",
      "Epoch 282/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9732 - accuracy: 0.6163 - top-4-accuracy: 0.9795 - val_loss: 1.3691 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9500\n",
      "Epoch 283/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9871 - accuracy: 0.6144 - top-4-accuracy: 0.9801 - val_loss: 1.2888 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9620\n",
      "Epoch 284/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9508 - accuracy: 0.6419 - top-4-accuracy: 0.9782 - val_loss: 1.3230 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9480\n",
      "Epoch 285/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9977 - accuracy: 0.6031 - top-4-accuracy: 0.9744 - val_loss: 1.3495 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9540\n",
      "Epoch 286/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0110 - accuracy: 0.6125 - top-4-accuracy: 0.9750 - val_loss: 1.2467 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9680\n",
      "Epoch 287/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9735 - accuracy: 0.6140 - top-4-accuracy: 0.9790 - val_loss: 1.3392 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9640\n",
      "Epoch 288/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9571 - accuracy: 0.6181 - top-4-accuracy: 0.9786 - val_loss: 1.3600 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9480\n",
      "Epoch 289/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9668 - accuracy: 0.6247 - top-4-accuracy: 0.9776 - val_loss: 1.3635 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9720\n",
      "Epoch 290/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9854 - accuracy: 0.6087 - top-4-accuracy: 0.9758 - val_loss: 1.3902 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9440\n",
      "Epoch 291/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9753 - accuracy: 0.6223 - top-4-accuracy: 0.9787 - val_loss: 1.3431 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9520\n",
      "Epoch 292/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9465 - accuracy: 0.6321 - top-4-accuracy: 0.9778 - val_loss: 1.3237 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9540\n",
      "Epoch 293/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9652 - accuracy: 0.6163 - top-4-accuracy: 0.9782 - val_loss: 1.4352 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9500\n",
      "Epoch 294/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9827 - accuracy: 0.6158 - top-4-accuracy: 0.9776 - val_loss: 1.3099 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9580\n",
      "Epoch 295/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9506 - accuracy: 0.6130 - top-4-accuracy: 0.9807 - val_loss: 1.3228 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9480\n",
      "Epoch 296/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9393 - accuracy: 0.6257 - top-4-accuracy: 0.9841 - val_loss: 1.3342 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9580\n",
      "Epoch 297/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9492 - accuracy: 0.6330 - top-4-accuracy: 0.9813 - val_loss: 1.3567 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9640\n",
      "Epoch 298/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9806 - accuracy: 0.6101 - top-4-accuracy: 0.9760 - val_loss: 1.3144 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9640\n",
      "Epoch 299/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0296 - accuracy: 0.6076 - top-4-accuracy: 0.9703 - val_loss: 1.3275 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9560\n",
      "Epoch 300/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9811 - accuracy: 0.6124 - top-4-accuracy: 0.9765 - val_loss: 1.4356 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9500\n",
      "Epoch 301/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0362 - accuracy: 0.6052 - top-4-accuracy: 0.9716 - val_loss: 1.2985 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9660\n",
      "Epoch 302/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9577 - accuracy: 0.6221 - top-4-accuracy: 0.9814 - val_loss: 1.4055 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9500\n",
      "Epoch 303/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9686 - accuracy: 0.6174 - top-4-accuracy: 0.9778 - val_loss: 1.3893 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9520\n",
      "Epoch 304/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9558 - accuracy: 0.6154 - top-4-accuracy: 0.9801 - val_loss: 1.3144 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9620\n",
      "Epoch 305/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9708 - accuracy: 0.6131 - top-4-accuracy: 0.9797 - val_loss: 1.3092 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9560\n",
      "Epoch 306/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9466 - accuracy: 0.6119 - top-4-accuracy: 0.9775 - val_loss: 1.3257 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9680\n",
      "Epoch 307/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9244 - accuracy: 0.6331 - top-4-accuracy: 0.9797 - val_loss: 1.3601 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9660\n",
      "Epoch 308/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9527 - accuracy: 0.6246 - top-4-accuracy: 0.9775 - val_loss: 1.3119 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9660\n",
      "Epoch 309/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9538 - accuracy: 0.6396 - top-4-accuracy: 0.9850 - val_loss: 1.3193 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9640\n",
      "Epoch 310/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9702 - accuracy: 0.6285 - top-4-accuracy: 0.9775 - val_loss: 1.3574 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9620\n",
      "Epoch 311/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9430 - accuracy: 0.6296 - top-4-accuracy: 0.9807 - val_loss: 1.3367 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9580\n",
      "Epoch 312/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9686 - accuracy: 0.6322 - top-4-accuracy: 0.9731 - val_loss: 1.2797 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9740\n",
      "Epoch 313/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0077 - accuracy: 0.5994 - top-4-accuracy: 0.9785 - val_loss: 1.3430 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9580\n",
      "Epoch 314/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9308 - accuracy: 0.6423 - top-4-accuracy: 0.9776 - val_loss: 1.3446 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9580\n",
      "Epoch 315/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9583 - accuracy: 0.6112 - top-4-accuracy: 0.9828 - val_loss: 1.3620 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9580\n",
      "Epoch 316/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9688 - accuracy: 0.6135 - top-4-accuracy: 0.9803 - val_loss: 1.3142 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9600\n",
      "Epoch 317/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0121 - accuracy: 0.6048 - top-4-accuracy: 0.9760 - val_loss: 1.3570 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9700\n",
      "Epoch 318/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9463 - accuracy: 0.6221 - top-4-accuracy: 0.9778 - val_loss: 1.2865 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9620\n",
      "Epoch 319/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9860 - accuracy: 0.6125 - top-4-accuracy: 0.9778 - val_loss: 1.3811 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9560\n",
      "Epoch 320/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9549 - accuracy: 0.6350 - top-4-accuracy: 0.9807 - val_loss: 1.3655 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9600\n",
      "Epoch 321/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0073 - accuracy: 0.6046 - top-4-accuracy: 0.9759 - val_loss: 1.3002 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9640\n",
      "Epoch 322/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9258 - accuracy: 0.6352 - top-4-accuracy: 0.9829 - val_loss: 1.2993 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9740\n",
      "Epoch 323/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9302 - accuracy: 0.6442 - top-4-accuracy: 0.9820 - val_loss: 1.4061 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9500\n",
      "Epoch 324/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9689 - accuracy: 0.6230 - top-4-accuracy: 0.9762 - val_loss: 1.2928 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9620\n",
      "Epoch 325/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9694 - accuracy: 0.6153 - top-4-accuracy: 0.9831 - val_loss: 1.2984 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9640\n",
      "Epoch 326/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9361 - accuracy: 0.6241 - top-4-accuracy: 0.9860 - val_loss: 1.4871 - val_accuracy: 0.4420 - val_top-4-accuracy: 0.9400\n",
      "Epoch 327/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9735 - accuracy: 0.6199 - top-4-accuracy: 0.9835 - val_loss: 1.3748 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9700\n",
      "Epoch 328/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9833 - accuracy: 0.6113 - top-4-accuracy: 0.9744 - val_loss: 1.3516 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9520\n",
      "Epoch 329/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9568 - accuracy: 0.6173 - top-4-accuracy: 0.9796 - val_loss: 1.3416 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9580\n",
      "Epoch 330/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9683 - accuracy: 0.6173 - top-4-accuracy: 0.9788 - val_loss: 1.3426 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9620\n",
      "Epoch 331/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9702 - accuracy: 0.6239 - top-4-accuracy: 0.9826 - val_loss: 1.3987 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9480\n",
      "Epoch 332/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9414 - accuracy: 0.6261 - top-4-accuracy: 0.9831 - val_loss: 1.3752 - val_accuracy: 0.4680 - val_top-4-accuracy: 0.9580\n",
      "Epoch 333/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9891 - accuracy: 0.6152 - top-4-accuracy: 0.9742 - val_loss: 1.4115 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9520\n",
      "Epoch 334/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0177 - accuracy: 0.6120 - top-4-accuracy: 0.9751 - val_loss: 1.3162 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9540\n",
      "Epoch 335/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9663 - accuracy: 0.6189 - top-4-accuracy: 0.9738 - val_loss: 1.3828 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9560\n",
      "Epoch 336/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9620 - accuracy: 0.6169 - top-4-accuracy: 0.9798 - val_loss: 1.3506 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9620\n",
      "Epoch 337/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9405 - accuracy: 0.6172 - top-4-accuracy: 0.9808 - val_loss: 1.3349 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9640\n",
      "Epoch 338/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9699 - accuracy: 0.6250 - top-4-accuracy: 0.9743 - val_loss: 1.3192 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9640\n",
      "Epoch 339/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9994 - accuracy: 0.6026 - top-4-accuracy: 0.9763 - val_loss: 1.3139 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9740\n",
      "Epoch 340/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9495 - accuracy: 0.6275 - top-4-accuracy: 0.9832 - val_loss: 1.3683 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9620\n",
      "Epoch 341/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0118 - accuracy: 0.6106 - top-4-accuracy: 0.9785 - val_loss: 1.3180 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9620\n",
      "Epoch 342/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9449 - accuracy: 0.6175 - top-4-accuracy: 0.9827 - val_loss: 1.2955 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9480\n",
      "Epoch 343/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9679 - accuracy: 0.6207 - top-4-accuracy: 0.9822 - val_loss: 1.4014 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9520\n",
      "Epoch 344/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9355 - accuracy: 0.6317 - top-4-accuracy: 0.9779 - val_loss: 1.3588 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9660\n",
      "Epoch 345/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9564 - accuracy: 0.6158 - top-4-accuracy: 0.9829 - val_loss: 1.3114 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9680\n",
      "Epoch 346/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9745 - accuracy: 0.6091 - top-4-accuracy: 0.9793 - val_loss: 1.3351 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9540\n",
      "Epoch 347/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9274 - accuracy: 0.6315 - top-4-accuracy: 0.9831 - val_loss: 1.3386 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9600\n",
      "Epoch 348/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9828 - accuracy: 0.6120 - top-4-accuracy: 0.9765 - val_loss: 1.2920 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9580\n",
      "Epoch 349/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9304 - accuracy: 0.6277 - top-4-accuracy: 0.9828 - val_loss: 1.3688 - val_accuracy: 0.4560 - val_top-4-accuracy: 0.9540\n",
      "Epoch 350/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9807 - accuracy: 0.6103 - top-4-accuracy: 0.9765 - val_loss: 1.3211 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9700\n",
      "Epoch 351/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9311 - accuracy: 0.6282 - top-4-accuracy: 0.9828 - val_loss: 1.3731 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9600\n",
      "Epoch 352/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0081 - accuracy: 0.6023 - top-4-accuracy: 0.9770 - val_loss: 1.3433 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9520\n",
      "Epoch 353/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9634 - accuracy: 0.6140 - top-4-accuracy: 0.9797 - val_loss: 1.2728 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9660\n",
      "Epoch 354/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9652 - accuracy: 0.6182 - top-4-accuracy: 0.9747 - val_loss: 1.3160 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9640\n",
      "Epoch 355/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9292 - accuracy: 0.6248 - top-4-accuracy: 0.9869 - val_loss: 1.2922 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9660\n",
      "Epoch 356/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9036 - accuracy: 0.6580 - top-4-accuracy: 0.9839 - val_loss: 1.4002 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9600\n",
      "Epoch 357/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9801 - accuracy: 0.6173 - top-4-accuracy: 0.9797 - val_loss: 1.3222 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9600\n",
      "Epoch 358/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9656 - accuracy: 0.6133 - top-4-accuracy: 0.9773 - val_loss: 1.3056 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9560\n",
      "Epoch 359/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9352 - accuracy: 0.6241 - top-4-accuracy: 0.9825 - val_loss: 1.3742 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9480\n",
      "Epoch 360/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9800 - accuracy: 0.6213 - top-4-accuracy: 0.9750 - val_loss: 1.3543 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9540\n",
      "Epoch 361/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9752 - accuracy: 0.6264 - top-4-accuracy: 0.9798 - val_loss: 1.3094 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9620\n",
      "Epoch 362/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9536 - accuracy: 0.6229 - top-4-accuracy: 0.9791 - val_loss: 1.3194 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9580\n",
      "Epoch 363/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9550 - accuracy: 0.6282 - top-4-accuracy: 0.9785 - val_loss: 1.4460 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9440\n",
      "Epoch 364/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9630 - accuracy: 0.6253 - top-4-accuracy: 0.9770 - val_loss: 1.3236 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9540\n",
      "Epoch 365/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9057 - accuracy: 0.6437 - top-4-accuracy: 0.9843 - val_loss: 1.4331 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9420\n",
      "Epoch 366/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9865 - accuracy: 0.6233 - top-4-accuracy: 0.9741 - val_loss: 1.3787 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9520\n",
      "Epoch 367/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9723 - accuracy: 0.6217 - top-4-accuracy: 0.9816 - val_loss: 1.2998 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9600\n",
      "Epoch 368/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9382 - accuracy: 0.6576 - top-4-accuracy: 0.9821 - val_loss: 1.3592 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9580\n",
      "Epoch 369/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9408 - accuracy: 0.6268 - top-4-accuracy: 0.9825 - val_loss: 1.3897 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9600\n",
      "Epoch 370/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9848 - accuracy: 0.6129 - top-4-accuracy: 0.9773 - val_loss: 1.3248 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9620\n",
      "Epoch 371/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9531 - accuracy: 0.6369 - top-4-accuracy: 0.9831 - val_loss: 1.4173 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9420\n",
      "Epoch 372/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9351 - accuracy: 0.6438 - top-4-accuracy: 0.9811 - val_loss: 1.3369 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9620\n",
      "Epoch 373/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9547 - accuracy: 0.6380 - top-4-accuracy: 0.9743 - val_loss: 1.3114 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9520\n",
      "Epoch 374/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9976 - accuracy: 0.6174 - top-4-accuracy: 0.9762 - val_loss: 1.3944 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9520\n",
      "Epoch 375/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9896 - accuracy: 0.6113 - top-4-accuracy: 0.9769 - val_loss: 1.2727 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9620\n",
      "Epoch 376/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9401 - accuracy: 0.6386 - top-4-accuracy: 0.9834 - val_loss: 1.2635 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9600\n",
      "Epoch 377/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9552 - accuracy: 0.6276 - top-4-accuracy: 0.9785 - val_loss: 1.3362 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9580\n",
      "Epoch 378/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9781 - accuracy: 0.6039 - top-4-accuracy: 0.9773 - val_loss: 1.3521 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9520\n",
      "Epoch 379/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9502 - accuracy: 0.6246 - top-4-accuracy: 0.9775 - val_loss: 1.3671 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9580\n",
      "Epoch 380/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9812 - accuracy: 0.6173 - top-4-accuracy: 0.9793 - val_loss: 1.4167 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9440\n",
      "Epoch 381/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9837 - accuracy: 0.6037 - top-4-accuracy: 0.9804 - val_loss: 1.3575 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9560\n",
      "Epoch 382/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9368 - accuracy: 0.6305 - top-4-accuracy: 0.9827 - val_loss: 1.3132 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9580\n",
      "Epoch 383/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9673 - accuracy: 0.6155 - top-4-accuracy: 0.9772 - val_loss: 1.3280 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9680\n",
      "Epoch 384/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9383 - accuracy: 0.6217 - top-4-accuracy: 0.9801 - val_loss: 1.3921 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9500\n",
      "Epoch 385/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0275 - accuracy: 0.6063 - top-4-accuracy: 0.9719 - val_loss: 1.3324 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9600\n",
      "Epoch 386/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9394 - accuracy: 0.6292 - top-4-accuracy: 0.9786 - val_loss: 1.3980 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9500\n",
      "Epoch 387/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9373 - accuracy: 0.6330 - top-4-accuracy: 0.9768 - val_loss: 1.4082 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9520\n",
      "Epoch 388/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9557 - accuracy: 0.6285 - top-4-accuracy: 0.9782 - val_loss: 1.2680 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9680\n",
      "Epoch 389/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0004 - accuracy: 0.6300 - top-4-accuracy: 0.9722 - val_loss: 1.3214 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9500\n",
      "Epoch 390/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9457 - accuracy: 0.6256 - top-4-accuracy: 0.9778 - val_loss: 1.4719 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9500\n",
      "Epoch 391/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9856 - accuracy: 0.6238 - top-4-accuracy: 0.9755 - val_loss: 1.3138 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9600\n",
      "Epoch 392/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9353 - accuracy: 0.6365 - top-4-accuracy: 0.9834 - val_loss: 1.3675 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9520\n",
      "Epoch 393/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9687 - accuracy: 0.6123 - top-4-accuracy: 0.9782 - val_loss: 1.3352 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9620\n",
      "Epoch 394/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9465 - accuracy: 0.6246 - top-4-accuracy: 0.9782 - val_loss: 1.2742 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9660\n",
      "Epoch 395/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0099 - accuracy: 0.6215 - top-4-accuracy: 0.9715 - val_loss: 1.2517 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9580\n",
      "Epoch 396/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9780 - accuracy: 0.6199 - top-4-accuracy: 0.9756 - val_loss: 1.2865 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9580\n",
      "Epoch 397/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9733 - accuracy: 0.6224 - top-4-accuracy: 0.9786 - val_loss: 1.3958 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9540\n",
      "Epoch 398/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9538 - accuracy: 0.6156 - top-4-accuracy: 0.9827 - val_loss: 1.3444 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9580\n",
      "Epoch 399/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9257 - accuracy: 0.6274 - top-4-accuracy: 0.9839 - val_loss: 1.3881 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9540\n",
      "Epoch 400/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9686 - accuracy: 0.6230 - top-4-accuracy: 0.9768 - val_loss: 1.3760 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9460\n",
      "Epoch 401/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9583 - accuracy: 0.6346 - top-4-accuracy: 0.9763 - val_loss: 1.3888 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9580\n",
      "Epoch 402/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0135 - accuracy: 0.6014 - top-4-accuracy: 0.9750 - val_loss: 1.3754 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9600\n",
      "Epoch 403/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9267 - accuracy: 0.6445 - top-4-accuracy: 0.9831 - val_loss: 1.3702 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9500\n",
      "Epoch 404/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9837 - accuracy: 0.6085 - top-4-accuracy: 0.9737 - val_loss: 1.3182 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9500\n",
      "Epoch 405/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9372 - accuracy: 0.6331 - top-4-accuracy: 0.9829 - val_loss: 1.3687 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9540\n",
      "Epoch 406/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9630 - accuracy: 0.6173 - top-4-accuracy: 0.9782 - val_loss: 1.3819 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9400\n",
      "Epoch 407/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9649 - accuracy: 0.6219 - top-4-accuracy: 0.9768 - val_loss: 1.3440 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9540\n",
      "Epoch 408/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0023 - accuracy: 0.5996 - top-4-accuracy: 0.9775 - val_loss: 1.3687 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9560\n",
      "Epoch 409/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9516 - accuracy: 0.6416 - top-4-accuracy: 0.9798 - val_loss: 1.2481 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9680\n",
      "Epoch 410/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9689 - accuracy: 0.6229 - top-4-accuracy: 0.9782 - val_loss: 1.3047 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9560\n",
      "Epoch 411/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9616 - accuracy: 0.6278 - top-4-accuracy: 0.9785 - val_loss: 1.3285 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9600\n",
      "Epoch 412/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9690 - accuracy: 0.6169 - top-4-accuracy: 0.9792 - val_loss: 1.3098 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9640\n",
      "Epoch 413/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9899 - accuracy: 0.6126 - top-4-accuracy: 0.9748 - val_loss: 1.3188 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9600\n",
      "Epoch 414/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9468 - accuracy: 0.6363 - top-4-accuracy: 0.9839 - val_loss: 1.4304 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9460\n",
      "Epoch 415/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9661 - accuracy: 0.6008 - top-4-accuracy: 0.9791 - val_loss: 1.3414 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9560\n",
      "Epoch 416/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9425 - accuracy: 0.6254 - top-4-accuracy: 0.9811 - val_loss: 1.4168 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9420\n",
      "Epoch 417/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9339 - accuracy: 0.6395 - top-4-accuracy: 0.9784 - val_loss: 1.3174 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9540\n",
      "Epoch 418/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9597 - accuracy: 0.6210 - top-4-accuracy: 0.9804 - val_loss: 1.3516 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9540\n",
      "Epoch 419/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9774 - accuracy: 0.6158 - top-4-accuracy: 0.9753 - val_loss: 1.3627 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9520\n",
      "Epoch 420/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0048 - accuracy: 0.6020 - top-4-accuracy: 0.9805 - val_loss: 1.3189 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9520\n",
      "Epoch 421/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9286 - accuracy: 0.6334 - top-4-accuracy: 0.9818 - val_loss: 1.3321 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9520\n",
      "Epoch 422/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9857 - accuracy: 0.6135 - top-4-accuracy: 0.9725 - val_loss: 1.3242 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9440\n",
      "Epoch 423/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9499 - accuracy: 0.6327 - top-4-accuracy: 0.9811 - val_loss: 1.3581 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9560\n",
      "Epoch 424/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9526 - accuracy: 0.6400 - top-4-accuracy: 0.9791 - val_loss: 1.3396 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9500\n",
      "Epoch 425/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9557 - accuracy: 0.6229 - top-4-accuracy: 0.9788 - val_loss: 1.3304 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9520\n",
      "Epoch 426/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9317 - accuracy: 0.6379 - top-4-accuracy: 0.9773 - val_loss: 1.2908 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9600\n",
      "Epoch 427/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9781 - accuracy: 0.6084 - top-4-accuracy: 0.9781 - val_loss: 1.2970 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9540\n",
      "Epoch 428/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9700 - accuracy: 0.6169 - top-4-accuracy: 0.9754 - val_loss: 1.3543 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9680\n",
      "Epoch 429/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9141 - accuracy: 0.6346 - top-4-accuracy: 0.9876 - val_loss: 1.4115 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9400\n",
      "Epoch 430/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9528 - accuracy: 0.6217 - top-4-accuracy: 0.9840 - val_loss: 1.2768 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9520\n",
      "Epoch 431/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9181 - accuracy: 0.6348 - top-4-accuracy: 0.9828 - val_loss: 1.3637 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9520\n",
      "Epoch 432/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9404 - accuracy: 0.6346 - top-4-accuracy: 0.9841 - val_loss: 1.3346 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9540\n",
      "Epoch 433/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9438 - accuracy: 0.6245 - top-4-accuracy: 0.9835 - val_loss: 1.3056 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9600\n",
      "Epoch 434/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9843 - accuracy: 0.6101 - top-4-accuracy: 0.9738 - val_loss: 1.3264 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9560\n",
      "Epoch 435/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9200 - accuracy: 0.6428 - top-4-accuracy: 0.9816 - val_loss: 1.3046 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9620\n",
      "Epoch 436/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9457 - accuracy: 0.6208 - top-4-accuracy: 0.9840 - val_loss: 1.2796 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9640\n",
      "Epoch 437/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0065 - accuracy: 0.6200 - top-4-accuracy: 0.9768 - val_loss: 1.3299 - val_accuracy: 0.4620 - val_top-4-accuracy: 0.9680\n",
      "Epoch 438/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9521 - accuracy: 0.6348 - top-4-accuracy: 0.9763 - val_loss: 1.3458 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9560\n",
      "Epoch 439/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9385 - accuracy: 0.6352 - top-4-accuracy: 0.9819 - val_loss: 1.2595 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9600\n",
      "Epoch 440/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9370 - accuracy: 0.6278 - top-4-accuracy: 0.9846 - val_loss: 1.2641 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9640\n",
      "Epoch 441/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9521 - accuracy: 0.6188 - top-4-accuracy: 0.9809 - val_loss: 1.2715 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9580\n",
      "Epoch 442/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9537 - accuracy: 0.6212 - top-4-accuracy: 0.9810 - val_loss: 1.2943 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9580\n",
      "Epoch 443/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9150 - accuracy: 0.6388 - top-4-accuracy: 0.9854 - val_loss: 1.2868 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9660\n",
      "Epoch 444/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9928 - accuracy: 0.6132 - top-4-accuracy: 0.9760 - val_loss: 1.3427 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9480\n",
      "Epoch 445/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9815 - accuracy: 0.6164 - top-4-accuracy: 0.9778 - val_loss: 1.2544 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9720\n",
      "Epoch 446/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9201 - accuracy: 0.6377 - top-4-accuracy: 0.9852 - val_loss: 1.3078 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9580\n",
      "Epoch 447/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9673 - accuracy: 0.6267 - top-4-accuracy: 0.9775 - val_loss: 1.2712 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9620\n",
      "Epoch 448/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9555 - accuracy: 0.6205 - top-4-accuracy: 0.9770 - val_loss: 1.3250 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9620\n",
      "Epoch 449/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9381 - accuracy: 0.6310 - top-4-accuracy: 0.9838 - val_loss: 1.2346 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9700\n",
      "Epoch 450/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9570 - accuracy: 0.6402 - top-4-accuracy: 0.9782 - val_loss: 1.3066 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9600\n",
      "Epoch 451/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9690 - accuracy: 0.6091 - top-4-accuracy: 0.9778 - val_loss: 1.3036 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9600\n",
      "Epoch 452/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9781 - accuracy: 0.6234 - top-4-accuracy: 0.9769 - val_loss: 1.2734 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9680\n",
      "Epoch 453/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9640 - accuracy: 0.6148 - top-4-accuracy: 0.9794 - val_loss: 1.3629 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9520\n",
      "Epoch 454/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9714 - accuracy: 0.6135 - top-4-accuracy: 0.9786 - val_loss: 1.2964 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9520\n",
      "Epoch 455/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9044 - accuracy: 0.6467 - top-4-accuracy: 0.9824 - val_loss: 1.3439 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9620\n",
      "Epoch 456/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9748 - accuracy: 0.6249 - top-4-accuracy: 0.9780 - val_loss: 1.2827 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9560\n",
      "Epoch 457/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9716 - accuracy: 0.6182 - top-4-accuracy: 0.9844 - val_loss: 1.2713 - val_accuracy: 0.5300 - val_top-4-accuracy: 0.9560\n",
      "Epoch 458/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9629 - accuracy: 0.6287 - top-4-accuracy: 0.9798 - val_loss: 1.3558 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9520\n",
      "Epoch 459/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0078 - accuracy: 0.6091 - top-4-accuracy: 0.9741 - val_loss: 1.2786 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9540\n",
      "Epoch 460/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9554 - accuracy: 0.6364 - top-4-accuracy: 0.9765 - val_loss: 1.2380 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9640\n",
      "Epoch 461/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9312 - accuracy: 0.6406 - top-4-accuracy: 0.9830 - val_loss: 1.2850 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9560\n",
      "Epoch 462/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9293 - accuracy: 0.6292 - top-4-accuracy: 0.9824 - val_loss: 1.3247 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9600\n",
      "Epoch 463/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0041 - accuracy: 0.6144 - top-4-accuracy: 0.9772 - val_loss: 1.2742 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9580\n",
      "Epoch 464/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9227 - accuracy: 0.6428 - top-4-accuracy: 0.9828 - val_loss: 1.2371 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9660\n",
      "Epoch 465/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9579 - accuracy: 0.6389 - top-4-accuracy: 0.9785 - val_loss: 1.3514 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9580\n",
      "Epoch 466/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9993 - accuracy: 0.6011 - top-4-accuracy: 0.9746 - val_loss: 1.2941 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9580\n",
      "Epoch 467/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9383 - accuracy: 0.6219 - top-4-accuracy: 0.9770 - val_loss: 1.2922 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9640\n",
      "Epoch 468/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9945 - accuracy: 0.6059 - top-4-accuracy: 0.9798 - val_loss: 1.3865 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9480\n",
      "Epoch 469/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9727 - accuracy: 0.6258 - top-4-accuracy: 0.9788 - val_loss: 1.2505 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9620\n",
      "Epoch 470/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9219 - accuracy: 0.6385 - top-4-accuracy: 0.9854 - val_loss: 1.2705 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9540\n",
      "Epoch 471/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9923 - accuracy: 0.6086 - top-4-accuracy: 0.9778 - val_loss: 1.3007 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9580\n",
      "Epoch 472/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9763 - accuracy: 0.6210 - top-4-accuracy: 0.9810 - val_loss: 1.3460 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9600\n",
      "Epoch 473/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9448 - accuracy: 0.6298 - top-4-accuracy: 0.9827 - val_loss: 1.2747 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9580\n",
      "Epoch 474/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9457 - accuracy: 0.6257 - top-4-accuracy: 0.9801 - val_loss: 1.2708 - val_accuracy: 0.5400 - val_top-4-accuracy: 0.9540\n",
      "Epoch 475/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9515 - accuracy: 0.6236 - top-4-accuracy: 0.9785 - val_loss: 1.2657 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9580\n",
      "Epoch 476/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9728 - accuracy: 0.6078 - top-4-accuracy: 0.9770 - val_loss: 1.2626 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9680\n",
      "Epoch 477/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9282 - accuracy: 0.6402 - top-4-accuracy: 0.9796 - val_loss: 1.3052 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9480\n",
      "Epoch 478/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9945 - accuracy: 0.6201 - top-4-accuracy: 0.9762 - val_loss: 1.2944 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9740\n",
      "Epoch 479/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9994 - accuracy: 0.6143 - top-4-accuracy: 0.9776 - val_loss: 1.2575 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9660\n",
      "Epoch 480/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9477 - accuracy: 0.6251 - top-4-accuracy: 0.9790 - val_loss: 1.2798 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9580\n",
      "Epoch 481/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9348 - accuracy: 0.6314 - top-4-accuracy: 0.9834 - val_loss: 1.3075 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9540\n",
      "Epoch 482/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0180 - accuracy: 0.6132 - top-4-accuracy: 0.9679 - val_loss: 1.2662 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9600\n",
      "Epoch 483/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9020 - accuracy: 0.6368 - top-4-accuracy: 0.9834 - val_loss: 1.2509 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9680\n",
      "Epoch 484/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9405 - accuracy: 0.6390 - top-4-accuracy: 0.9792 - val_loss: 1.2885 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9640\n",
      "Epoch 485/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0152 - accuracy: 0.6107 - top-4-accuracy: 0.9777 - val_loss: 1.3145 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9580\n",
      "Epoch 486/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9980 - accuracy: 0.6017 - top-4-accuracy: 0.9778 - val_loss: 1.2212 - val_accuracy: 0.5400 - val_top-4-accuracy: 0.9700\n",
      "Epoch 487/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9547 - accuracy: 0.6298 - top-4-accuracy: 0.9755 - val_loss: 1.2502 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9580\n",
      "Epoch 488/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9285 - accuracy: 0.6401 - top-4-accuracy: 0.9788 - val_loss: 1.3065 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9520\n",
      "Epoch 489/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9727 - accuracy: 0.6239 - top-4-accuracy: 0.9728 - val_loss: 1.2526 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9680\n",
      "Epoch 490/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9402 - accuracy: 0.6337 - top-4-accuracy: 0.9824 - val_loss: 1.3188 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9560\n",
      "Epoch 491/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9347 - accuracy: 0.6425 - top-4-accuracy: 0.9794 - val_loss: 1.2651 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9600\n",
      "Epoch 492/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9444 - accuracy: 0.6158 - top-4-accuracy: 0.9817 - val_loss: 1.3877 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9520\n",
      "Epoch 493/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9648 - accuracy: 0.6289 - top-4-accuracy: 0.9791 - val_loss: 1.2662 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9680\n",
      "Epoch 494/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9555 - accuracy: 0.6330 - top-4-accuracy: 0.9818 - val_loss: 1.2939 - val_accuracy: 0.5540 - val_top-4-accuracy: 0.9600\n",
      "Epoch 495/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9525 - accuracy: 0.6368 - top-4-accuracy: 0.9816 - val_loss: 1.2339 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9680\n",
      "Epoch 496/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9602 - accuracy: 0.6223 - top-4-accuracy: 0.9759 - val_loss: 1.3049 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9660\n",
      "Epoch 497/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9274 - accuracy: 0.6301 - top-4-accuracy: 0.9792 - val_loss: 1.3038 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9560\n",
      "Epoch 498/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9224 - accuracy: 0.6428 - top-4-accuracy: 0.9828 - val_loss: 1.4174 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9500\n",
      "Epoch 499/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9713 - accuracy: 0.6231 - top-4-accuracy: 0.9789 - val_loss: 1.3239 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9600\n",
      "Epoch 500/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9441 - accuracy: 0.6473 - top-4-accuracy: 0.9798 - val_loss: 1.3508 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9520\n",
      "Epoch 501/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9989 - accuracy: 0.6171 - top-4-accuracy: 0.9754 - val_loss: 1.3840 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9540\n",
      "Epoch 502/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9719 - accuracy: 0.6279 - top-4-accuracy: 0.9787 - val_loss: 1.3144 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9600\n",
      "Epoch 503/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9578 - accuracy: 0.6156 - top-4-accuracy: 0.9830 - val_loss: 1.2471 - val_accuracy: 0.5320 - val_top-4-accuracy: 0.9580\n",
      "Epoch 504/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9329 - accuracy: 0.6391 - top-4-accuracy: 0.9788 - val_loss: 1.3298 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9580\n",
      "Epoch 505/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9690 - accuracy: 0.6165 - top-4-accuracy: 0.9794 - val_loss: 1.2734 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9600\n",
      "Epoch 506/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9729 - accuracy: 0.6367 - top-4-accuracy: 0.9757 - val_loss: 1.2816 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9660\n",
      "Epoch 507/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9747 - accuracy: 0.6190 - top-4-accuracy: 0.9797 - val_loss: 1.2537 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9600\n",
      "Epoch 508/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9471 - accuracy: 0.6212 - top-4-accuracy: 0.9805 - val_loss: 1.2794 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9640\n",
      "Epoch 509/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9576 - accuracy: 0.6284 - top-4-accuracy: 0.9771 - val_loss: 1.2955 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9620\n",
      "Epoch 510/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9975 - accuracy: 0.6154 - top-4-accuracy: 0.9792 - val_loss: 1.2693 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9560\n",
      "Epoch 511/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9669 - accuracy: 0.6398 - top-4-accuracy: 0.9794 - val_loss: 1.3357 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9500\n",
      "Epoch 512/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9769 - accuracy: 0.6217 - top-4-accuracy: 0.9804 - val_loss: 1.3132 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9620\n",
      "Epoch 513/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9626 - accuracy: 0.6341 - top-4-accuracy: 0.9759 - val_loss: 1.2616 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9620\n",
      "Epoch 514/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9427 - accuracy: 0.6344 - top-4-accuracy: 0.9805 - val_loss: 1.3151 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9520\n",
      "Epoch 515/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9672 - accuracy: 0.6249 - top-4-accuracy: 0.9784 - val_loss: 1.3195 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9580\n",
      "Epoch 516/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9846 - accuracy: 0.6210 - top-4-accuracy: 0.9748 - val_loss: 1.2784 - val_accuracy: 0.5460 - val_top-4-accuracy: 0.9520\n",
      "Epoch 517/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9839 - accuracy: 0.6076 - top-4-accuracy: 0.9750 - val_loss: 1.3158 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9520\n",
      "Epoch 518/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9609 - accuracy: 0.6262 - top-4-accuracy: 0.9775 - val_loss: 1.3435 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9460\n",
      "Epoch 519/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9531 - accuracy: 0.6285 - top-4-accuracy: 0.9807 - val_loss: 1.3258 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9600\n",
      "Epoch 520/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9396 - accuracy: 0.6262 - top-4-accuracy: 0.9783 - val_loss: 1.3121 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9560\n",
      "Epoch 521/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9431 - accuracy: 0.6421 - top-4-accuracy: 0.9825 - val_loss: 1.3395 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9660\n",
      "Epoch 522/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9600 - accuracy: 0.6295 - top-4-accuracy: 0.9746 - val_loss: 1.2792 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9560\n",
      "Epoch 523/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0145 - accuracy: 0.6050 - top-4-accuracy: 0.9682 - val_loss: 1.2566 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9640\n",
      "Epoch 524/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9733 - accuracy: 0.6127 - top-4-accuracy: 0.9806 - val_loss: 1.2127 - val_accuracy: 0.5420 - val_top-4-accuracy: 0.9700\n",
      "Epoch 525/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9426 - accuracy: 0.6368 - top-4-accuracy: 0.9783 - val_loss: 1.2911 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9580\n",
      "Epoch 526/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0236 - accuracy: 0.6131 - top-4-accuracy: 0.9726 - val_loss: 1.2782 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9560\n",
      "Epoch 527/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9447 - accuracy: 0.6371 - top-4-accuracy: 0.9769 - val_loss: 1.2521 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9600\n",
      "Epoch 528/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9577 - accuracy: 0.6255 - top-4-accuracy: 0.9794 - val_loss: 1.2782 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9540\n",
      "Epoch 529/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9704 - accuracy: 0.6203 - top-4-accuracy: 0.9753 - val_loss: 1.2795 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9580\n",
      "Epoch 530/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9912 - accuracy: 0.6258 - top-4-accuracy: 0.9727 - val_loss: 1.2906 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9540\n",
      "Epoch 531/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9387 - accuracy: 0.6318 - top-4-accuracy: 0.9808 - val_loss: 1.3125 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9580\n",
      "Epoch 532/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9533 - accuracy: 0.6163 - top-4-accuracy: 0.9840 - val_loss: 1.2194 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9620\n",
      "Epoch 533/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9179 - accuracy: 0.6421 - top-4-accuracy: 0.9778 - val_loss: 1.2561 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9640\n",
      "Epoch 534/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9678 - accuracy: 0.6300 - top-4-accuracy: 0.9794 - val_loss: 1.2195 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9700\n",
      "Epoch 535/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9306 - accuracy: 0.6374 - top-4-accuracy: 0.9856 - val_loss: 1.2981 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9480\n",
      "Epoch 536/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9556 - accuracy: 0.6333 - top-4-accuracy: 0.9801 - val_loss: 1.2589 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9540\n",
      "Epoch 537/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9895 - accuracy: 0.6255 - top-4-accuracy: 0.9786 - val_loss: 1.2836 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9620\n",
      "Epoch 538/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9027 - accuracy: 0.6582 - top-4-accuracy: 0.9833 - val_loss: 1.2852 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9620\n",
      "Epoch 539/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9897 - accuracy: 0.6153 - top-4-accuracy: 0.9763 - val_loss: 1.2098 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9600\n",
      "Epoch 540/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9587 - accuracy: 0.6330 - top-4-accuracy: 0.9738 - val_loss: 1.2777 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9640\n",
      "Epoch 541/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9415 - accuracy: 0.6188 - top-4-accuracy: 0.9840 - val_loss: 1.2747 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9600\n",
      "Epoch 542/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9288 - accuracy: 0.6399 - top-4-accuracy: 0.9768 - val_loss: 1.3554 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9640\n",
      "Epoch 543/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9447 - accuracy: 0.6304 - top-4-accuracy: 0.9790 - val_loss: 1.2932 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9640\n",
      "Epoch 544/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9519 - accuracy: 0.6279 - top-4-accuracy: 0.9769 - val_loss: 1.3059 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9580\n",
      "Epoch 545/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9587 - accuracy: 0.6291 - top-4-accuracy: 0.9784 - val_loss: 1.3103 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9580\n",
      "Epoch 546/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9643 - accuracy: 0.6238 - top-4-accuracy: 0.9733 - val_loss: 1.3737 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9540\n",
      "Epoch 547/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9635 - accuracy: 0.6185 - top-4-accuracy: 0.9793 - val_loss: 1.2856 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9640\n",
      "Epoch 548/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9745 - accuracy: 0.6258 - top-4-accuracy: 0.9765 - val_loss: 1.3464 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9680\n",
      "Epoch 549/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9650 - accuracy: 0.6281 - top-4-accuracy: 0.9789 - val_loss: 1.2641 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9540\n",
      "Epoch 550/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9839 - accuracy: 0.6147 - top-4-accuracy: 0.9763 - val_loss: 1.3515 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9460\n",
      "Epoch 551/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9776 - accuracy: 0.6170 - top-4-accuracy: 0.9771 - val_loss: 1.2683 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9640\n",
      "Epoch 552/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9424 - accuracy: 0.6211 - top-4-accuracy: 0.9821 - val_loss: 1.2170 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9600\n",
      "Epoch 553/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9539 - accuracy: 0.6309 - top-4-accuracy: 0.9809 - val_loss: 1.2114 - val_accuracy: 0.5480 - val_top-4-accuracy: 0.9700\n",
      "Epoch 554/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9486 - accuracy: 0.6258 - top-4-accuracy: 0.9764 - val_loss: 1.3988 - val_accuracy: 0.4460 - val_top-4-accuracy: 0.9540\n",
      "Epoch 555/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9886 - accuracy: 0.6087 - top-4-accuracy: 0.9748 - val_loss: 1.3137 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9540\n",
      "Epoch 556/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9682 - accuracy: 0.6152 - top-4-accuracy: 0.9795 - val_loss: 1.3158 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9620\n",
      "Epoch 557/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9691 - accuracy: 0.6224 - top-4-accuracy: 0.9779 - val_loss: 1.2321 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9580\n",
      "Epoch 558/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9488 - accuracy: 0.6226 - top-4-accuracy: 0.9841 - val_loss: 1.2729 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9600\n",
      "Epoch 559/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9777 - accuracy: 0.6243 - top-4-accuracy: 0.9785 - val_loss: 1.2853 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9560\n",
      "Epoch 560/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9451 - accuracy: 0.6395 - top-4-accuracy: 0.9801 - val_loss: 1.3095 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9700\n",
      "Epoch 561/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9445 - accuracy: 0.6251 - top-4-accuracy: 0.9805 - val_loss: 1.2715 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9720\n",
      "Epoch 562/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9481 - accuracy: 0.6356 - top-4-accuracy: 0.9750 - val_loss: 1.2355 - val_accuracy: 0.5340 - val_top-4-accuracy: 0.9660\n",
      "Epoch 563/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9527 - accuracy: 0.6266 - top-4-accuracy: 0.9785 - val_loss: 1.2883 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9640\n",
      "Epoch 564/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9548 - accuracy: 0.6240 - top-4-accuracy: 0.9783 - val_loss: 1.2557 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9620\n",
      "Epoch 565/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9420 - accuracy: 0.6410 - top-4-accuracy: 0.9802 - val_loss: 1.2177 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9640\n",
      "Epoch 566/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9797 - accuracy: 0.6070 - top-4-accuracy: 0.9755 - val_loss: 1.3800 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9580\n",
      "Epoch 567/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0019 - accuracy: 0.6096 - top-4-accuracy: 0.9704 - val_loss: 1.2986 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9480\n",
      "Epoch 568/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9322 - accuracy: 0.6379 - top-4-accuracy: 0.9812 - val_loss: 1.3562 - val_accuracy: 0.4520 - val_top-4-accuracy: 0.9520\n",
      "Epoch 569/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9896 - accuracy: 0.6186 - top-4-accuracy: 0.9759 - val_loss: 1.3663 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9600\n",
      "Epoch 570/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9869 - accuracy: 0.6227 - top-4-accuracy: 0.9778 - val_loss: 1.2610 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9560\n",
      "Epoch 571/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9470 - accuracy: 0.6390 - top-4-accuracy: 0.9793 - val_loss: 1.3066 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9620\n",
      "Epoch 572/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9386 - accuracy: 0.6306 - top-4-accuracy: 0.9767 - val_loss: 1.2699 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9700\n",
      "Epoch 573/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9647 - accuracy: 0.6306 - top-4-accuracy: 0.9813 - val_loss: 1.2980 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9500\n",
      "Epoch 574/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9581 - accuracy: 0.6287 - top-4-accuracy: 0.9755 - val_loss: 1.2746 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9560\n",
      "Epoch 575/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9355 - accuracy: 0.6376 - top-4-accuracy: 0.9816 - val_loss: 1.3334 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9560\n",
      "Epoch 576/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0212 - accuracy: 0.6066 - top-4-accuracy: 0.9708 - val_loss: 1.2949 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9540\n",
      "Epoch 577/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9956 - accuracy: 0.6024 - top-4-accuracy: 0.9773 - val_loss: 1.2646 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9480\n",
      "Epoch 578/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9561 - accuracy: 0.6293 - top-4-accuracy: 0.9734 - val_loss: 1.3230 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9600\n",
      "Epoch 579/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9741 - accuracy: 0.6175 - top-4-accuracy: 0.9726 - val_loss: 1.2759 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9520\n",
      "Epoch 580/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9624 - accuracy: 0.6209 - top-4-accuracy: 0.9804 - val_loss: 1.2852 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9560\n",
      "Epoch 581/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9409 - accuracy: 0.6388 - top-4-accuracy: 0.9807 - val_loss: 1.3477 - val_accuracy: 0.4580 - val_top-4-accuracy: 0.9640\n",
      "Epoch 582/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0167 - accuracy: 0.6045 - top-4-accuracy: 0.9783 - val_loss: 1.2902 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9660\n",
      "Epoch 583/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9384 - accuracy: 0.6255 - top-4-accuracy: 0.9809 - val_loss: 1.2755 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9660\n",
      "Epoch 584/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9821 - accuracy: 0.6021 - top-4-accuracy: 0.9790 - val_loss: 1.3656 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9600\n",
      "Epoch 585/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9748 - accuracy: 0.6141 - top-4-accuracy: 0.9769 - val_loss: 1.2683 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9580\n",
      "Epoch 586/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9734 - accuracy: 0.6117 - top-4-accuracy: 0.9728 - val_loss: 1.2572 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9600\n",
      "Epoch 587/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9843 - accuracy: 0.6148 - top-4-accuracy: 0.9751 - val_loss: 1.2632 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9660\n",
      "Epoch 588/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9301 - accuracy: 0.6452 - top-4-accuracy: 0.9798 - val_loss: 1.2964 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9560\n",
      "Epoch 589/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9521 - accuracy: 0.6258 - top-4-accuracy: 0.9798 - val_loss: 1.2695 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9600\n",
      "Epoch 590/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9267 - accuracy: 0.6311 - top-4-accuracy: 0.9817 - val_loss: 1.2731 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9580\n",
      "Epoch 591/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9651 - accuracy: 0.6124 - top-4-accuracy: 0.9792 - val_loss: 1.1924 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9760\n",
      "Epoch 592/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9532 - accuracy: 0.6257 - top-4-accuracy: 0.9813 - val_loss: 1.2844 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9560\n",
      "Epoch 593/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9886 - accuracy: 0.6171 - top-4-accuracy: 0.9753 - val_loss: 1.3016 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9620\n",
      "Epoch 594/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9950 - accuracy: 0.6037 - top-4-accuracy: 0.9730 - val_loss: 1.2911 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9540\n",
      "Epoch 595/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9136 - accuracy: 0.6411 - top-4-accuracy: 0.9843 - val_loss: 1.3329 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9560\n",
      "Epoch 596/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0008 - accuracy: 0.6049 - top-4-accuracy: 0.9762 - val_loss: 1.2357 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9560\n",
      "Epoch 597/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9799 - accuracy: 0.6185 - top-4-accuracy: 0.9757 - val_loss: 1.2673 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9580\n",
      "Epoch 598/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0249 - accuracy: 0.6058 - top-4-accuracy: 0.9737 - val_loss: 1.3049 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9540\n",
      "Epoch 599/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9130 - accuracy: 0.6475 - top-4-accuracy: 0.9789 - val_loss: 1.2768 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9640\n",
      "Epoch 600/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9371 - accuracy: 0.6429 - top-4-accuracy: 0.9828 - val_loss: 1.2840 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9600\n",
      "Epoch 601/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9528 - accuracy: 0.6334 - top-4-accuracy: 0.9800 - val_loss: 1.2614 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9600\n",
      "Epoch 602/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9245 - accuracy: 0.6406 - top-4-accuracy: 0.9802 - val_loss: 1.3094 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9620\n",
      "Epoch 603/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9336 - accuracy: 0.6321 - top-4-accuracy: 0.9815 - val_loss: 1.3164 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9560\n",
      "Epoch 604/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9252 - accuracy: 0.6254 - top-4-accuracy: 0.9834 - val_loss: 1.2871 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9520\n",
      "Epoch 605/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0025 - accuracy: 0.6097 - top-4-accuracy: 0.9774 - val_loss: 1.2512 - val_accuracy: 0.5320 - val_top-4-accuracy: 0.9540\n",
      "Epoch 606/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9583 - accuracy: 0.6105 - top-4-accuracy: 0.9784 - val_loss: 1.2829 - val_accuracy: 0.5340 - val_top-4-accuracy: 0.9680\n",
      "Epoch 607/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9281 - accuracy: 0.6548 - top-4-accuracy: 0.9797 - val_loss: 1.3093 - val_accuracy: 0.5460 - val_top-4-accuracy: 0.9500\n",
      "Epoch 608/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9963 - accuracy: 0.6187 - top-4-accuracy: 0.9746 - val_loss: 1.2891 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9680\n",
      "Epoch 609/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9886 - accuracy: 0.6082 - top-4-accuracy: 0.9792 - val_loss: 1.2456 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9620\n",
      "Epoch 610/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9546 - accuracy: 0.6320 - top-4-accuracy: 0.9770 - val_loss: 1.2728 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9600\n",
      "Epoch 611/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9865 - accuracy: 0.6120 - top-4-accuracy: 0.9794 - val_loss: 1.2912 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9460\n",
      "Epoch 612/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9682 - accuracy: 0.6181 - top-4-accuracy: 0.9781 - val_loss: 1.2500 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9640\n",
      "Epoch 613/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9652 - accuracy: 0.6203 - top-4-accuracy: 0.9777 - val_loss: 1.2642 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9500\n",
      "Epoch 614/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9873 - accuracy: 0.6118 - top-4-accuracy: 0.9733 - val_loss: 1.2049 - val_accuracy: 0.5320 - val_top-4-accuracy: 0.9620\n",
      "Epoch 615/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9763 - accuracy: 0.6290 - top-4-accuracy: 0.9689 - val_loss: 1.3053 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9580\n",
      "Epoch 616/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9536 - accuracy: 0.6344 - top-4-accuracy: 0.9772 - val_loss: 1.2681 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9680\n",
      "Epoch 617/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9563 - accuracy: 0.6168 - top-4-accuracy: 0.9792 - val_loss: 1.3171 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9580\n",
      "Epoch 618/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9508 - accuracy: 0.6271 - top-4-accuracy: 0.9798 - val_loss: 1.3157 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9620\n",
      "Epoch 619/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0260 - accuracy: 0.6059 - top-4-accuracy: 0.9764 - val_loss: 1.2901 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9600\n",
      "Epoch 620/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9703 - accuracy: 0.6164 - top-4-accuracy: 0.9753 - val_loss: 1.2757 - val_accuracy: 0.5340 - val_top-4-accuracy: 0.9540\n",
      "Epoch 621/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9623 - accuracy: 0.6349 - top-4-accuracy: 0.9769 - val_loss: 1.2436 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9480\n",
      "Epoch 622/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9563 - accuracy: 0.6381 - top-4-accuracy: 0.9819 - val_loss: 1.3055 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9580\n",
      "Epoch 623/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9948 - accuracy: 0.6029 - top-4-accuracy: 0.9732 - val_loss: 1.2605 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9660\n",
      "Epoch 624/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9729 - accuracy: 0.6136 - top-4-accuracy: 0.9781 - val_loss: 1.2439 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9520\n",
      "Epoch 625/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9457 - accuracy: 0.6339 - top-4-accuracy: 0.9835 - val_loss: 1.3405 - val_accuracy: 0.4640 - val_top-4-accuracy: 0.9580\n",
      "Epoch 626/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9725 - accuracy: 0.6335 - top-4-accuracy: 0.9756 - val_loss: 1.2014 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9660\n",
      "Epoch 627/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9477 - accuracy: 0.6319 - top-4-accuracy: 0.9804 - val_loss: 1.2849 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9680\n",
      "Epoch 628/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9578 - accuracy: 0.6211 - top-4-accuracy: 0.9801 - val_loss: 1.3195 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9560\n",
      "Epoch 629/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9560 - accuracy: 0.6344 - top-4-accuracy: 0.9761 - val_loss: 1.2539 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9660\n",
      "Epoch 630/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9721 - accuracy: 0.6218 - top-4-accuracy: 0.9751 - val_loss: 1.2685 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9600\n",
      "Epoch 631/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9586 - accuracy: 0.6321 - top-4-accuracy: 0.9795 - val_loss: 1.2198 - val_accuracy: 0.5440 - val_top-4-accuracy: 0.9640\n",
      "Epoch 632/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9422 - accuracy: 0.6472 - top-4-accuracy: 0.9774 - val_loss: 1.3422 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9520\n",
      "Epoch 633/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0173 - accuracy: 0.6076 - top-4-accuracy: 0.9792 - val_loss: 1.2818 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9640\n",
      "Epoch 634/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9831 - accuracy: 0.6202 - top-4-accuracy: 0.9803 - val_loss: 1.2286 - val_accuracy: 0.5540 - val_top-4-accuracy: 0.9620\n",
      "Epoch 635/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9964 - accuracy: 0.6263 - top-4-accuracy: 0.9772 - val_loss: 1.2799 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9480\n",
      "Epoch 636/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9792 - accuracy: 0.6176 - top-4-accuracy: 0.9810 - val_loss: 1.2790 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9620\n",
      "Epoch 637/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9531 - accuracy: 0.6181 - top-4-accuracy: 0.9786 - val_loss: 1.2972 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9620\n",
      "Epoch 638/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9391 - accuracy: 0.6250 - top-4-accuracy: 0.9799 - val_loss: 1.2906 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9660\n",
      "Epoch 639/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9899 - accuracy: 0.6059 - top-4-accuracy: 0.9771 - val_loss: 1.2252 - val_accuracy: 0.5340 - val_top-4-accuracy: 0.9640\n",
      "Epoch 640/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9611 - accuracy: 0.6335 - top-4-accuracy: 0.9786 - val_loss: 1.2476 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9520\n",
      "Epoch 641/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9979 - accuracy: 0.6266 - top-4-accuracy: 0.9724 - val_loss: 1.3162 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9620\n",
      "Epoch 642/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9580 - accuracy: 0.6291 - top-4-accuracy: 0.9785 - val_loss: 1.3051 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9500\n",
      "Epoch 643/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9864 - accuracy: 0.6048 - top-4-accuracy: 0.9749 - val_loss: 1.2768 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9660\n",
      "Epoch 644/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9954 - accuracy: 0.6144 - top-4-accuracy: 0.9714 - val_loss: 1.1898 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9700\n",
      "Epoch 645/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9463 - accuracy: 0.6289 - top-4-accuracy: 0.9793 - val_loss: 1.3074 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9500\n",
      "Epoch 646/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9818 - accuracy: 0.6117 - top-4-accuracy: 0.9748 - val_loss: 1.2745 - val_accuracy: 0.5440 - val_top-4-accuracy: 0.9400\n",
      "Epoch 647/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9816 - accuracy: 0.6235 - top-4-accuracy: 0.9757 - val_loss: 1.3139 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9520\n",
      "Epoch 648/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9716 - accuracy: 0.6095 - top-4-accuracy: 0.9816 - val_loss: 1.3495 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9560\n",
      "Epoch 649/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9953 - accuracy: 0.6157 - top-4-accuracy: 0.9796 - val_loss: 1.3269 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9580\n",
      "Epoch 650/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9613 - accuracy: 0.6218 - top-4-accuracy: 0.9763 - val_loss: 1.2688 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9540\n",
      "Epoch 651/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9186 - accuracy: 0.6399 - top-4-accuracy: 0.9850 - val_loss: 1.2889 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9640\n",
      "Epoch 652/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9975 - accuracy: 0.6203 - top-4-accuracy: 0.9746 - val_loss: 1.2803 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9640\n",
      "Epoch 653/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9600 - accuracy: 0.6212 - top-4-accuracy: 0.9794 - val_loss: 1.3041 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9540\n",
      "Epoch 654/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9688 - accuracy: 0.6248 - top-4-accuracy: 0.9802 - val_loss: 1.2758 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9640\n",
      "Epoch 655/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9723 - accuracy: 0.6249 - top-4-accuracy: 0.9745 - val_loss: 1.1714 - val_accuracy: 0.5500 - val_top-4-accuracy: 0.9620\n",
      "Epoch 656/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9910 - accuracy: 0.6311 - top-4-accuracy: 0.9709 - val_loss: 1.2651 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9620\n",
      "Epoch 657/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9519 - accuracy: 0.6221 - top-4-accuracy: 0.9819 - val_loss: 1.3232 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9520\n",
      "Epoch 658/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9787 - accuracy: 0.6349 - top-4-accuracy: 0.9743 - val_loss: 1.2713 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9600\n",
      "Epoch 659/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9399 - accuracy: 0.6263 - top-4-accuracy: 0.9802 - val_loss: 1.2893 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9480\n",
      "Epoch 660/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9170 - accuracy: 0.6389 - top-4-accuracy: 0.9813 - val_loss: 1.2920 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9520\n",
      "Epoch 661/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9977 - accuracy: 0.6237 - top-4-accuracy: 0.9731 - val_loss: 1.3321 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9520\n",
      "Epoch 662/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9914 - accuracy: 0.6153 - top-4-accuracy: 0.9740 - val_loss: 1.2494 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9580\n",
      "Epoch 663/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9467 - accuracy: 0.6337 - top-4-accuracy: 0.9812 - val_loss: 1.2692 - val_accuracy: 0.5400 - val_top-4-accuracy: 0.9540\n",
      "Epoch 664/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9527 - accuracy: 0.6267 - top-4-accuracy: 0.9828 - val_loss: 1.2346 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9540\n",
      "Epoch 665/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9496 - accuracy: 0.6262 - top-4-accuracy: 0.9810 - val_loss: 1.2321 - val_accuracy: 0.5460 - val_top-4-accuracy: 0.9580\n",
      "Epoch 666/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9745 - accuracy: 0.6144 - top-4-accuracy: 0.9760 - val_loss: 1.2465 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9520\n",
      "Epoch 667/1000\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 0.9458 - accuracy: 0.6302 - top-4-accuracy: 0.9801 - val_loss: 1.2997 - val_accuracy: 0.5400 - val_top-4-accuracy: 0.9440\n",
      "Epoch 668/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9424 - accuracy: 0.6293 - top-4-accuracy: 0.9814 - val_loss: 1.2364 - val_accuracy: 0.5460 - val_top-4-accuracy: 0.9600\n",
      "Epoch 669/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0263 - accuracy: 0.6053 - top-4-accuracy: 0.9775 - val_loss: 1.2636 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9560\n",
      "Epoch 670/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9892 - accuracy: 0.6119 - top-4-accuracy: 0.9782 - val_loss: 1.4173 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9560\n",
      "Epoch 671/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0171 - accuracy: 0.5967 - top-4-accuracy: 0.9768 - val_loss: 1.3040 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9560\n",
      "Epoch 672/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9353 - accuracy: 0.6534 - top-4-accuracy: 0.9766 - val_loss: 1.2092 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9600\n",
      "Epoch 673/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9824 - accuracy: 0.6050 - top-4-accuracy: 0.9755 - val_loss: 1.2771 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9520\n",
      "Epoch 674/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0175 - accuracy: 0.6040 - top-4-accuracy: 0.9722 - val_loss: 1.2589 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9640\n",
      "Epoch 675/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9406 - accuracy: 0.6338 - top-4-accuracy: 0.9825 - val_loss: 1.2999 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9580\n",
      "Epoch 676/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0212 - accuracy: 0.5985 - top-4-accuracy: 0.9704 - val_loss: 1.2775 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9560\n",
      "Epoch 677/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9651 - accuracy: 0.6216 - top-4-accuracy: 0.9727 - val_loss: 1.2371 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9740\n",
      "Epoch 678/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9571 - accuracy: 0.6254 - top-4-accuracy: 0.9802 - val_loss: 1.2835 - val_accuracy: 0.5320 - val_top-4-accuracy: 0.9460\n",
      "Epoch 679/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0087 - accuracy: 0.5918 - top-4-accuracy: 0.9798 - val_loss: 1.2738 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9580\n",
      "Epoch 680/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9795 - accuracy: 0.6182 - top-4-accuracy: 0.9778 - val_loss: 1.2143 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9620\n",
      "Epoch 681/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9269 - accuracy: 0.6542 - top-4-accuracy: 0.9785 - val_loss: 1.3230 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9540\n",
      "Epoch 682/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9587 - accuracy: 0.6249 - top-4-accuracy: 0.9775 - val_loss: 1.2926 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9620\n",
      "Epoch 683/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9837 - accuracy: 0.6140 - top-4-accuracy: 0.9736 - val_loss: 1.2798 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9580\n",
      "Epoch 684/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0140 - accuracy: 0.6030 - top-4-accuracy: 0.9720 - val_loss: 1.2670 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9480\n",
      "Epoch 685/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9950 - accuracy: 0.6040 - top-4-accuracy: 0.9783 - val_loss: 1.2874 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9540\n",
      "Epoch 686/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9442 - accuracy: 0.6275 - top-4-accuracy: 0.9822 - val_loss: 1.2672 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9560\n",
      "Epoch 687/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9892 - accuracy: 0.6190 - top-4-accuracy: 0.9780 - val_loss: 1.1901 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9560\n",
      "Epoch 688/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9145 - accuracy: 0.6343 - top-4-accuracy: 0.9813 - val_loss: 1.2597 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9600\n",
      "Epoch 689/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9620 - accuracy: 0.6269 - top-4-accuracy: 0.9798 - val_loss: 1.3129 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9580\n",
      "Epoch 690/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9981 - accuracy: 0.6150 - top-4-accuracy: 0.9692 - val_loss: 1.2963 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9540\n",
      "Epoch 691/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0020 - accuracy: 0.6011 - top-4-accuracy: 0.9816 - val_loss: 1.2586 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9560\n",
      "Epoch 692/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9973 - accuracy: 0.6133 - top-4-accuracy: 0.9778 - val_loss: 1.2806 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9480\n",
      "Epoch 693/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9987 - accuracy: 0.6089 - top-4-accuracy: 0.9753 - val_loss: 1.2775 - val_accuracy: 0.4700 - val_top-4-accuracy: 0.9580\n",
      "Epoch 694/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9552 - accuracy: 0.6223 - top-4-accuracy: 0.9831 - val_loss: 1.2545 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9580\n",
      "Epoch 695/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0279 - accuracy: 0.6113 - top-4-accuracy: 0.9714 - val_loss: 1.2073 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9640\n",
      "Epoch 696/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9934 - accuracy: 0.6118 - top-4-accuracy: 0.9781 - val_loss: 1.1527 - val_accuracy: 0.5340 - val_top-4-accuracy: 0.9600\n",
      "Epoch 697/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0044 - accuracy: 0.6076 - top-4-accuracy: 0.9739 - val_loss: 1.2586 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9620\n",
      "Epoch 698/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9513 - accuracy: 0.6463 - top-4-accuracy: 0.9803 - val_loss: 1.2120 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9660\n",
      "Epoch 699/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9433 - accuracy: 0.6249 - top-4-accuracy: 0.9778 - val_loss: 1.2211 - val_accuracy: 0.5340 - val_top-4-accuracy: 0.9600\n",
      "Epoch 700/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9233 - accuracy: 0.6383 - top-4-accuracy: 0.9824 - val_loss: 1.2170 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9660\n",
      "Epoch 701/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9210 - accuracy: 0.6370 - top-4-accuracy: 0.9818 - val_loss: 1.2827 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9520\n",
      "Epoch 702/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9911 - accuracy: 0.5974 - top-4-accuracy: 0.9755 - val_loss: 1.3519 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9420\n",
      "Epoch 703/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0316 - accuracy: 0.5993 - top-4-accuracy: 0.9666 - val_loss: 1.2249 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9560\n",
      "Epoch 704/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9676 - accuracy: 0.6290 - top-4-accuracy: 0.9799 - val_loss: 1.3298 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9500\n",
      "Epoch 705/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9602 - accuracy: 0.6350 - top-4-accuracy: 0.9802 - val_loss: 1.2613 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9660\n",
      "Epoch 706/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9810 - accuracy: 0.6177 - top-4-accuracy: 0.9740 - val_loss: 1.3128 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9620\n",
      "Epoch 707/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9610 - accuracy: 0.6353 - top-4-accuracy: 0.9799 - val_loss: 1.2693 - val_accuracy: 0.4800 - val_top-4-accuracy: 0.9600\n",
      "Epoch 708/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9938 - accuracy: 0.6322 - top-4-accuracy: 0.9728 - val_loss: 1.3452 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9560\n",
      "Epoch 709/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0433 - accuracy: 0.6017 - top-4-accuracy: 0.9736 - val_loss: 1.3201 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9600\n",
      "Epoch 710/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9409 - accuracy: 0.6333 - top-4-accuracy: 0.9825 - val_loss: 1.2557 - val_accuracy: 0.5300 - val_top-4-accuracy: 0.9540\n",
      "Epoch 711/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9846 - accuracy: 0.6190 - top-4-accuracy: 0.9807 - val_loss: 1.2550 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9520\n",
      "Epoch 712/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9926 - accuracy: 0.6167 - top-4-accuracy: 0.9768 - val_loss: 1.3660 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9400\n",
      "Epoch 713/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9769 - accuracy: 0.6162 - top-4-accuracy: 0.9772 - val_loss: 1.2350 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9640\n",
      "Epoch 714/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0052 - accuracy: 0.6091 - top-4-accuracy: 0.9761 - val_loss: 1.2418 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9540\n",
      "Epoch 715/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9562 - accuracy: 0.6240 - top-4-accuracy: 0.9770 - val_loss: 1.2301 - val_accuracy: 0.5540 - val_top-4-accuracy: 0.9600\n",
      "Epoch 716/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9397 - accuracy: 0.6457 - top-4-accuracy: 0.9793 - val_loss: 1.2991 - val_accuracy: 0.5560 - val_top-4-accuracy: 0.9540\n",
      "Epoch 717/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9676 - accuracy: 0.6299 - top-4-accuracy: 0.9787 - val_loss: 1.2714 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9480\n",
      "Epoch 718/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0039 - accuracy: 0.6057 - top-4-accuracy: 0.9738 - val_loss: 1.3069 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9500\n",
      "Epoch 719/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9952 - accuracy: 0.6111 - top-4-accuracy: 0.9806 - val_loss: 1.3015 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9620\n",
      "Epoch 720/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9670 - accuracy: 0.6224 - top-4-accuracy: 0.9809 - val_loss: 1.2296 - val_accuracy: 0.5400 - val_top-4-accuracy: 0.9580\n",
      "Epoch 721/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9798 - accuracy: 0.6262 - top-4-accuracy: 0.9755 - val_loss: 1.2316 - val_accuracy: 0.5320 - val_top-4-accuracy: 0.9540\n",
      "Epoch 722/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9831 - accuracy: 0.6188 - top-4-accuracy: 0.9809 - val_loss: 1.1968 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9680\n",
      "Epoch 723/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9948 - accuracy: 0.6161 - top-4-accuracy: 0.9747 - val_loss: 1.2289 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9700\n",
      "Epoch 724/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9346 - accuracy: 0.6342 - top-4-accuracy: 0.9810 - val_loss: 1.2635 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9600\n",
      "Epoch 725/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0088 - accuracy: 0.6041 - top-4-accuracy: 0.9749 - val_loss: 1.3684 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9380\n",
      "Epoch 726/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9745 - accuracy: 0.6195 - top-4-accuracy: 0.9796 - val_loss: 1.2674 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9560\n",
      "Epoch 727/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9594 - accuracy: 0.6224 - top-4-accuracy: 0.9742 - val_loss: 1.2998 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9440\n",
      "Epoch 728/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9781 - accuracy: 0.6168 - top-4-accuracy: 0.9779 - val_loss: 1.2153 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9620\n",
      "Epoch 729/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9709 - accuracy: 0.6191 - top-4-accuracy: 0.9778 - val_loss: 1.2880 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9480\n",
      "Epoch 730/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9842 - accuracy: 0.6115 - top-4-accuracy: 0.9789 - val_loss: 1.2801 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9460\n",
      "Epoch 731/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9571 - accuracy: 0.6297 - top-4-accuracy: 0.9770 - val_loss: 1.2050 - val_accuracy: 0.5660 - val_top-4-accuracy: 0.9660\n",
      "Epoch 732/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9577 - accuracy: 0.6310 - top-4-accuracy: 0.9761 - val_loss: 1.2331 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9600\n",
      "Epoch 733/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9877 - accuracy: 0.6172 - top-4-accuracy: 0.9774 - val_loss: 1.1986 - val_accuracy: 0.5400 - val_top-4-accuracy: 0.9720\n",
      "Epoch 734/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9828 - accuracy: 0.6194 - top-4-accuracy: 0.9726 - val_loss: 1.2575 - val_accuracy: 0.5300 - val_top-4-accuracy: 0.9620\n",
      "Epoch 735/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9496 - accuracy: 0.6303 - top-4-accuracy: 0.9813 - val_loss: 1.2676 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9520\n",
      "Epoch 736/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9491 - accuracy: 0.6193 - top-4-accuracy: 0.9804 - val_loss: 1.2696 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9600\n",
      "Epoch 737/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9884 - accuracy: 0.6082 - top-4-accuracy: 0.9724 - val_loss: 1.2524 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9580\n",
      "Epoch 738/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9434 - accuracy: 0.6182 - top-4-accuracy: 0.9818 - val_loss: 1.2886 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9580\n",
      "Epoch 739/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9770 - accuracy: 0.6191 - top-4-accuracy: 0.9782 - val_loss: 1.2338 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9700\n",
      "Epoch 740/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0240 - accuracy: 0.6180 - top-4-accuracy: 0.9702 - val_loss: 1.3182 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9520\n",
      "Epoch 741/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0005 - accuracy: 0.6192 - top-4-accuracy: 0.9718 - val_loss: 1.2681 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9580\n",
      "Epoch 742/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9882 - accuracy: 0.6100 - top-4-accuracy: 0.9755 - val_loss: 1.2522 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9600\n",
      "Epoch 743/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9624 - accuracy: 0.6262 - top-4-accuracy: 0.9775 - val_loss: 1.3104 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9520\n",
      "Epoch 744/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9863 - accuracy: 0.6206 - top-4-accuracy: 0.9770 - val_loss: 1.2973 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9500\n",
      "Epoch 745/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0040 - accuracy: 0.6130 - top-4-accuracy: 0.9763 - val_loss: 1.2283 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9620\n",
      "Epoch 746/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9574 - accuracy: 0.6200 - top-4-accuracy: 0.9769 - val_loss: 1.2801 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9660\n",
      "Epoch 747/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9486 - accuracy: 0.6274 - top-4-accuracy: 0.9794 - val_loss: 1.2434 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9660\n",
      "Epoch 748/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9621 - accuracy: 0.6264 - top-4-accuracy: 0.9787 - val_loss: 1.2831 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9480\n",
      "Epoch 749/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9607 - accuracy: 0.6348 - top-4-accuracy: 0.9781 - val_loss: 1.2685 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9540\n",
      "Epoch 750/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9307 - accuracy: 0.6427 - top-4-accuracy: 0.9769 - val_loss: 1.2148 - val_accuracy: 0.5300 - val_top-4-accuracy: 0.9580\n",
      "Epoch 751/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0514 - accuracy: 0.5892 - top-4-accuracy: 0.9658 - val_loss: 1.2879 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9540\n",
      "Epoch 752/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9539 - accuracy: 0.6303 - top-4-accuracy: 0.9769 - val_loss: 1.2636 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9600\n",
      "Epoch 753/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9398 - accuracy: 0.6319 - top-4-accuracy: 0.9813 - val_loss: 1.2273 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9660\n",
      "Epoch 754/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9756 - accuracy: 0.6198 - top-4-accuracy: 0.9812 - val_loss: 1.3282 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9500\n",
      "Epoch 755/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9885 - accuracy: 0.6171 - top-4-accuracy: 0.9803 - val_loss: 1.2292 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9560\n",
      "Epoch 756/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9613 - accuracy: 0.6289 - top-4-accuracy: 0.9818 - val_loss: 1.2424 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9660\n",
      "Epoch 757/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9889 - accuracy: 0.6175 - top-4-accuracy: 0.9752 - val_loss: 1.2318 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9660\n",
      "Epoch 758/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9781 - accuracy: 0.6244 - top-4-accuracy: 0.9761 - val_loss: 1.2553 - val_accuracy: 0.5320 - val_top-4-accuracy: 0.9640\n",
      "Epoch 759/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9509 - accuracy: 0.6237 - top-4-accuracy: 0.9836 - val_loss: 1.3381 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9580\n",
      "Epoch 760/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9969 - accuracy: 0.6054 - top-4-accuracy: 0.9761 - val_loss: 1.2991 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9580\n",
      "Epoch 761/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9462 - accuracy: 0.6436 - top-4-accuracy: 0.9760 - val_loss: 1.2989 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9620\n",
      "Epoch 762/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9803 - accuracy: 0.6257 - top-4-accuracy: 0.9765 - val_loss: 1.3244 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9560\n",
      "Epoch 763/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9811 - accuracy: 0.6259 - top-4-accuracy: 0.9775 - val_loss: 1.2291 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9660\n",
      "Epoch 764/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9281 - accuracy: 0.6396 - top-4-accuracy: 0.9838 - val_loss: 1.2717 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9660\n",
      "Epoch 765/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9999 - accuracy: 0.6168 - top-4-accuracy: 0.9736 - val_loss: 1.2549 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9620\n",
      "Epoch 766/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9533 - accuracy: 0.6233 - top-4-accuracy: 0.9793 - val_loss: 1.2673 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9740\n",
      "Epoch 767/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9711 - accuracy: 0.6245 - top-4-accuracy: 0.9788 - val_loss: 1.2956 - val_accuracy: 0.5460 - val_top-4-accuracy: 0.9520\n",
      "Epoch 768/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9815 - accuracy: 0.6138 - top-4-accuracy: 0.9774 - val_loss: 1.2475 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9660\n",
      "Epoch 769/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9803 - accuracy: 0.6227 - top-4-accuracy: 0.9788 - val_loss: 1.2821 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9520\n",
      "Epoch 770/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9915 - accuracy: 0.6227 - top-4-accuracy: 0.9720 - val_loss: 1.2434 - val_accuracy: 0.5440 - val_top-4-accuracy: 0.9540\n",
      "Epoch 771/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0165 - accuracy: 0.6056 - top-4-accuracy: 0.9748 - val_loss: 1.2813 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9600\n",
      "Epoch 772/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9702 - accuracy: 0.6112 - top-4-accuracy: 0.9778 - val_loss: 1.2225 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9640\n",
      "Epoch 773/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9570 - accuracy: 0.6353 - top-4-accuracy: 0.9797 - val_loss: 1.3252 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9480\n",
      "Epoch 774/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9614 - accuracy: 0.6179 - top-4-accuracy: 0.9763 - val_loss: 1.2629 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9600\n",
      "Epoch 775/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9563 - accuracy: 0.6234 - top-4-accuracy: 0.9799 - val_loss: 1.3527 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9460\n",
      "Epoch 776/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9780 - accuracy: 0.6238 - top-4-accuracy: 0.9753 - val_loss: 1.2496 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9680\n",
      "Epoch 777/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9786 - accuracy: 0.6259 - top-4-accuracy: 0.9765 - val_loss: 1.2546 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9520\n",
      "Epoch 778/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9596 - accuracy: 0.6251 - top-4-accuracy: 0.9773 - val_loss: 1.3153 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9620\n",
      "Epoch 779/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9884 - accuracy: 0.6195 - top-4-accuracy: 0.9732 - val_loss: 1.2243 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9680\n",
      "Epoch 780/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9930 - accuracy: 0.6065 - top-4-accuracy: 0.9810 - val_loss: 1.2784 - val_accuracy: 0.4760 - val_top-4-accuracy: 0.9640\n",
      "Epoch 781/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9843 - accuracy: 0.6139 - top-4-accuracy: 0.9764 - val_loss: 1.2907 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9580\n",
      "Epoch 782/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9971 - accuracy: 0.6085 - top-4-accuracy: 0.9766 - val_loss: 1.3232 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9460\n",
      "Epoch 783/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9496 - accuracy: 0.6345 - top-4-accuracy: 0.9773 - val_loss: 1.2776 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9580\n",
      "Epoch 784/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9292 - accuracy: 0.6529 - top-4-accuracy: 0.9784 - val_loss: 1.3634 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9420\n",
      "Epoch 785/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9730 - accuracy: 0.6219 - top-4-accuracy: 0.9790 - val_loss: 1.2227 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9600\n",
      "Epoch 786/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9584 - accuracy: 0.6235 - top-4-accuracy: 0.9812 - val_loss: 1.2266 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9580\n",
      "Epoch 787/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9880 - accuracy: 0.6104 - top-4-accuracy: 0.9784 - val_loss: 1.3354 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9480\n",
      "Epoch 788/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9980 - accuracy: 0.6275 - top-4-accuracy: 0.9698 - val_loss: 1.3099 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9560\n",
      "Epoch 789/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9855 - accuracy: 0.6128 - top-4-accuracy: 0.9753 - val_loss: 1.2517 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9600\n",
      "Epoch 790/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9540 - accuracy: 0.6312 - top-4-accuracy: 0.9804 - val_loss: 1.2708 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9620\n",
      "Epoch 791/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0336 - accuracy: 0.5898 - top-4-accuracy: 0.9789 - val_loss: 1.3188 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9520\n",
      "Epoch 792/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9779 - accuracy: 0.6244 - top-4-accuracy: 0.9763 - val_loss: 1.3632 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9540\n",
      "Epoch 793/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9928 - accuracy: 0.6123 - top-4-accuracy: 0.9760 - val_loss: 1.3348 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9520\n",
      "Epoch 794/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9686 - accuracy: 0.6186 - top-4-accuracy: 0.9793 - val_loss: 1.2082 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9660\n",
      "Epoch 795/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9918 - accuracy: 0.6108 - top-4-accuracy: 0.9791 - val_loss: 1.3170 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9520\n",
      "Epoch 796/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9497 - accuracy: 0.6357 - top-4-accuracy: 0.9805 - val_loss: 1.2425 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9560\n",
      "Epoch 797/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0098 - accuracy: 0.5924 - top-4-accuracy: 0.9730 - val_loss: 1.3173 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9480\n",
      "Epoch 798/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9819 - accuracy: 0.6109 - top-4-accuracy: 0.9818 - val_loss: 1.2746 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9480\n",
      "Epoch 799/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9808 - accuracy: 0.6236 - top-4-accuracy: 0.9755 - val_loss: 1.2839 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9560\n",
      "Epoch 800/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9683 - accuracy: 0.6212 - top-4-accuracy: 0.9789 - val_loss: 1.2557 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9540\n",
      "Epoch 801/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0027 - accuracy: 0.6120 - top-4-accuracy: 0.9792 - val_loss: 1.3304 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9440\n",
      "Epoch 802/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9764 - accuracy: 0.6238 - top-4-accuracy: 0.9769 - val_loss: 1.3183 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9480\n",
      "Epoch 803/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9726 - accuracy: 0.6259 - top-4-accuracy: 0.9728 - val_loss: 1.2485 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9560\n",
      "Epoch 804/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0027 - accuracy: 0.6051 - top-4-accuracy: 0.9752 - val_loss: 1.2579 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9640\n",
      "Epoch 805/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9691 - accuracy: 0.6158 - top-4-accuracy: 0.9803 - val_loss: 1.3575 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9440\n",
      "Epoch 806/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0041 - accuracy: 0.6058 - top-4-accuracy: 0.9773 - val_loss: 1.2472 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9560\n",
      "Epoch 807/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9718 - accuracy: 0.6222 - top-4-accuracy: 0.9811 - val_loss: 1.2445 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9620\n",
      "Epoch 808/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0193 - accuracy: 0.6053 - top-4-accuracy: 0.9770 - val_loss: 1.2861 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9620\n",
      "Epoch 809/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0128 - accuracy: 0.6006 - top-4-accuracy: 0.9736 - val_loss: 1.2231 - val_accuracy: 0.5320 - val_top-4-accuracy: 0.9620\n",
      "Epoch 810/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9833 - accuracy: 0.6312 - top-4-accuracy: 0.9791 - val_loss: 1.2362 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9580\n",
      "Epoch 811/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9598 - accuracy: 0.6108 - top-4-accuracy: 0.9777 - val_loss: 1.3315 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9580\n",
      "Epoch 812/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9866 - accuracy: 0.6013 - top-4-accuracy: 0.9792 - val_loss: 1.2659 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9520\n",
      "Epoch 813/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0130 - accuracy: 0.6042 - top-4-accuracy: 0.9793 - val_loss: 1.2890 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9620\n",
      "Epoch 814/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9831 - accuracy: 0.6148 - top-4-accuracy: 0.9781 - val_loss: 1.3581 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9520\n",
      "Epoch 815/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9564 - accuracy: 0.6288 - top-4-accuracy: 0.9784 - val_loss: 1.3201 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9520\n",
      "Epoch 816/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9439 - accuracy: 0.6408 - top-4-accuracy: 0.9810 - val_loss: 1.1942 - val_accuracy: 0.5480 - val_top-4-accuracy: 0.9700\n",
      "Epoch 817/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9852 - accuracy: 0.6215 - top-4-accuracy: 0.9762 - val_loss: 1.2051 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9720\n",
      "Epoch 818/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9890 - accuracy: 0.6191 - top-4-accuracy: 0.9753 - val_loss: 1.3292 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9580\n",
      "Epoch 819/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9916 - accuracy: 0.6124 - top-4-accuracy: 0.9785 - val_loss: 1.3106 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9500\n",
      "Epoch 820/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0077 - accuracy: 0.6075 - top-4-accuracy: 0.9747 - val_loss: 1.4325 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9260\n",
      "Epoch 821/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0461 - accuracy: 0.5934 - top-4-accuracy: 0.9723 - val_loss: 1.3290 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9560\n",
      "Epoch 822/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9737 - accuracy: 0.6196 - top-4-accuracy: 0.9760 - val_loss: 1.3553 - val_accuracy: 0.5340 - val_top-4-accuracy: 0.9460\n",
      "Epoch 823/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9601 - accuracy: 0.6124 - top-4-accuracy: 0.9789 - val_loss: 1.2178 - val_accuracy: 0.5440 - val_top-4-accuracy: 0.9620\n",
      "Epoch 824/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9954 - accuracy: 0.6163 - top-4-accuracy: 0.9780 - val_loss: 1.3292 - val_accuracy: 0.4660 - val_top-4-accuracy: 0.9580\n",
      "Epoch 825/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9803 - accuracy: 0.6290 - top-4-accuracy: 0.9767 - val_loss: 1.2932 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9480\n",
      "Epoch 826/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9854 - accuracy: 0.6099 - top-4-accuracy: 0.9809 - val_loss: 1.2162 - val_accuracy: 0.5480 - val_top-4-accuracy: 0.9680\n",
      "Epoch 827/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9914 - accuracy: 0.6081 - top-4-accuracy: 0.9768 - val_loss: 1.3884 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9340\n",
      "Epoch 828/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0090 - accuracy: 0.6136 - top-4-accuracy: 0.9698 - val_loss: 1.3051 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9560\n",
      "Epoch 829/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0015 - accuracy: 0.5990 - top-4-accuracy: 0.9738 - val_loss: 1.3938 - val_accuracy: 0.4720 - val_top-4-accuracy: 0.9580\n",
      "Epoch 830/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0471 - accuracy: 0.5835 - top-4-accuracy: 0.9733 - val_loss: 1.2602 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9560\n",
      "Epoch 831/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0313 - accuracy: 0.6031 - top-4-accuracy: 0.9727 - val_loss: 1.2380 - val_accuracy: 0.5300 - val_top-4-accuracy: 0.9600\n",
      "Epoch 832/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9730 - accuracy: 0.6278 - top-4-accuracy: 0.9697 - val_loss: 1.3333 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9540\n",
      "Epoch 833/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0553 - accuracy: 0.5892 - top-4-accuracy: 0.9715 - val_loss: 1.3370 - val_accuracy: 0.4600 - val_top-4-accuracy: 0.9540\n",
      "Epoch 834/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9915 - accuracy: 0.6158 - top-4-accuracy: 0.9788 - val_loss: 1.2808 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9540\n",
      "Epoch 835/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0390 - accuracy: 0.5894 - top-4-accuracy: 0.9724 - val_loss: 1.2391 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9560\n",
      "Epoch 836/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9438 - accuracy: 0.6271 - top-4-accuracy: 0.9819 - val_loss: 1.2992 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9460\n",
      "Epoch 837/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0100 - accuracy: 0.5971 - top-4-accuracy: 0.9694 - val_loss: 1.3408 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9500\n",
      "Epoch 838/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9754 - accuracy: 0.6177 - top-4-accuracy: 0.9728 - val_loss: 1.3171 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9600\n",
      "Epoch 839/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0250 - accuracy: 0.5989 - top-4-accuracy: 0.9715 - val_loss: 1.2978 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9540\n",
      "Epoch 840/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9918 - accuracy: 0.6128 - top-4-accuracy: 0.9750 - val_loss: 1.2914 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9500\n",
      "Epoch 841/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9753 - accuracy: 0.6233 - top-4-accuracy: 0.9750 - val_loss: 1.2576 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9500\n",
      "Epoch 842/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9693 - accuracy: 0.6151 - top-4-accuracy: 0.9818 - val_loss: 1.2404 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9560\n",
      "Epoch 843/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9648 - accuracy: 0.6146 - top-4-accuracy: 0.9854 - val_loss: 1.2943 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9520\n",
      "Epoch 844/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9807 - accuracy: 0.6092 - top-4-accuracy: 0.9748 - val_loss: 1.3259 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9520\n",
      "Epoch 845/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9910 - accuracy: 0.6070 - top-4-accuracy: 0.9769 - val_loss: 1.2478 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9640\n",
      "Epoch 846/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9665 - accuracy: 0.6150 - top-4-accuracy: 0.9787 - val_loss: 1.2761 - val_accuracy: 0.5300 - val_top-4-accuracy: 0.9540\n",
      "Epoch 847/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9634 - accuracy: 0.6227 - top-4-accuracy: 0.9769 - val_loss: 1.2908 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9580\n",
      "Epoch 848/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0454 - accuracy: 0.5969 - top-4-accuracy: 0.9677 - val_loss: 1.3372 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9560\n",
      "Epoch 849/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9983 - accuracy: 0.5978 - top-4-accuracy: 0.9764 - val_loss: 1.2818 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9560\n",
      "Epoch 850/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9907 - accuracy: 0.6305 - top-4-accuracy: 0.9793 - val_loss: 1.2693 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9580\n",
      "Epoch 851/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9853 - accuracy: 0.6159 - top-4-accuracy: 0.9739 - val_loss: 1.2469 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9620\n",
      "Epoch 852/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9798 - accuracy: 0.6228 - top-4-accuracy: 0.9782 - val_loss: 1.3290 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9580\n",
      "Epoch 853/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9913 - accuracy: 0.6193 - top-4-accuracy: 0.9749 - val_loss: 1.3162 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9500\n",
      "Epoch 854/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9865 - accuracy: 0.6267 - top-4-accuracy: 0.9770 - val_loss: 1.2951 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9620\n",
      "Epoch 855/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9375 - accuracy: 0.6311 - top-4-accuracy: 0.9816 - val_loss: 1.2328 - val_accuracy: 0.5300 - val_top-4-accuracy: 0.9600\n",
      "Epoch 856/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9992 - accuracy: 0.6129 - top-4-accuracy: 0.9780 - val_loss: 1.2505 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9520\n",
      "Epoch 857/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9883 - accuracy: 0.6182 - top-4-accuracy: 0.9796 - val_loss: 1.3013 - val_accuracy: 0.4740 - val_top-4-accuracy: 0.9600\n",
      "Epoch 858/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9510 - accuracy: 0.6371 - top-4-accuracy: 0.9820 - val_loss: 1.2808 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9620\n",
      "Epoch 859/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9719 - accuracy: 0.6246 - top-4-accuracy: 0.9766 - val_loss: 1.2518 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9560\n",
      "Epoch 860/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9243 - accuracy: 0.6341 - top-4-accuracy: 0.9805 - val_loss: 1.3298 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9460\n",
      "Epoch 861/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9948 - accuracy: 0.6207 - top-4-accuracy: 0.9708 - val_loss: 1.3390 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9520\n",
      "Epoch 862/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9594 - accuracy: 0.6289 - top-4-accuracy: 0.9757 - val_loss: 1.3339 - val_accuracy: 0.5260 - val_top-4-accuracy: 0.9480\n",
      "Epoch 863/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9931 - accuracy: 0.6172 - top-4-accuracy: 0.9750 - val_loss: 1.2875 - val_accuracy: 0.5060 - val_top-4-accuracy: 0.9600\n",
      "Epoch 864/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0072 - accuracy: 0.6116 - top-4-accuracy: 0.9756 - val_loss: 1.2776 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9560\n",
      "Epoch 865/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9764 - accuracy: 0.6214 - top-4-accuracy: 0.9787 - val_loss: 1.3014 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9620\n",
      "Epoch 866/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9540 - accuracy: 0.6243 - top-4-accuracy: 0.9819 - val_loss: 1.3388 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9540\n",
      "Epoch 867/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9928 - accuracy: 0.6104 - top-4-accuracy: 0.9788 - val_loss: 1.3634 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9460\n",
      "Epoch 868/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9918 - accuracy: 0.6172 - top-4-accuracy: 0.9779 - val_loss: 1.3344 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9480\n",
      "Epoch 869/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9714 - accuracy: 0.6218 - top-4-accuracy: 0.9828 - val_loss: 1.3107 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9560\n",
      "Epoch 870/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0211 - accuracy: 0.6064 - top-4-accuracy: 0.9738 - val_loss: 1.3810 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9400\n",
      "Epoch 871/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0217 - accuracy: 0.6029 - top-4-accuracy: 0.9705 - val_loss: 1.3177 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9520\n",
      "Epoch 872/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0324 - accuracy: 0.6090 - top-4-accuracy: 0.9692 - val_loss: 1.3192 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9480\n",
      "Epoch 873/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9706 - accuracy: 0.6139 - top-4-accuracy: 0.9808 - val_loss: 1.3529 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9440\n",
      "Epoch 874/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0267 - accuracy: 0.5960 - top-4-accuracy: 0.9766 - val_loss: 1.2315 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9620\n",
      "Epoch 875/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9462 - accuracy: 0.6424 - top-4-accuracy: 0.9759 - val_loss: 1.3462 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9580\n",
      "Epoch 876/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9957 - accuracy: 0.6110 - top-4-accuracy: 0.9759 - val_loss: 1.2363 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9520\n",
      "Epoch 877/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0087 - accuracy: 0.6210 - top-4-accuracy: 0.9742 - val_loss: 1.3603 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9480\n",
      "Epoch 878/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0325 - accuracy: 0.6055 - top-4-accuracy: 0.9730 - val_loss: 1.2613 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9540\n",
      "Epoch 879/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9630 - accuracy: 0.6138 - top-4-accuracy: 0.9822 - val_loss: 1.2620 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9640\n",
      "Epoch 880/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9467 - accuracy: 0.6260 - top-4-accuracy: 0.9838 - val_loss: 1.4218 - val_accuracy: 0.4660 - val_top-4-accuracy: 0.9520\n",
      "Epoch 881/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9966 - accuracy: 0.6233 - top-4-accuracy: 0.9771 - val_loss: 1.2320 - val_accuracy: 0.5460 - val_top-4-accuracy: 0.9600\n",
      "Epoch 882/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9805 - accuracy: 0.6211 - top-4-accuracy: 0.9753 - val_loss: 1.3156 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9560\n",
      "Epoch 883/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0041 - accuracy: 0.6108 - top-4-accuracy: 0.9764 - val_loss: 1.3032 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9480\n",
      "Epoch 884/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9865 - accuracy: 0.6218 - top-4-accuracy: 0.9785 - val_loss: 1.2304 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9540\n",
      "Epoch 885/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0168 - accuracy: 0.6004 - top-4-accuracy: 0.9697 - val_loss: 1.3034 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9460\n",
      "Epoch 886/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0307 - accuracy: 0.5946 - top-4-accuracy: 0.9727 - val_loss: 1.2904 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9500\n",
      "Epoch 887/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0121 - accuracy: 0.6118 - top-4-accuracy: 0.9745 - val_loss: 1.2416 - val_accuracy: 0.5320 - val_top-4-accuracy: 0.9540\n",
      "Epoch 888/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9864 - accuracy: 0.6178 - top-4-accuracy: 0.9797 - val_loss: 1.2902 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9520\n",
      "Epoch 889/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9692 - accuracy: 0.6208 - top-4-accuracy: 0.9733 - val_loss: 1.2221 - val_accuracy: 0.5360 - val_top-4-accuracy: 0.9560\n",
      "Epoch 890/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0265 - accuracy: 0.6052 - top-4-accuracy: 0.9727 - val_loss: 1.3018 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9500\n",
      "Epoch 891/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0321 - accuracy: 0.6131 - top-4-accuracy: 0.9700 - val_loss: 1.2982 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9560\n",
      "Epoch 892/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0159 - accuracy: 0.6008 - top-4-accuracy: 0.9755 - val_loss: 1.2250 - val_accuracy: 0.5500 - val_top-4-accuracy: 0.9480\n",
      "Epoch 893/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9781 - accuracy: 0.6162 - top-4-accuracy: 0.9822 - val_loss: 1.2891 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9500\n",
      "Epoch 894/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0106 - accuracy: 0.6138 - top-4-accuracy: 0.9733 - val_loss: 1.2751 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9460\n",
      "Epoch 895/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0157 - accuracy: 0.6077 - top-4-accuracy: 0.9756 - val_loss: 1.2851 - val_accuracy: 0.5120 - val_top-4-accuracy: 0.9520\n",
      "Epoch 896/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0052 - accuracy: 0.6187 - top-4-accuracy: 0.9749 - val_loss: 1.2679 - val_accuracy: 0.5440 - val_top-4-accuracy: 0.9580\n",
      "Epoch 897/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9866 - accuracy: 0.6146 - top-4-accuracy: 0.9752 - val_loss: 1.2493 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9500\n",
      "Epoch 898/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9559 - accuracy: 0.6262 - top-4-accuracy: 0.9806 - val_loss: 1.3295 - val_accuracy: 0.4860 - val_top-4-accuracy: 0.9460\n",
      "Epoch 899/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9920 - accuracy: 0.6148 - top-4-accuracy: 0.9803 - val_loss: 1.3806 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9420\n",
      "Epoch 900/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9707 - accuracy: 0.6298 - top-4-accuracy: 0.9794 - val_loss: 1.3695 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9540\n",
      "Epoch 901/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0408 - accuracy: 0.5955 - top-4-accuracy: 0.9738 - val_loss: 1.3077 - val_accuracy: 0.5300 - val_top-4-accuracy: 0.9500\n",
      "Epoch 902/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9530 - accuracy: 0.6335 - top-4-accuracy: 0.9774 - val_loss: 1.2774 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9620\n",
      "Epoch 903/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0245 - accuracy: 0.6005 - top-4-accuracy: 0.9721 - val_loss: 1.3335 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9480\n",
      "Epoch 904/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9848 - accuracy: 0.6309 - top-4-accuracy: 0.9710 - val_loss: 1.2421 - val_accuracy: 0.5240 - val_top-4-accuracy: 0.9560\n",
      "Epoch 905/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0314 - accuracy: 0.6138 - top-4-accuracy: 0.9756 - val_loss: 1.3456 - val_accuracy: 0.4920 - val_top-4-accuracy: 0.9480\n",
      "Epoch 906/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0700 - accuracy: 0.5892 - top-4-accuracy: 0.9669 - val_loss: 1.2909 - val_accuracy: 0.5300 - val_top-4-accuracy: 0.9460\n",
      "Epoch 907/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9698 - accuracy: 0.6284 - top-4-accuracy: 0.9778 - val_loss: 1.2884 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9520\n",
      "Epoch 908/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9967 - accuracy: 0.6082 - top-4-accuracy: 0.9749 - val_loss: 1.2478 - val_accuracy: 0.5500 - val_top-4-accuracy: 0.9540\n",
      "Epoch 909/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9754 - accuracy: 0.6179 - top-4-accuracy: 0.9759 - val_loss: 1.2918 - val_accuracy: 0.5220 - val_top-4-accuracy: 0.9480\n",
      "Epoch 910/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0228 - accuracy: 0.6047 - top-4-accuracy: 0.9720 - val_loss: 1.2870 - val_accuracy: 0.4960 - val_top-4-accuracy: 0.9560\n",
      "Epoch 911/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9951 - accuracy: 0.6205 - top-4-accuracy: 0.9747 - val_loss: 1.3419 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9400\n",
      "Epoch 912/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9874 - accuracy: 0.6186 - top-4-accuracy: 0.9796 - val_loss: 1.2770 - val_accuracy: 0.5100 - val_top-4-accuracy: 0.9500\n",
      "Epoch 913/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0051 - accuracy: 0.6198 - top-4-accuracy: 0.9722 - val_loss: 1.2663 - val_accuracy: 0.5180 - val_top-4-accuracy: 0.9580\n",
      "Epoch 914/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0362 - accuracy: 0.6087 - top-4-accuracy: 0.9674 - val_loss: 1.3086 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9480\n",
      "Epoch 915/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9697 - accuracy: 0.6315 - top-4-accuracy: 0.9740 - val_loss: 1.3331 - val_accuracy: 0.4900 - val_top-4-accuracy: 0.9540\n",
      "Epoch 916/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0107 - accuracy: 0.6265 - top-4-accuracy: 0.9734 - val_loss: 1.2864 - val_accuracy: 0.4880 - val_top-4-accuracy: 0.9480\n",
      "Epoch 917/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0389 - accuracy: 0.5995 - top-4-accuracy: 0.9696 - val_loss: 1.2666 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9580\n",
      "Epoch 918/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9563 - accuracy: 0.6363 - top-4-accuracy: 0.9778 - val_loss: 1.3379 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9560\n",
      "Epoch 919/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 1.0378 - accuracy: 0.5933 - top-4-accuracy: 0.9697 - val_loss: 1.2953 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9520\n",
      "Epoch 920/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0208 - accuracy: 0.5916 - top-4-accuracy: 0.9767 - val_loss: 1.3088 - val_accuracy: 0.4780 - val_top-4-accuracy: 0.9500\n",
      "Epoch 921/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9988 - accuracy: 0.6104 - top-4-accuracy: 0.9717 - val_loss: 1.3824 - val_accuracy: 0.5140 - val_top-4-accuracy: 0.9480\n",
      "Epoch 922/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0221 - accuracy: 0.5916 - top-4-accuracy: 0.9732 - val_loss: 1.3431 - val_accuracy: 0.4980 - val_top-4-accuracy: 0.9420\n",
      "Epoch 923/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0235 - accuracy: 0.5998 - top-4-accuracy: 0.9713 - val_loss: 1.2790 - val_accuracy: 0.5160 - val_top-4-accuracy: 0.9520\n",
      "Epoch 924/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9952 - accuracy: 0.6208 - top-4-accuracy: 0.9758 - val_loss: 1.2877 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9460\n",
      "Epoch 925/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9912 - accuracy: 0.6161 - top-4-accuracy: 0.9788 - val_loss: 1.2273 - val_accuracy: 0.5280 - val_top-4-accuracy: 0.9560\n",
      "Epoch 926/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0075 - accuracy: 0.6029 - top-4-accuracy: 0.9739 - val_loss: 1.2903 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9640\n",
      "Epoch 927/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9821 - accuracy: 0.6215 - top-4-accuracy: 0.9801 - val_loss: 1.2943 - val_accuracy: 0.5000 - val_top-4-accuracy: 0.9520\n",
      "Epoch 928/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 0.9455 - accuracy: 0.6356 - top-4-accuracy: 0.9787 - val_loss: 1.3477 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9480\n",
      "Epoch 929/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9769 - accuracy: 0.6180 - top-4-accuracy: 0.9802 - val_loss: 1.2653 - val_accuracy: 0.5480 - val_top-4-accuracy: 0.9500\n",
      "Epoch 930/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9644 - accuracy: 0.6554 - top-4-accuracy: 0.9755 - val_loss: 1.2171 - val_accuracy: 0.5200 - val_top-4-accuracy: 0.9600\n",
      "Epoch 931/1000\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 0.9749 - accuracy: 0.6125 - top-4-accuracy: 0.9798 - val_loss: 1.2158 - val_accuracy: 0.5380 - val_top-4-accuracy: 0.9580\n",
      "Epoch 932/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9802 - accuracy: 0.6192 - top-4-accuracy: 0.9744 - val_loss: 1.2606 - val_accuracy: 0.4940 - val_top-4-accuracy: 0.9540\n",
      "Epoch 933/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0206 - accuracy: 0.6202 - top-4-accuracy: 0.9717 - val_loss: 1.2747 - val_accuracy: 0.5080 - val_top-4-accuracy: 0.9520\n",
      "Epoch 934/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9734 - accuracy: 0.6391 - top-4-accuracy: 0.9758 - val_loss: 1.3236 - val_accuracy: 0.4820 - val_top-4-accuracy: 0.9640\n",
      "Epoch 935/1000\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 1.0048 - accuracy: 0.6182 - top-4-accuracy: 0.9668 - val_loss: 1.3250 - val_accuracy: 0.5040 - val_top-4-accuracy: 0.9500\n",
      "Epoch 936/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 0.9894 - accuracy: 0.6251 - top-4-accuracy: 0.9768 - val_loss: 1.2634 - val_accuracy: 0.5020 - val_top-4-accuracy: 0.9440\n",
      "Epoch 937/1000\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1.0358 - accuracy: 0.6156 - top-4-accuracy: 0.9704 - val_loss: 1.3363 - val_accuracy: 0.4840 - val_top-4-accuracy: 0.9460\n",
      "Epoch 938/1000\n",
      "69/71 [============================>.] - ETA: 0s - loss: 1.0032 - accuracy: 0.6193 - top-4-accuracy: 0.9717"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aggregate-merchandise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2141 - accuracy: 0.5540 - top-4-accuracy: 0.9580\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    score = vit_classifier.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "private-legend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 160, 16 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "data_augmentation (Sequential)  (None, 160, 160, 16) 33          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 4, 4, 64)     1638464     data_augmentation[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 16, 64)       0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding (PositionEmb (None, 16, 64)       1024        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 16, 64)       128         position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 16, 64)       66368       layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 64)       0           multi_head_attention[0][0]       \n",
      "                                                                 position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 16, 64)       128         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16, 128)      8320        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16, 128)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16, 64)       8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 64)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 64)       0           dropout_1[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 16, 64)       128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 16, 64)       66368       layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 64)       0           multi_head_attention_1[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 16, 64)       128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16, 128)      8320        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 128)      0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16, 64)       8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 64)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 64)       0           dropout_3[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 16, 64)       128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 16, 64)       66368       layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 64)       0           multi_head_attention_2[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 16, 64)       128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16, 128)      8320        layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 128)      0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16, 64)       8256        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 64)       0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 64)       0           dropout_5[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 16, 64)       128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 16, 64)       66368       layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 64)       0           multi_head_attention_3[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 16, 64)       128         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16, 128)      8320        layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 128)      0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16, 64)       8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16, 64)       0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 64)       0           dropout_7[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 16, 64)       128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 16, 64)       66368       layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 64)       0           multi_head_attention_4[0][0]     \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 16, 64)       128         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16, 128)      8320        layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 128)      0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16, 64)       8256        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 64)       0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 64)       0           dropout_9[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, 16, 64)       128         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 16, 64)       66368       layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 64)       0           multi_head_attention_5[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, 16, 64)       128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16, 128)      8320        layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 128)      0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16, 64)       8256        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 64)       0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 64)       0           dropout_11[0][0]                 \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 16, 64)       128         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, 16, 64)       66368       layer_normalization_12[0][0]     \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 64)       0           multi_head_attention_6[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 16, 64)       128         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 16, 128)      8320        layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 128)      0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16, 64)       8256        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 64)       0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 64)       0           dropout_13[0][0]                 \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 16, 64)       128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, 16, 64)       66368       layer_normalization_14[0][0]     \n",
      "                                                                 layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 64)       0           multi_head_attention_7[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, 16, 64)       128         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16, 128)      8320        layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 128)      0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 16, 64)       8256        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 64)       0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 64)       0           dropout_15[0][0]                 \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 16, 64)       128         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64)           0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2048)         133120      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 2048)         0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1024)         2098176     dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1024)         0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 8)            8200        dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,544,745\n",
      "Trainable params: 4,544,712\n",
      "Non-trainable params: 33\n",
      "__________________________________________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "vit_classifier.summary()\n",
    "keras.utils.plot_model(vit_classifier,\n",
    "                       to_file=\"vit-cifar.png\",\n",
    "                       show_shapes=True,\n",
    "                       expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "trained-middle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)  \n",
    "  \n",
    "# summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "   \n",
    "# summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db668d-57d8-4fc4-8f47-c6173f426b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (λ)",
   "language": "python",
   "name": "lambda-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
